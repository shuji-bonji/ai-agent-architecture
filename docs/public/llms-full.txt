# AI Agent Architecture

> A documentation site explaining how AI agents discover and orchestrate Skills, Tools, and Protocols...

This document is a comprehensive concatenation of all English documentation pages from the AI Agent Architecture project. It includes foundational concepts, MCP (Model Context Protocol) guidance, Skills framework, Agent architecture, strategy, and workflows.

---

## Vision for AI-Driven Development

Source: https://shuji-bonji.github.io/ai-agent-architecture/concepts/01-vision/

# Vision for AI-Driven Development

This document outlines the philosophy underlying AI agent architecture (MCP, Skills, and Agent integration) and the fundamental approach to AI-driven development.

> The essence of AI-driven development is not just code generation, but **leveraging AI as an "intelligent assistant" throughout the entire process**, enabling humans to focus on higher-level decision-making and creativity.

## Core Understanding

### AI is "Not Omnipotent"

While AI capabilities are rapidly advancing, it is crucial to correctly recognize their limitations. To avoid over-reliance on AI and use it appropriately, we need to understand the following constraints.

AI generates outputs probabilistically from training data, but cannot guarantee the following:

| AI Limitation      | Description                                                              |
| ------------------ | ------------------------------------------------------------------------ |
| **Accuracy**       | Hallucination problem - may generate information that differs from facts |
| **Currency**       | Does not have information beyond the training data cutoff                |
| **Authority**      | Cannot guarantee official interpretation of specifications               |
| **Accountability** | Cannot provide grounds for legal or ethical judgments                    |

**Therefore, we need to connect to reliable sources.**

## The Essence of AI-Driven Development

```
AI-driven development â‰  Having AI write code
AI-driven development = Utilizing AI throughout all processes while humans focus on judgment and creativity
```

### The Reality During This Transitional Period

Until the future comes when AI (including CI/CD) can immediately output binaries and be implemented, AI-driven development will require the introduction of the engineering skills that people have cultivated up to now.

What are these necessary elements?

In other words, "AI can generate plausible outputs, but **guidelines for decision-making are needed**."

This is why **unwavering reference sources** are necessary.

```mermaid
graph TB
    subgraph Current Software Development
        AI[AI] --> |"Generation"| Code[Code]
        Code --> |"Depends on"| Layer[Abstraction Layer]
        Layer --> |"Human Heritage"| Standards[Standards & Specifications]
    end

    Standards --> |"Reference"| AI

    style Standards fill:#ffd700,color:#000,stroke:#b8860b,stroke-width:2px

```

## The Importance of "Unwavering Reference Sources"

### Why Reference Sources Are Needed

| AI Challenge                       | What Reference Sources Solve               |
| ---------------------------------- | ------------------------------------------ |
| Fixed point-in-time training data  | Access to authoritative up-to-date sources |
| Hallucination                      | Provision of verifiable evidence           |
| Interpretation variance by context | Consistent decision criteria               |
| Lack of latest information         | Retrieval of current specifications        |

### Two Means to Achieve "Unwavering Reference Sources"

**MCP** and **Skills** serve as means to provide AI with "unwavering reference sources."

| Means                                               | Role                                                   | Examples                                       |
| --------------------------------------------------- | ------------------------------------------------------ | ---------------------------------------------- |
| **[MCP](https://modelcontextprotocol.io/)**         | Dynamic access to external authoritative sources       | RFC, legislation, W3C standards                |
| **[Skills](https://github.com/vercel-labs/skills)** | Systematization of domain knowledge and best practices | Design principles, workflows, coding standards |

### Value of Reference MCP/Skills

1. **AI decisions become verifiable** - Can demonstrate the basis for outputs
2. **Consistent quality is ensured** - Standards-compliant outputs
3. **Vendor lock-in is avoided** - Based on open standards
4. **Access to knowledge is democratized** - Reach accurate information without being an expert
5. **Domain knowledge becomes reusable** - Formalize team know-how as Skills

## Democratization of Knowledge

### Problems with the Traditional Approach

```mermaid
flowchart LR
    G[General Developers]
    Expert --> Books/Lectures --> G
```

- High cost
- One-way
- Language barriers

### The World MCP/Skills Enables

```mermaid
flowchart TB
  A["External Authoritative Sources<br>(RFC/Legislation/W3C)"]
  B["Domain Knowledge <br>(Design Principles/Standards)" ]
  M["MCP-ified<br>(Dynamic Access)"]
  S["Skills-ified<br>(Systematization)"]
  K[Knowledge Accessible to Everyone]

  A --> M
  B --> S
  M --> AI
  S --> AI
  AI --> Documentation/Checklists --> K
```

**Development based on accurate information becomes possible** without relying on expensive consultants or specialists.

> For **how to distinguish between MCP and Skills**, see [skills/vs-mcp.md](../skills/vs-mcp.md).

## Human â†’ AI (Structuring) Knowledge Transformation

Enable AI to access "unwavering reference sources."

### Structuring External Information Sources via MCP

| Human Knowledge          | Structured Format | AI-Usable Form |
| ------------------------ | ----------------- | -------------- |
| Legal text               | e-Gov API         | hourei-mcp     |
| Technical specifications | RFC XML           | rfcxml-mcp     |
| Web standards            | W3C/WHATWG        | w3c-mcp        |
| Translation rules        | Glossary          | DeepL Glossary |

### Systematizing Domain Knowledge via Skills

| Team Knowledge    | Format   | AI-Usable Form         |
| ----------------- | -------- | ---------------------- |
| Design principles | Markdown | frontend-design skill  |
| Coding standards  | Markdown | coding-standards skill |
| Workflows         | Markdown | doc-coauthoring skill  |

## AI â†’ Human (Comprehension Support) Knowledge Transformation

Enable humans to access accurate knowledge even without being specialists.

| Complex Information Source  | AI Processing             | Human-Understandable Form      |
| --------------------------- | ------------------------- | ------------------------------ |
| RFC 3161 (135 requirements) | Extraction/Classification | Checklist                      |
| Digital Signature Law + RFC | Mapping                   | Correspondence table           |
| Technical specifications    | Visualization             | Mermaid diagrams               |
| English RFCs                | Translation               | Explanations in local language |

## Division of Roles Between Humans and AI

The diagram below illustrates how human capabilities and AI capabilities complement each other to achieve better development outcomes.

```mermaid
graph TB
    subgraph Human Roles
        A[Decision Making]
        B[Creativity]
        C[Quality Judgment]
        D[Stakeholder Communication]
    end

    subgraph "AI Roles (via MCP)"
        E[Information Gathering & Analysis]
        F[Routine Task Automation]
        G[Quality Checking]
        H[Document Generation]
    end

    subgraph Outcomes
        I[Improved Development Speed]
        J[Improved Quality]
        K[Knowledge Accumulation]
        L[Reduced Key-Person Dependency]
    end

    A --> E
    B --> F
    C --> G
    D --> H
    E --> I
    F --> I
    G --> J
    H --> K
    I --> L
    J --> L
    K --> L
```

## Basic flow of MCP, Skills, and Agent

Here is the fundamental flow that shows how user input flows through the agent core and tool integrations to produce results:

```mermaid
graph TB
    A[User Input] --> B[Agent Core]
    B --> C[Tool Integrations]
    C --> D[Web Scraping]
    C --> E[API Calls]
    C --> F[Data Processing]
    B --> G[Decision Engine]
    G --> H[Output Generation]
    H --> I[User Response]
```

This diagram illustrates a basic flow: inputs processed through an agent core, utilizing tools, and outputting results.

## Positioning of This Repository

```mermaid
graph TB
    subgraph Democratization of Knowledge
        RAW[Raw Information Sources<br/>RFCãƒ»Legislationãƒ»Standards]
        DOMAIN[Domain Knowledge<br/>Design Principlesãƒ»Standards]
        MCP[MCP Layer<br/>rfcxml / hourei / w3c]
        SKILLS[Skills Layer<br/>frontend-design / doc-coauthoring]
        DOC[Documentation Layer<br/>Notes-about-Digital-Signatures<br/>websocket-practical-guide]
        USER[End Users<br/>Developersãƒ»Learners]

        RAW -->|"AI structures<br/>and retrieves"| MCP
        DOMAIN -->|"AI references"| SKILLS
        MCP -->|"AI transforms<br/>for humans"| DOC
        SKILLS -->|"AI applies"| DOC
        DOC -->|"Understandãƒ»Implement"| USER
    end
```

This repository is a place to organize the design philosophy, architecture, and practical know-how of AI agent architecture (MCP, Skills, and Agent integration), and to document **strategies for building "unwavering reference sources" as the foundation of AI-driven development**.

## Core Messages

1. **AI-driven development is not just code generation** - Utilize AI throughout all processes
2. **AI needs guidelines for decision-making** - The importance of unwavering reference sources
3. **Systematize human engineering knowledge** - Formalize as MCP/Skills
4. **Standards-based MCPs are the foundation** - Democratize access to RFC, W3C, legislation, etc.
5. **Share domain knowledge via Skills** - Make team know-how reusable
6. **Bidirectional knowledge transformation** - Humanâ†’AI (structuring), AIâ†’Human (comprehension support)

---

## The Framework of "Authoritative Reference Sources"

Source: https://shuji-bonji.github.io/ai-agent-architecture/concepts/02-reference-sources/

# The Framework of "Authoritative Reference Sources"

> Providing authoritative reference sources for AI decisions is the foundation of reliability in AI-driven development.

## About This Document

In AI-driven development, the quality of AI output is determined by "what it references." This document systematically organizes the "authoritative reference sources" that AI should use as the basis for its decisions, clarifying why they are necessary, what characteristics they should have, and how they should be connected.

By converting authoritative information sources such as RFCs, W3C specifications, and legislation into [MCP](https://modelcontextprotocol.io/) format, AI output can have **verifiable evidence**. This enables a development environment where the question "Is what the AI says really true?" can always be answered by pointing to the original source.

> **Note**: This document primarily covers "external authoritative information sources." For team domain knowledge and best practices, see [Skills](../skills/what-is-skills). For the distinction between MCP and Skills, see [vs-mcp.md](../skills/vs-mcp.md).

## Chapter 1: Why Does AI "Fluctuate"?

### 1.1 The Nature of Probabilistic Generation

Large Language Models (LLMs) are fundamentally **probabilistic text generation systems**. The diagram below illustrates how this process works from input to output:

```mermaid
flowchart LR
    INPUT[Input Text] --> MODEL[LLM]
    MODEL --> PROB[Probability Distribution]
    PROB --> SAMPLE[Sampling]
    SAMPLE --> OUTPUT[Output Text]

    style PROB fill:#ff9999,color:#333
```

| Characteristic                   | Description                                                                | Impact on AI                              |
| -------------------------------- | -------------------------------------------------------------------------- | ----------------------------------------- |
| **Statistical Pattern Learning** | Predicts "likely next tokens" from co-occurrence patterns in training data | Outputs "plausible" rather than "correct" |
| **Non-deterministic Sampling**   | Same input can produce different outputs                                   | Consistency guarantees are difficult      |
| **Context Dependency**           | Subtle differences in prompts change output                                | Reproducibility issues                    |

### 1.2 The Four Fundamental Limitations of AI

Understanding these four core categories of limitations is essential for working with AI effectively:

```mermaid
mindmap
  root((AI Limitations))
    Accuracy Limitations
      Hallucination
      Factual Errors
      Logical Contradictions
    Recency Limitations
      Training Data Cutoff
      Lack of Real-time Information
      Cannot Track Changed Specifications
    Authority Limitations
      Absence of Official Interpretation
      Ambiguous Sources
      Divergence from Expert Consensus
    Accountability Limitations
      Lack of Legal Basis
      No Accountability
      Missing Audit Trail
```

#### 1.2.1 Accuracy Limitations (Hallucination Problem)

AI doesn't "know" â€” it "generates."

```
User: What is the meaning of status code 1006 for Close frames
      as defined in Section 5.5.1 of RFC 6455?

AI Possibility A: "1006 indicates unexpected disconnection" (correct)
AI Possibility B: "1006 indicates a protocol error" (wrong - that's 1002)
AI Possibility C: "Section 5.5.1 contains the definition of 1006" (wrong - 7.4.1 is correct)
```

**Hallucination Generation Mechanisms**

The following table explains the primary causes that lead to hallucinated outputs:

| Cause                               | Description                                    | Example                                 |
| ----------------------------------- | ---------------------------------------------- | --------------------------------------- |
| **Sparse Training Data**            | Rare information is undertrained               | Details of minor RFCs                   |
| **Confusion with Similar Patterns** | Confuses similar concepts                      | Close code 1002 vs 1006                 |
| **Overconfident Completion**        | Fills in unknown parts "plausibly"             | Generating non-existent section numbers |
| **Context Contamination**           | Treats misinformation in conversation as truth | Amplifies user misunderstandings        |

#### 1.2.2 Recency Limitations

AI knowledge is fixed at a point in time, making it unable to reflect real-world changes that occur after training:

```mermaid
timeline
    title Knowledge Temporal Fixation Problem

    section Training Data
      December 2023 : Training Cutoff

    section Real World
      March 2024 : RFC 9562 Published
      June 2024 : New HTTP/3 Extensions
      September 2024 : Security Vulnerability Discovered
      January 2025 : Legal Amendment Enacted
```

**Specific Impacts**

The following examples demonstrate how recency limitations manifest in practical scenarios:

| Category                | Problem                              | Example                                      |
| ----------------------- | ------------------------------------ | -------------------------------------------- |
| **New RFCs**            | Unaware of existence                 | Does not know RFC 9562 (UUIDv7)              |
| **Legal Amendments**    | Answers based on old law             | Answers based on pre-amendment privacy law   |
| **Deprecation/Updates** | Treats old specifications as current | References RFC 2616 as the HTTP/1.1 standard |
| **Security**            | Unaware of known vulnerabilities     | Does not know CVEs discovered after cutoff   |

#### 1.2.3 Authority Limitations

AI output is "one interpretation" and **not an official opinion**. When multiple interpretations of a specification are possible, AI may select one without guarantee of correctness:

```
Problem Structure:

RFC 6455 Original Text
    â†“
    Multiple Interpretation Possibilities
    â”œâ”€â”€ Interpretation A (Strict)
    â”œâ”€â”€ Interpretation B (Lenient)
    â””â”€â”€ Interpretation C (Context-dependent)

AI Output
    â†“
    Outputs one interpretation "plausibly"
    â†“
    No guarantee that it is the correct interpretation
```

**Situations Where Lack of Authority Is Problematic**

These scenarios illustrate where the absence of official authority creates real risks:

| Situation                        | Risk                            | Required Response         |
| -------------------------------- | ------------------------------- | ------------------------- |
| **Specification Implementation** | Non-compliant implementation    | Verify RFC original text  |
| **Legal Decisions**              | Compliance violations           | Verify legal text         |
| **Security**                     | Overlooking vulnerabilities     | Check official advisories |
| **Contracts/SLAs**               | Disputes from misinterpretation | Verify contract text      |

#### 1.2.4 Accountability Limitations

AI output has **no subject of accountability**. This differs fundamentally from traditional information sources where responsibility can be traced:

```mermaid
graph TB
    subgraph Traditional Information Sources
        direction TB
        EXPERT[Expert] --> |"Signature/Review"| DOC[Document]
        DOC --> |"Citation/Reference"| USER[User]
        EXPERT --> |"Bears Responsibility"| USER
    end

    subgraph AI Output
        direction TB
        AI[AI] --> |"Generation"| OUTPUT[Output]
        OUTPUT --> |"Usage"| USER2[User]
        AI -.- |"Responsibility is Ambiguous"| USER2
    end

    style AI fill:#ff9999,color:#333
```

| Problem                     | Description                      | Result                    |
| --------------------------- | -------------------------------- | ------------------------- |
| **Source Opacity**          | Unknown basis for generation     | Cannot verify             |
| **Revision Untraceability** | Unknown when information is from | Cannot audit              |
| **Error Attribution**       | Unclear who bears responsibility | Difficult risk management |

These accountability issues create significant challenges for risk management and compliance.

## Chapter 2: What Are "Authoritative Reference Sources"?

### 2.1 Definition

**Authoritative Reference Sources** are information sources that satisfy the following characteristics, each contributing to overall trustworthiness:

```mermaid
graph TB
    subgraph Five Characteristics of Authoritative Reference Sources
        AUTH[Authoritativeness]
        IMMUT[Immutability & Versioning]
        STRUCT[Structuredness]
        VERIFY[Verifiability]
        ACCESS[Accessibility]
    end

    AUTH --> |"Who said it"| TRUST[Trustworthiness]
    IMMUT --> |"When is the information from"| TRUST
    STRUCT --> |"What is written"| TRUST
    VERIFY --> |"Can be confirmed"| TRUST
    ACCESS --> |"Can be referenced"| TRUST

    style TRUST fill:#90EE90,color:#333
```

### 2.2 The Five Characteristics

#### 2.2.1 Authoritativeness

The information source has **official decision-making authority or expertise** in its domain. Different types of authority carry different weights:

| Type of Authority           | Description                                               | Examples                             |
| --------------------------- | --------------------------------------------------------- | ------------------------------------ |
| **Institutional Authority** | Official bodies established by law or treaty              | IETF, W3C, ISO, National Governments |
| **De facto Authority**      | Entities recognized as de facto standards in the industry | OWASP, Ecma International            |
| **Academic Authority**      | Academic communities with peer review processes           | IEEE, ACM                            |
| **Technical Authority**     | Developers/maintainers of technology                      | OSS Projects, Vendors                |

The hierarchy of authority is shown in the following diagram:

```mermaid
graph TB
    subgraph Authority Hierarchy
        L1[Legally Binding<br/>Laws/Treaties]
        L2[International Standards Bodies<br/>IETF/W3C/ISO]
        L3[Industry Standards/De facto<br/>OWASP/OpenAPI]
        L4[Official Tech Vendors<br/>MDN/Various SDKs]
        L5[Community Knowledge<br/>Stack Overflow etc.]
    end

    L1 --> L2 --> L3 --> L4 --> L5

    style L1 fill:#ff6b6b,color:#333
    style L2 fill:#feca57,color:#333
    style L3 fill:#48dbfb,color:#333
    style L4 fill:#1dd1a1,color:#333
    style L5 fill:#c8d6e5,color:#333
```

#### 2.2.2 Immutability & Versioning

Once published, content either **does not change** or when it does, **clear version management** is applied. These patterns ensure you know the precise source of information:

| Pattern                   | Description                        | Example                            |
| ------------------------- | ---------------------------------- | ---------------------------------- |
| **Complete Immutability** | Never changed once published       | RFC (except Errata)                |
| **Versioned Changes**     | New version replaces old version   | ISO Standards, W3C Recommendations |
| **Explicit Deprecation**  | Old versions explicitly deprecated | RFC obsoletes/updates              |

Here is how the RFC versioning model exemplifies this principle:

```
RFC Immutability Model:

RFC 2616 (HTTP/1.1, 1999)
    â†“ obsoleted by
RFC 7230-7235 (2014)
    â†“ obsoleted by
RFC 9110-9114 (2022)

â†’ Each RFC is unchanged after publication
â†’ New RFCs "replace" old RFCs
â†’ Clear which point in time the specification is from
```

#### 2.2.3 Structuredness

Information is **systematically organized** so specific information can be precisely referenced. Structured sources allow for unambiguous citations:

```mermaid
graph TB
    subgraph Structured Reference
        direction TB
        RFC["RFC 6455"]
        SEC["Section 7.4.1"]
        PARA["Paragraph 3"]
        REQ["MUST requirement"]
    end

    RFC --> SEC --> PARA --> REQ

    subgraph Ambiguous Reference
        direction TB
        VAGUE["The WebSocket specification says..."]
    end

    style RFC fill:#90EE90,color:#333
    style VAGUE fill:#ff9999,color:#333
```

| Structuring Element        | Description                                     | Benefit for AI                          |
| -------------------------- | ----------------------------------------------- | --------------------------------------- |
| **Hierarchical Structure** | Clear hierarchy of chapters/sections/paragraphs | Precise reference to specific locations |
| **Identifiers**            | Unique section/article numbers                  | Unambiguous citations                   |
| **Cross-references**       | Explicit links to other documents/sections      | Tracking related information            |
| **Index**                  | Term index, requirement lists                   | Efficient searching                     |

#### 2.2.4 Verifiability

AI output can be **confirmed against the original source**. The following sequence diagram shows how verification works in practice:

```mermaid
sequenceDiagram
    participant User as User
    participant AI as AI (Claude)
    participant MCP as MCP Server
    participant Source as Original Source (RFC)

    User->>AI: Tell me about WebSocket Close codes
    AI->>MCP: get_requirements(6455, section="7.4.1")
    MCP->>Source: Fetch RFC original text
    Source-->>MCP: Original text
    MCP-->>AI: Structured requirements
    AI-->>User: Answer + Source citation

    Note over User: Verifiable!
    User->>Source: Can also verify directly
```

**Elements Ensuring Verifiability**

| Element                    | Description                          | Implementation                        |
| -------------------------- | ------------------------------------ | ------------------------------------- |
| **Persistent URI**         | Reference won't disappear            | DOI, RFC number, Legal article number |
| **Version Specification**  | Clarify which version was referenced | RFC 9110, ISO 27001:2022              |
| **Section Specification**  | Clarify which part was referenced    | Section 7.4.1                         |
| **Original Text Citation** | Show the referenced wording          | MUST/SHOULD/MAY original text         |

#### 2.2.5 Accessibility

Provided in a format that **AI can access programmatically**. Different levels of accessibility present different opportunities and challenges:

| Level               | Description                           | Example             |
| ------------------- | ------------------------------------- | ------------------- |
| **Structured API**  | Accessible in machine-readable format | RFC XML, e-Gov API  |
| **HTML/PDF**        | Published on web but requires parsing | W3C specs, most ISO |
| **Paid/Restricted** | Access has constraints                | Some ISO standards  |

The diagram below illustrates the accessibility spectrum:

```mermaid
graph TB
    subgraph Ideal Accessibility
        API[Structured API] --> MCP[MCP Server] --> AI[AI]
    end

    subgraph Real-world Challenges
        PDF[PDF only] --> |"OCR/Parse"| MANUAL[Manual Processing]
        PAID[Paid] --> |"License"| BARRIER[Barrier]
    end

    style API fill:#90EE90,color:#333
    style PDF fill:#feca57,color:#333
    style PAID fill:#ff9999,color:#333
```

### 2.3 Criteria for Evaluating "Authoritative Reference Sources"

Use this decision flowchart to evaluate whether an information source qualifies as authoritative:

```mermaid
flowchart TB
    START[Information Source] --> Q1{Is the issuing body<br/>an official organization?}
    Q1 -->|Yes| Q2{Is it version<br/>controlled?}
    Q1 -->|No| LOW[Reliability: Low]

    Q2 -->|Yes| Q3{Is it<br/>structured?}
    Q2 -->|No| MED1[Reliability: Medium<br/>Watch version tracking]

    Q3 -->|Yes| Q4{Is it in a<br/>verifiable format?}
    Q3 -->|No| MED2[Reliability: Medium<br/>Watch for ambiguity]

    Q4 -->|Yes| Q5{Is it programmatically<br/>accessible?}
    Q4 -->|No| MED3[Reliability: Medium<br/>High verification cost]

    Q5 -->|Yes| HIGH[Reliability: High<br/>Recommended for MCP]
    Q5 -->|No| MED4[Reliability: Medium-High<br/>Value increases with MCP]

    style HIGH fill:#90EE90,color:#333
    style LOW fill:#ff9999,color:#333
```

## Chapter 3: Hierarchical Structure of Reference Sources

### 3.1 The Four-Layer Model

Reference sources are organized into a four-level hierarchy, where each level has different compliance requirements:

```mermaid
graph TB
    subgraph Level1["Level 1: International Standards & Regulations (MUST)"]
        direction TB
        IETF[IETF RFC]
        W3C[W3C Standards]
        ISO[ISO Standards]
        LAW[Laws & Regulations]
    end

    subgraph Level2["Level 2: Industry Standards & De facto (SHOULD)"]
        direction TB
        OPENAPI[OpenAPI]
        OWASP[OWASP]
        OAUTH[OAuth 2.0]
        SEMVER[Semantic Versioning]
    end

    subgraph Level3["Level 3: Organization/Project Rules (Local)"]
        direction TB
        CODING[Coding Standards]
        ADR[ADR]
        STYLE[Style Guide]
    end

    subgraph Level4["Level 4: Best Practices (Recommended)"]
        direction TB
        PATTERN[Design Patterns]
        CLEAN[Clean Code]
        SOLID[SOLID Principles]
    end

    Level1 --> Level2 --> Level3 --> Level4
```

### 3.2 Level Details

#### Level 1: International Standards & Regulations (MUST Comply)

Highest authority reference sources. Violations cause **interoperability issues or legal problems**. The following table shows examples from different domains:

| Category                    | Reference    | 5 Characteristics Rating | MCP Status             |
| --------------------------- | ------------ | ------------------------ | ---------------------- |
| **Communication Protocols** | IETF RFC     | â—Žâ—Žâ—Žâ—Žâ—Ž                    | âœ… rfcxml-mcp          |
| **Web Standards**           | W3C / WHATWG | â—Žâ—Žâ—Žâ—Žâ—‹                    | âœ… w3c-mcp             |
| **International Standards** | ISO          | â—Žâ—Žâ—Žâ—‹â–³                    | ðŸ”œ Under consideration |
| **Japanese Laws**           | e-Gov        | â—Žâ—Žâ—Žâ—Žâ—Ž                    | âœ… hourei-mcp          |
| **EU Regulations**          | EUR-Lex      | â—Žâ—Žâ—Žâ—Žâ—‹                    | ðŸ“‹ Planned             |

IETF RFCs exemplify the highest standard for all five characteristics:

```
Authoritativeness: â—Ž Official publication by IETF, WG consensus
Immutability:      â—Ž No changes after publication, managed via obsoletes/updates
Structuredness:    â—Ž Section numbers, clear MUST/SHOULD/MAY definitions
Verifiability:     â—Ž Uniquely identified by RFC number and section number
Accessibility:     â—Ž Published in RFC XML format, free access
```

#### Level 2: Industry Standards & De facto (SHOULD Comply)

Widely adopted standards. Non-compliance causes **compatibility issues within the industry**. Key examples include:

| Category           | Reference        | Characteristics                     | MCP Value |
| ------------------ | ---------------- | ----------------------------------- | --------- |
| **API Design**     | OpenAPI Spec     | De facto standard for REST APIs     | High      |
| **Security**       | OWASP            | Web security best practices         | High      |
| **Authentication** | OAuth 2.0 / OIDC | De facto standard for authorization | High      |
| **Messaging**      | AsyncAPI         | Async API specification             | Medium    |

#### Level 3: Organization/Project Rules (Local Compliance)

Rules that should be unified within teams/projects. These are managed at a local scope:

| Type                 | Characteristics               | Management Method         |
| -------------------- | ----------------------------- | ------------------------- |
| **Coding Standards** | Project-specific styles       | Markdown / Linter configs |
| **ADR**              | Architecture decision records | Git-managed Markdown      |
| **CLAUDE.md**        | Claude-specific instructions  | Project root placement    |

#### Level 4: Best Practices (Recommended)

Recommendations based on experience. **Apply as appropriate to the situation**. These guide implementation when no standard applies:

| Type                  | Source           | Application Judgment      |
| --------------------- | ---------------- | ------------------------- |
| **Design Principles** | SOLID, DRY, KISS | Situational               |
| **Design Patterns**   | GoF, POSA        | When matching the problem |
| **Clean Code**        | Robert C. Martin | Within team agreement     |

## Chapter 4: AI Decision Flow

### 4.1 Decision Algorithm Based on Reference Sources

When implementing a feature or making a decision, AI should follow this hierarchical decision flow:

```mermaid
flowchart TB
    A[Implementation Request] --> B{Defined in<br/>international standard?}
    B -->|Yes| C[Follow standard<br/>MUST comply]
    B -->|No| D{Defined in<br/>industry standard?}
    D -->|Yes| E[Follow industry standard<br/>SHOULD comply]
    D -->|No| F{Defined in<br/>org rules?}
    F -->|Yes| G[Follow rules]
    F -->|No| H{Best practices<br/>exist?}
    H -->|Yes| I[Propose as recommendation]
    H -->|No| J[Defer to human judgment]

    C --> K[Implement with cited evidence]
    E --> K
    G --> K
    I --> L[Present options]
    J --> L
```

### 4.2 Output Templates

When providing answers, structure your response according to whether authoritative sources are available. Here is the template for cases where a reference source is found:

```markdown
## Answer

Status code 1006 for WebSocket Close frames indicates "Abnormal Closure."

### Evidence

- **Source**: RFC 6455, Section 7.4.1
- **Original Text**: "1006 is a reserved value and MUST NOT be set as a status code
  in a Close control frame by an endpoint. It is designated for use in
  applications expecting a status code to indicate that the connection
  was closed abnormally"
- **Requirement Level**: MUST NOT (must not be set in implementation)

### Notes

This code is for applications to detect abnormal termination and
cannot be sent in actual Close frames.
```

When no authoritative reference source is available, use this template to transparently acknowledge the limitation:

```markdown
## Answer

I could not identify an authoritative reference source for this matter.

### Information Sources Checked

- RFC 6455: No relevant description found
- W3C WebSocket API: No relevant description found

### Speculation

As a general implementation practice, there is a tendency to~, but
this is not defined by any standard.

### Recommendation

If precise specifications are needed, I recommend checking~.
```

## Chapter 5: Design Requirements for Reference Source MCPs

### 5.0 Separation of MCP and Skills

MCP and Skills are both means to achieve "authoritative reference sources", but they serve different purposes:

| Aspect              | MCP                                        | Skills                              |
| ------------------- | ------------------------------------------ | ----------------------------------- |
| **Target**          | External authoritative information sources | Domain knowledge & best practices   |
| **Examples**        | RFC, Laws, W3C standards                   | Design principles, Coding standards |
| **Characteristics** | Dynamic access, via API                    | Static reference, Markdown format   |
| **Updates**         | Dependent on external systems              | Team-driven updates                 |

> For details, see [skills/vs-mcp.md](../skills/vs-mcp.md).

### 5.1 Required Functions

MCPs should provide these core functions to enable comprehensive access to reference sources:

| Function                    | Description                                | Example                         |
| --------------------------- | ------------------------------------------ | ------------------------------- |
| **Search**                  | Keyword search within specifications       | "WebSocket close frame"         |
| **Structure Retrieval**     | Chapter/section hierarchy                  | Table of contents for RFC 6455  |
| **Requirements Extraction** | Extract MUST/SHOULD/MAY                    | List of normative requirements  |
| **Term Definitions**        | Get definitions of technical terms         | Definition of "Origin"          |
| **Reference Relationships** | Dependencies on other specifications       | RFC 6455 â†’ RFC 2616             |
| **Checklist Generation**    | Generate implementation verification items | Client implementation checklist |
| **Validation**              | Check if implementation complies with spec | Statement validation            |

### 5.2 RFC MCP Tool Design

The following TypeScript interface illustrates the structure of an RFC MCP implementation:

```typescript
interface RfcMcpTools {
	// Search & Retrieval
	searchRfc(keyword: string): RfcSummary[];
	getRfcStructure(rfcNumber: number): Section[];
	getRfcSection(rfcNumber: number, section: string): Content;

	// Requirements Extraction
	getRequirements(rfcNumber: number, level?: RequirementLevel): Requirement[];
	getDefinitions(rfcNumber: number, term?: string): Definition[];

	// Relationships
	getDependencies(rfcNumber: number): Dependency[];
	getRelatedSections(rfcNumber: number, section: string): RelatedSection[];

	// Implementation Support
	generateChecklist(rfcNumber: number, role: 'client' | 'server'): Checklist;
	validateStatement(rfcNumber: number, statement: string): ValidationResult;
}
```

## Chapter 6: Concrete Example â€” Electronic Signature Act Ã— RFC 3161

### 6.1 Mapping Legal Requirements to Technical Specifications

```mermaid
graph TB
    subgraph Electronic Signature Act Article 2
        A1["Requirement 1: Proof of Creator<br/>Demonstrates that the information<br/>was created by the person<br/>who performed the measure"]
        A2["Requirement 2: Tampering Detection<br/>Enables confirmation of whether<br/>the information has been altered"]
    end

    subgraph RFC3161
        B1["MessageImprint<br/>Data identity proof<br/>via hash value"]
        B2["TSA Signature<br/>Existence proof at<br/>trusted time"]
        B3["TSTInfo<br/>genTime: Time<br/>serialNumber: Unique ID"]
    end

    A2 -->|Technical Implementation| B1
    A1 -->|Time Proof| B2
    B1 --> B3
    B2 --> B3
```

### 6.2 Verification Workflow via MCP Integration

```mermaid
sequenceDiagram
    participant User as User
    participant AI as Claude + MCPs
    participant Hourei as hourei-mcp
    participant RFC as rfcxml-mcp

    User->>AI: Is my timestamp implementation<br/>compliant with the Electronic Signature Act?
    AI->>Hourei: Get Electronic Signature Act Article 2
    Hourei-->>AI: Legal requirements
    AI->>RFC: Get RFC 3161 requirements
    RFC-->>AI: Technical requirements (75 MUSTs)
    AI->>AI: Map legal requirements â†”<br/>technical requirements
    AI-->>User: Compliance report<br/>+ Checklist
```

## Chapter 7: Resolving Reference Source Conflicts

### 7.1 Conflict Resolution Rules

1. **Higher levels take priority** - Laws > Industry standards > Organization rules
2. **Newer versions take priority** - RFC 9110 > RFC 7230 (obsolete)
3. **More specific specifications take priority** - WebSocket RFC > General TCP specifications
4. **When contradictions exist, defer to human judgment**

### 7.2 Example: HTTP Specification References

```
âŒ RFC 2616 (HTTP/1.1 - obsolete)
âœ… RFC 9110 (HTTP Semantics - current)
âœ… RFC 9111 (HTTP Caching - current)
```

## Chapter 8: List of Built Reference Source MCPs

| MCP            | Target                        | Main Functions                                                     | Repository                                          |
| -------------- | ----------------------------- | ------------------------------------------------------------------ | --------------------------------------------------- |
| **rfcxml-mcp** | IETF RFC                      | Structure retrieval, requirements extraction, checklist generation | [GitHub](https://github.com/shuji-bonji/rfcxml-mcp) |
| **w3c-mcp**    | W3C/WHATWG/IETF Web Standards | WebIDL, CSS, HTML elements                                         | [GitHub](https://github.com/shuji-bonji/w3c-mcp)    |
| **hourei-mcp** | Japanese Laws (e-Gov)         | Law search, article retrieval                                      | [GitHub](https://github.com/ryoooo/e-gov-law-mcp)   |

## Chapter 9: Future Expansion Candidates

### High Priority

| Candidate       | Target            | Value                                      |
| --------------- | ----------------- | ------------------------------------------ |
| **OpenAPI MCP** | OpenAPI Spec      | API design standards compliance            |
| **OWASP MCP**   | OWASP Top 10 etc. | Security requirements checking             |
| **OAuth MCP**   | OAuth 2.0 / OIDC  | Authentication flow implementation support |

### Medium Priority

| Candidate        | Target            | Value                             |
| ---------------- | ----------------- | --------------------------------- |
| **ISO MCP**      | ISO Standards     | International standards reference |
| **PDF Spec MCP** | ISO 32000         | PDF specification reference       |
| **BIM/IFC MCP**  | buildingSMART IFC | Building information model        |
| **HL7 FHIR MCP** | HL7 FHIR          | Healthcare information exchange   |

## Summary

### Core Messages

1. **AI "fluctuates"** - Probabilistic generation, training data constraints, lack of authority
2. **"Authoritative reference sources" are needed** - Authoritativeness, immutability, structuredness, verifiability, accessibility
3. **Organize hierarchically** - International standards > Industry standards > Organization rules > Best practices
4. **Connect to external information sources via MCP** - Provide RFC, laws, W3C standards in a format AI can reference
5. **Systematize domain knowledge with Skills** - Share team know-how in reusable formats
6. **Always cite evidence** - Show source, section, and original text

### The Value of "Authoritative Reference Sources"

```mermaid
graph LR
    subgraph Before["Without MCP"]
        Q1["Is what the AI says<br/>true?"]
        A1["Unknown"]
    end

    subgraph After["With MCP"]
        Q2["Is what the AI says<br/>true?"]
        A2["Can be verified in<br/>RFC 6455 Section 7.4.1"]
    end

    Before -->|MCP Introduction| After

    style A1 fill:#ff9999,color:#333
    style A2 fill:#90EE90,color:#333
```

**By providing authoritative reference sources for AI decisions, output reliability and verifiability are ensured.**

---

## MCP/A2A/Skill/Agent Architecture

Source: https://shuji-bonji.github.io/ai-agent-architecture/concepts/03-architecture/

# MCP/A2A/Skill/Agent Architecture

> Understanding the components of AI-driven development infrastructure and organizing their roles and relationships.

## Layer Structure Overview

The architecture is organized into four distinct layers, each with specific responsibilities, as shown in the following diagram:

```mermaid
block-beta
    columns 1

    USER["User Request"]:1

    block:AGENT_LAYER:1
        columns 1
        AGENT["Agent Layer\nTask Understanding / Orchestration Decisions / Result Synthesis"]
    end

    block:SKILL_LAYER:1
        columns 1
        SKILL["Skills Layer\nDomain Knowledge / Best Practices & Guidelines / Decision Criteria"]
    end

    block:MCP_LAYER:1
        columns 1
        MCP["MCP Layer\nExternal API Access / Tool Execution / Data Retrieval"]
    end

    EXTERNAL["External Services (DeepL, RFC Editor, GitHub, etc.)"]:1

    USER --> AGENT
    MCP --> EXTERNAL

    style AGENT fill:#87CEEB,color:#333,stroke:#333
    style SKILL fill:#90EE90,color:#333,stroke:#333
    style MCP fill:#FFB6C1,color:#333,stroke:#333
```

### Layer Responsibilities

Each layer has distinct ownership and responsibility areas:

| Layer      | Responsibility                 | Owns             | Examples                                 |
| ---------- | ------------------------------ | ---------------- | ---------------------------------------- |
| **Agent**  | Orchestration, decision-making | Task flow        | Claude Code, Cursor                      |
| **Skills** | Domain knowledge, guidelines   | Best practices   | SOLID principles, translation guidelines |
| **MCP**    | External connectivity          | Tool definitions | deepl-mcp, rfcxml-mcp                    |

## About This Document

AI-driven development involves multiple components, and correctly understanding their roles and relationships is key to efficient development. This document organizes four main concepts: MCP (tool connectivity), A2A (agent-to-agent communication), Skill (static knowledge), and Custom Sub-agents (role specialization).

When you are unsure about "What should be implemented as MCP?", "When is a Skill sufficient?", or "When should I use a sub-agent?", refer to this document to make the appropriate choice.

## Overall Architecture

The following diagram shows how all components interact within the complete system architecture:

```mermaid
flowchart TB
    USER["User"]

    subgraph HOST_LAYER["Host Layer"]
        HOST["Host<bn>(Claude Code / Claude.ai)"]
        SKILL["Skills<bn>(Static Knowledge)"]
    end

    subgraph AGENT_LAYER["Agent Layer"]
        MAIN["Main Agent"]
        SUB["Sub Agent"]
    end

    subgraph PROTOCOL_LAYER["Protocol Layer"]
        MCP_CLIENT["MCP Client"]
        A2A_CLIENT["A2A Client"]
    end

    subgraph EXTERNAL_LAYER["External Services Layer"]
        MCP_SERVER["MCP Servers"]
        A2A_AGENT["External A2A Agents"]
    end

    USER --> HOST
    HOST --> SKILL
    HOST --> MAIN
    MAIN --> SUB
    MAIN --> MCP_CLIENT
    MAIN --> A2A_CLIENT
    SUB --> MCP_CLIENT
    MCP_CLIENT --> MCP_SERVER
    A2A_CLIENT --> A2A_AGENT

    style SKILL fill:#90EE90,color:#333,stroke:#333
    style MCP_SERVER fill:#FFB6C1,color:#333,stroke:#333
    style A2A_AGENT fill:#87CEEB,color:#333,stroke:#333
```

## MCP Three-Layer Structure

### Host / Client / Server

MCP is built on a three-layer architecture, where communication flows through the client layer:

```mermaid
block-beta
    columns 1

    block:HOST_BLOCK:1
        HOST["Host (Host Application)\nUser Interface / Session Management"]
    end

    block:CLIENT_BLOCK:1
        CLIENT["Client (MCP Client)\nServer Discovery / Protocol Processing"]
    end

    block:SERVER_BLOCK:1
        SERVER["Server (MCP Server)\nTool/Resource Provider / Processing"]
    end

    HOST --> CLIENT
    CLIENT --"JSON-RPC"--> SERVER

    style HOST fill:#87CEEB,color:#333,stroke:#333
    style CLIENT fill:#FFE4B5,color:#333,stroke:#333
    style SERVER fill:#FFB6C1,color:#333,stroke:#333
```

| Layer      | Role                                   | Example                      | Developer Involvement |
| ---------- | -------------------------------------- | ---------------------------- | --------------------- |
| **Host**   | UI, session management                 | Claude Code, Cursor, VS Code | Consumer              |
| **Client** | Protocol processing, server management | Built into Host              | Usually not concerned |
| **Server** | Tool/resource provision                | rfcxml-mcp, deepl-mcp        | **Provider**          |

### Why You Don't Need to Worry About the Client

For most developers, the client layer operates transparently as part of the host:

```
Typical development flow:
1. Create an MCP Server (e.g., rfcxml)
2. Add it to Claude Code configuration
3. Claude Code operates as a built-in Client
4. Tools become available

â†’ The Client is embedded in the Host and
   functions as a black box
```

## MCP and A2A: Separation of Concerns

### Protocol Differences

While MCP and A2A serve different purposes, they are complementary and address different communication needs:

```mermaid
graph TB
    subgraph MCP["MCP (Model Context Protocol)"]
        MCP_DESC["Agent â†” Tool"]
        MCP_EXAMPLE["Example: Claude â†’ rfcxml-mcp"]
    end

    subgraph A2A["A2A (Agent-to-Agent Protocol)"]
        A2A_DESC["Agent â†” Agent"]
        A2A_EXAMPLE["Example: Internal Agent â†’ Salesforce Agent"]
    end

    MCP -->|Complementary| A2A
```

| Item            | MCP                         | A2A                                  |
| --------------- | --------------------------- | ------------------------------------ |
| **Led by**      | Anthropic                   | Google â†’ Linux Foundation            |
| **Purpose**     | Tool connectivity           | Agent-to-agent communication         |
| **Connects to** | MCP Server (tools)          | Other agents (including third-party) |
| **Context**     | Can share with parent agent | Completely isolated                  |
| **Owner**       | Self                        | Self or **others**                   |

### Official Recommendation

> Build with ADK, equip with **MCP** (tools), communicate with **A2A** (agents)

```
MCP = Using hands (tools)
A2A = Collaborating with others (agents)
```

## Custom Sub-agents

### What is a Sub-agent?

An **AI assistant specialized for specific tasks** that can be defined within Claude Code.

```
Location:
â”œâ”€â”€ Project: .claude/agents/xxx.md (Priority: High)
â””â”€â”€ User:    ~/.claude/agents/xxx.md (Priority: Low)
```

### Definition Format

Sub-agents are defined using a simple markdown format that specifies their role, capabilities, and instructions:

```markdown
name: rfc-specialist
description: Expert in RFC specification verification and validation
tools: rfcxml:get_rfc_structure, rfcxml:get_requirements
model: sonnet

You are an expert in RFC specifications.
Use only the rfcxml tools.
```

### Sub-agent Positioning

The following diagram illustrates where sub-agents sit within the Claude Code architecture:

```mermaid
flowchart TB
    subgraph CLAUDE_CODE["Claude Code"]
        USER["User"]
        MAIN["Main Claude<bn>(Orchestrator)"]
        SUBAGENT["Custom Sub Agent<bn>(.claude/agents/)"]
        MCP_CLIENT["MCP Client<bn>(Built into Claude Code)"]

        USER --> MAIN
        MAIN --"Delegate"--> SUBAGENT
        SUBAGENT --"Use"--> MCP_CLIENT
        MAIN --"Direct Use"--> MCP_CLIENT
    end

    MCP_SERVERS["MCP Servers<bn>rfcxml, deepl, etc."]

    MCP_CLIENT --"JSON-RPC"--> MCP_SERVERS

    style MCP_CLIENT fill:#FFB6C1,color:#333,stroke:#333
    style SUBAGENT fill:#90EE90,color:#333,stroke:#333
    style MCP_SERVERS fill:#E8E8E8,color:#333,stroke:#333
```

**Important**: Sub-agents are not a "replacement" for the MCP Client, but rather a "higher layer"

- **Sub-agent** = Defines "what to do" (role, procedures)
- **MCP Client** = Implements "how to connect" (protocol processing)

## Skill

### What is a Skill?

**Static knowledge and guidelines** that can be referenced in Claude Code. Skills are stored in the following locations:

```
Location:
â”œâ”€â”€ Project: .claude/skills/xxx/SKILL.md
â””â”€â”€ User:    ~/.claude/skills/xxx/SKILL.md
```

### Skill Characteristics

Skills have these key characteristics that distinguish them from other approaches:

| Item                    | Description                                      |
| ----------------------- | ------------------------------------------------ |
| **Format**              | Markdown file                                    |
| **Content**             | Best practices, workflow definitions, guidelines |
| **Execution**           | None (reference only)                            |
| **Context consumption** | Low (only when referenced)                       |

## MCP vs Skill vs Sub-agent

### Decision Flow

Use this flowchart to determine whether to implement something as a Skill, MCP, or Sub-agent:

```mermaid
graph TB
    Q1{External API/dynamic<br/>processing needed?}
    Q1 -->|Yes| MCP[Use MCP]
    Q1 -->|No| Q2{Complex processing<br/>logic needed?}
    Q2 -->|Yes| MCP
    Q2 -->|No| Q3{Role/expertise<br/>separation needed?}
    Q3 -->|Yes| AGENT[Use Sub-agent]
    Q3 -->|No| SKILL[Use Skill]

    style MCP fill:#FFB6C1,color:#333
    style SKILL fill:#90EE90,color:#333
    style AGENT fill:#87CEEB,color:#333
```

### Comparison Table

| Aspect                  | Skill                | MCP                  | Sub-agent                 |
| ----------------------- | -------------------- | -------------------- | ------------------------- |
| **Context consumption** | Low                  | High                 | Medium                    |
| **Dynamic processing**  | Not possible         | Possible             | Possible                  |
| **External API**        | Not possible         | Possible             | Via MCP                   |
| **Maintenance**         | Markdown editing     | npm publish, etc.    | Markdown editing          |
| **Reusability**         | Within project       | Global               | Within project            |
| **Use case**            | Knowledge/guidelines | Tool/API integration | Role/expertise separation |

### Principles for Choosing

```
Skill = "Knowledge", "Guidelines", "Workflow definitions"
MCP   = "Tools", "API integration", "Dynamic processing"
Sub-agent = "Roles", "Expertise", "Task delegation"

Use Skills to define "what should be done"
Use MCP to provide "how to execute it"
Use Sub-agents to separate "who does it"
```

## A2A vs Sub-agent

### Fundamental Differences

| Aspect                      | Custom Sub-agent             | A2A Agent                             |
| --------------------------- | ---------------------------- | ------------------------------------- |
| **Location**                | Within same process          | Over the network                      |
| **Owner**                   | Self                         | Self or **others**                    |
| **Trust**                   | Full trust                   | Authentication/authorization required |
| **Context**                 | Partially shared with parent | Completely isolated                   |
| **Lifecycle**               | Session-limited              | Persistent service                    |
| **Internal implementation** | Visible (Markdown)           | Not visible (API contract only)       |

### Analogy

```
Custom Sub-agent = "Internal specialized department"
A2A Agent        = "Outsourcing partner / Partner company"

Even with internal specialized departments, outsourcing partners are needed
Even with outsourcing partners, internal specialized departments are needed

â†’ Both are necessary; they are not substitutes for each other
```

### When to Use Which

| Scenario                                          | What to Use |
| ------------------------------------------------- | ----------- |
| Want to use your own MCP expertly                 | Sub-agent   |
| Want to reuse the same processing repeatedly      | Sub-agent   |
| Want to define a workflow                         | Sub-agent   |
| Integrate with third-party agents                 | A2A         |
| Expose your agent externally                      | A2A         |
| Agent collaboration across multiple organizations | A2A         |

## Executor Selection

Beyond choosing MCP / Skill / Sub-agent, the perspective of **"who makes the decision"** becomes crucial.

### Evolution of Execution

The way we integrate with external services has evolved with technology.

```mermaid
flowchart LR
    subgraph PAST["Past"]
        direction TB
        HUMAN["Human\n(CLI)"]
        API1["API"]
        HUMAN --> API1
    end

    subgraph PRESENT["Present"]
        direction TB
        AI["AI\n(via MCP)"]
        API2["API"]
        AI --> API2
    end

    subgraph FUTURE["Future"]
        direction TB
        AGENT["Agent\n(Autonomous)"]
        API3["API"]
        AGENT --> API3
    end

    PAST -.-> PRESENT -.-> FUTURE

    style HUMAN fill:#E8E8E8,color:#333,stroke:#333
    style AI fill:#FFE4B5,color:#333,stroke:#333
    style AGENT fill:#87CEEB,color:#333,stroke:#333
```

In this evolution, **not everything needs to be MCP-ified**.
The appropriate layer is determined by "who makes the decision".

### Layer Selection by Decision Maker

Choose the implementation layer based on who makes the decision:

| Decision Maker                 | Appropriate Layer | Characteristics                     | Examples                                    |
| ------------------------------ | ----------------- | ----------------------------------- | ------------------------------------------- |
| **None** (Deterministic)       | Direct program    | No judgment needed, fast, reliable  | Batch processing, CI/CD, cron               |
| **Human**                      | CLI               | Human decides, AI doesn't execute   | `gh pr list`, `aws s3 ls`                   |
| **AI** (One-shot)              | MCP + Skill       | AI decides and executes per request | Translation, RFC lookup, quality evaluation |
| **AI** (Continuous/Autonomous) | Sub-agent         | Autonomous decisions with expertise | Review specialist, translation specialist   |

### Decision Flow

This comprehensive flowchart guides the selection process from initial request through final implementation:

```mermaid
flowchart TD
    START[Capability needed] --> Q0{Who decides?}

    Q0 -->|No decision needed<br/>Deterministic| PG[Execute directly in program]
    Q0 -->|Human decides| HUMAN{Official CLI exists?}
    Q0 -->|AI decides| AI{Complexity & continuity?}

    HUMAN -->|Yes| CLI[Use CLI]
    HUMAN -->|No| SCRIPT[Script/Direct API]

    AI -->|One-shot, simple| MCP_SKILL[MCP + Skill]
    AI -->|Continuous, autonomous| SUBAGENT[Sub-agent]

    MCP_SKILL --> Q2{CLI exists?}
    Q2 -->|Yes| CLI_SKILL[CLI + Skill<br/>Token efficient â—Ž]
    Q2 -->|No| MCP_BUILD[Build MCP]

    style PG fill:#E8E8E8,color:#333
    style CLI fill:#FFE4B5,color:#333
    style CLI_SKILL fill:#90EE90,color:#333
    style MCP_BUILD fill:#FFB6C1,color:#333
    style SUBAGENT fill:#87CEEB,color:#333
```

### CLI vs MCP: When AI Makes the Decision

> **Key Insight**: When an official CLI exists, **CLI + Skill** is more efficient than building an MCP
>
> _â€” From r/ClaudeAI community discussion_

When both a CLI and an MCP are possible options, use this comparison table to choose the more efficient approach:

| Aspect                | CLI + Skill          | MCP                               |
| --------------------- | -------------------- | --------------------------------- |
| **Token consumption** | Low (command only)   | High (loads all tool definitions) |
| **Startup cost**      | None                 | Requires server process           |
| **Authentication**    | Local                | Managed by MCP                    |
| **Purpose-built**     | â—Ž (Dedicated design) | â–³ (General purpose)               |

#### Examples

These examples illustrate the decision for popular services:

| Service      | CLI      | Recommendation |
| ------------ | -------- | -------------- |
| GitHub       | `gh`     | CLI + Skill    |
| AWS          | `aws`    | CLI + Skill    |
| Google Cloud | `gcloud` | CLI + Skill    |
| PostgreSQL   | `psql`   | CLI + Skill    |
| Linear       | âŒ       | MCP            |
| Greptile     | âŒ       | MCP            |
| DeepL        | âŒ       | MCP            |

### Key Insight

The fundamental principle for layer selection is:

```
Selection changes based on "who decides", not just "what to execute"

No decision needed  â†’ Direct program
Human decides       â†’ CLI
AI decides          â†’ MCP or CLI + Skill
AI autonomous       â†’ Sub-agent
```

With this perspective, you can avoid over-MCPization and implement at the appropriate layer.

## Combination Patterns

### The Most Powerful Combination

The most effective approach combines all three components working together:

```mermaid
graph LR
    SKILL[Skill<br/>Workflow Definition] -->|"Reference"| AGENT[Sub-agent]
    AGENT -->|"Execute"| MCP[MCP<br/>Tools]

    style SKILL fill:#90EE90,color:#333
    style MCP fill:#FFB6C1,color:#333
    style AGENT fill:#87CEEB,color:#333
```

### Concrete Example: Translation Workflow

Here is a practical example showing how Skill, Sub-agent, and MCP work together:

```markdown
<!-- skills/translation-workflow/SKILL.md -->

# Technical Document Translation Workflow

## MCP Tools Used

- `deepl` - Translation execution
- `xcomet` - Quality evaluation

## Workflow

1. Translate with deepl:translate-text (formality: "more")
2. Evaluate with xcomet:xcomet_evaluate
   - Score 0.85 or higher: OK
   - Score below 0.85: Re-translate or manual correction
3. Detect errors with xcomet:xcomet_detect_errors
```

```markdown
<!-- agents/translation-specialist.md -->

name: translation-specialist
description: Specialized agent for technical document translation and quality evaluation
tools: deepl:translate-text, xcomet:xcomet_evaluate, xcomet:xcomet_detect_errors
model: sonnet

You are an expert in technical translation.
Please refer to the translation-workflow skill.
```

## Sequence Diagrams: Visualizing Execution Flow

Sequence diagrams help visualize how components interact during task execution.

### Code Review Task

Here is how a code review task flows through the system:

```mermaid
sequenceDiagram
    participant U as User
    participant M as Main Agent
    participant S as Skill<br/>(Code Review)
    participant MCP as MCP Server<br/>(ESLint)

    U->>M: "Review this PR"
    M->>S: Reference guidelines
    S-->>M: Review perspectives & checklist
    M->>MCP: Run lint
    MCP-->>M: Violation list
    M->>U: Review result report
```

### Translation Workflow

Here is the sequence for a translation task with quality evaluation:

```mermaid
sequenceDiagram
    participant U as User
    participant M as Main Agent
    participant S as Skill<br/>(Translation Guidelines)
    participant D as MCP Server<br/>(DeepL)
    participant X as MCP Server<br/>(xCOMET)

    U->>M: "Translate this document"
    M->>S: Reference translation rules
    S-->>M: Tone & terminology rules
    M->>D: translate-text
    D-->>M: Translation result
    M->>X: xcomet_evaluate
    X-->>M: Quality score
    alt Score < 0.85
        M->>D: Re-translate (adjust parameters)
        D-->>M: Improved translation
    end
    M->>U: Final translation result
```

## Layer Structure Summary

The following layered structure shows how all components integrate:

```mermaid
block-beta
    columns 1

    USER["User"]:1
    HOST["Host (Claude Code / Claude.ai)"]:1
    SKILLS["Skills (Static Knowledge & Guidelines)"]:1
    MAIN["Main Agent â† Orchestration"]:1
    SUBAGENT["Custom Sub-agents â† Role & Expertise Definition"]:1
    PROTOCOL["MCP Client / A2A Client â† Protocol Processing"]:1
    EXTERNAL["MCP Servers / External A2A Agents â† Tools & External Services"]:1

    USER --> HOST
    HOST --> SKILLS
    SKILLS --> MAIN
    MAIN --> SUBAGENT
    SUBAGENT --> PROTOCOL
    PROTOCOL --> EXTERNAL

    style HOST fill:#87CEEB,color:#333,stroke:#333
    style SKILLS fill:#90EE90,color:#333,stroke:#333
    style MAIN fill:#FFE4B5,color:#333,stroke:#333
    style SUBAGENT fill:#87CEEB,color:#333,stroke:#333
    style PROTOCOL fill:#FFB6C1,color:#333,stroke:#333
    style EXTERNAL fill:#E8E8E8,color:#333,stroke:#333
```

---

## AI Design Patterns and the Role of MCP

Source: https://shuji-bonji.github.io/ai-agent-architecture/concepts/04-ai-design-patterns/

# AI Design Patterns and the Role of MCP

> As AI systems have advanced, how has the industry addressed the LLM's "knowledge limitations"? Where does MCP fit in, and what makes it different?

## About This Document

Implementing generative AI (LLM) in practical systems requires more than the capabilities of the model alone. AI knowledge has inherent limitations (see [01-vision.md](./01-vision.md)), and various design patterns have emerged to overcome them.

This document provides an overview of major design patterns and carefully explains the differences between RAG (Retrieval-Augmented Generation) and MCP. The goal is to answer questions like "What's the difference between RAG and MCP?" and "Why does this project choose MCP?"

## Chapter 1: LLM's "Knowledge Limitations" â€” Why External Knowledge is Needed

LLMs are probabilistic generative models trained on massive amounts of text data. They possess remarkably broad knowledge, but have clear limitations (see Chapter 1 of [02-reference-sources.md](./02-reference-sources.md) for details).

```
LLM Knowledge
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… Pre-trained knowledge (vast but fixed) â”‚
â”‚     - General knowledge, programming, languages â”‚
â”‚     - Information up to training cutoff       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âŒ Knowledge it lacks                  â”‚
â”‚     - Information after training cutoff     â”‚
â”‚     - Internal documents and proprietary data â”‚
â”‚     - Rare specialized knowledge (obscure RFC details) â”‚
â”‚     - Real-time information                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Various design patterns have been devised to address this "missing knowledge."

## Chapter 2: Major AI Design Patterns

### 2.1 Overview of Patterns

Here's a summary of the major design patterns for addressing LLM knowledge limitations.

```mermaid
mindmap
  root((Patterns to Address<br/>LLM Knowledge Limitations))
    External Knowledge Injection
      RAG
        Vector Search
        Chunking
      MCP
        Structured APIs
        Tool Calling
      GraphRAG
        Knowledge Graph
    Model Enhancement
      Fine-tuning
        Additional Training
        Domain Specialization
    Input Optimization
      Prompt Engineering
        Few-shot
        Chain-of-Thought
    Autonomous Behavior
      Agentic AI
        Planning and Execution
        Tool Usage
```

### 2.2 Overview of Each Pattern

#### RAG (Retrieval-Augmented Generation)

A technique that searches external documents and injects relevant information into the LLM's prompt. Rather than modifying the LLM itself, it combines "retrieval + generation."

```mermaid
flowchart LR
    subgraph PrepPhase["Preparation Phase"]
        D[Documents] --> C[Chunk Splitting]
        C --> E[Vectorization<bn>Embedding]
        E --> V[(Vector DB)]
    end

    subgraph ExecPhase["Execution Phase"]
        Q[User Question] --> QE[Vectorization]
        QE --> S[Similarity Search]
        V --> S
        S --> R[Retrieve Relevant Chunks]
        R --> P[Build Prompt<bn>Question + Search Results]
        P --> L[LLM]
        L --> A[Generate Answer]
    end
```

**Key Point**: The core of RAG is searching information using "vector similarity." Documents are split into small fragments (chunks), and fragments semantically closest to the question are retrieved and passed to the LLM.

| Characteristic     | Description                                                    |
| ------------------ | -------------------------------------------------------------- |
| **Target**         | Unstructured text (documents, FAQs, internal wikis, etc.)      |
| **Search Method**  | Vector similarity search (semantic search)                     |
| **Pre-processing** | Document chunking â†’ Vectorization â†’ DB storage                 |
| **Strengths**      | Can find relevant information from large document collections  |
| **Weaknesses**     | Context is lost through chunking, doesn't understand structure |

#### MCP (Model Context Protocol)

A standard protocol developed by Anthropic for connecting AI models with external tools and services. It enables AIs to access external data through structured APIs and execute actions.

```mermaid
flowchart LR
    subgraph MCPSystem["MCP"]
        Q2[User Question] --> A2[AI Decides]
        A2 --> T[Tool Call<bn>Example: get_requirements]
        T --> S2[MCP Server]
        S2 --> E2[External Service<bn>RFC / DeepL etc.]
        E2 --> R2[Structured Result]
        R2 --> G2[Generate Answer]
    end
```

**Key Point**: The core of MCP is accessing information through "structured APIs." Data is retrieved with understanding of domain structure (sections, requirement levels, cross-references, etc.).

| Characteristic     | Description                                        |
| ------------------ | -------------------------------------------------- |
| **Target**         | Structured data, APIs, external services           |
| **Access Method**  | Structured API calls (JSON-RPC)                    |
| **Pre-processing** | Not required (MCP server understands structure)    |
| **Strengths**      | Accurate data retrieval, verifiable, distributable |
| **Weaknesses**     | Requires MCP server development                    |

> **MCP Details**: See [mcp/what-is-mcp.md](../mcp/what-is-mcp.md).

#### Fine-tuning

A technique that performs additional training of LLM parameters on domain-specific data. It rewrites the model's "internal knowledge."

```
Base Model (GPT-4, Claude, etc.)
    â†“ + Additional training with domain-specific data
Customized Model
    â†“
Can answer with domain-specific knowledge
```

| Characteristic         | Description                                                            |
| ---------------------- | ---------------------------------------------------------------------- |
| **Target**             | Domain-specific knowledge and style                                    |
| **Modified Component** | Model parameters themselves                                            |
| **Cost**               | High (data preparation + computational resources)                      |
| **Strengths**          | Deep knowledge embedding in the model                                  |
| **Weaknesses**         | Difficult to update, complete elimination of hallucinations impossible |

#### Prompt Engineering

A technique that controls output quality through careful input prompt design without modifying model parameters.

```
Main techniques:
- Zero-shot:         Instruction only
- Few-shot:          Provide several examples
- Chain-of-Thought:  "Think step by step"
- System Prompt:     Pre-define role and constraints
```

| Characteristic         | Description                                        |
| ---------------------- | -------------------------------------------------- |
| **Target**             | Any task                                           |
| **Modified Component** | Input prompt only                                  |
| **Cost**               | Lowest                                             |
| **Strengths**          | Can try immediately, no model modification needed  |
| **Weaknesses**         | Cannot supplement knowledge the model doesn't have |

#### Agentic AI

A pattern where the LLM autonomously plans, calls tools, and solves problems through multiple steps. MCP is one of the foundational technologies supporting this pattern.

```mermaid
flowchart TB
    U[User Request] --> P[Plan]
    P --> E1[Step 1: Information Gathering]
    E1 --> E2[Step 2: Analysis]
    E2 --> E3[Step 3: Execution]
    E3 --> R[Integrate Results]
    R --> V{Verification}
    V -->|Insufficient| P
    V -->|OK| O[Final Answer]

    E1 -.->|MCP| T1[External Tools]
    E2 -.->|Skill| T2[Domain Knowledge]
    E3 -.->|MCP| T3[Execution Tools]
```

| Characteristic   | Description                                         |
| ---------------- | --------------------------------------------------- |
| **Target**       | Complex, multi-step tasks                           |
| **Operation**    | Autonomous planning â†’ execution â†’ verification loop |
| **Dependencies** | MCP (tool connection), Skills (knowledge reference) |
| **Strengths**    | Can automate complex tasks                          |
| **Weaknesses**   | Hard to predict, difficult to control in some cases |

> **Agent Details**: See [03-architecture.md](./03-architecture.md).

#### GraphRAG

A technique combining knowledge graphs with standard RAG to leverage relationships between entities.

```
Standard RAG:  Documents â†’ Chunks â†’ Vector Search
GraphRAG:      Documents â†’ Entity Extraction â†’ Build Relationship Graph â†’ Graph Search
```

| Characteristic | Description                                             |
| -------------- | ------------------------------------------------------- |
| **Target**     | Data where relationships between entities are important |
| **Strengths**  | Strong at "How does A relate to B?"                     |
| **Weaknesses** | High cost of graph construction                         |

### 2.3 Pattern Comparison Table

| Pattern                | Problem Solved                           | Modified Component | Cost        | Real-time                             |
| ---------------------- | ---------------------------------------- | ------------------ | ----------- | ------------------------------------- |
| **RAG**                | Knowledge completion                     | Prompt             | Medium      | â–³ (depends on index update frequency) |
| **MCP**                | Tool connection, accurate data retrieval | Prompt             | Medium-High | â—Ž (Real-time)                         |
| **Fine-tuning**        | Domain specialization                    | Model parameters   | High        | âœ— (retraining needed)                 |
| **Prompt Engineering** | Output quality control                   | Prompt             | Low         | -                                     |
| **Agentic AI**         | Complex task automation                  | Architecture       | High        | â—Ž                                     |
| **GraphRAG**           | Relationship understanding               | Prompt + Graph     | High        | â–³                                     |

### 2.4 Patterns Are Not Mutually Exclusive

These patterns **are not mutually exclusive; they can and should be combined**.

```mermaid
graph TB
    subgraph ActualSystem["Real System"]
        PE[Prompt Engineering<bn>Base Instructions]
        RAG_COMP[RAG<bn>Internal Document Search]
        MCP_COMP[MCP<bn>Standard Specification Reference]
        AGENT[Agentic AI<bn>Orchestration]
    end

    PE --> AGENT
    RAG_COMP --> AGENT
    MCP_COMP --> AGENT

    AGENT --> OUTPUT[High Quality Output]
```

For example, a system where Agentic AI receives appropriate instructions through Prompt Engineering, searches internal documents through RAG as needed, and confirms standard specifications through MCP is entirely plausible.

## Chapter 3: Deep Dive into RAG

### 3.1 How RAG Works

RAG is a technique published in 2020 by Meta's (formerly Facebook's) research team and is the most popular pattern for providing external knowledge to LLMs.

#### Step 1: Index Building (Offline)

```
Original Document:
  "RFC 6455 defines the WebSocket protocol.
   Section 5.5.1 specifies the format of Close frames,
   Section 7.4.1 defines status codes.
   1006 indicates abnormal closure and
   MUST NOT be included in Close frames."

    â†“ Chunk Splitting

Chunk 1: "RFC 6455 defines the WebSocket protocol.
         Section 5.5.1 specifies the format of Close frames"
Chunk 2: "Section 7.4.1 defines status codes.
         1006 indicates abnormal closure"
Chunk 3: "MUST NOT be included in Close frames."

    â†“ Vectorization (Embedding)

Chunk 1 â†’ [0.12, -0.34, 0.56, ...]  â† Numerical vector, hundreds to thousands of dimensions
Chunk 2 â†’ [0.23, -0.11, 0.78, ...]
Chunk 3 â†’ [0.45, -0.67, 0.12, ...]

    â†“ Store in Vector DB
```

#### Step 2: Search and Generation (Online)

```
User Question: "What does WebSocket status code 1006 mean?"

    â†“ Vectorize Question

Question Vector â†’ [0.21, -0.15, 0.72, ...]

    â†“ Similarity Search (Cosine Similarity, etc.)

Closest Chunk â†’ Chunk 2:
  "Section 7.4.1 defines status codes.
   1006 indicates abnormal closure"

    â†“ Inject into Prompt

"Please answer the question using the following information.
 ---
 Section 7.4.1 defines status codes.
 1006 indicates abnormal closure
 ---
 Question: What does WebSocket status code 1006 mean?"

    â†“ LLM Generates Answer
```

### 3.2 RAG Strengths and Typical Use Cases

Here are the scenarios where RAG is particularly effective.

| Use Case                     | Description                                                       | Example                      |
| ---------------------------- | ----------------------------------------------------------------- | ---------------------------- |
| **Internal Document Search** | Retrieve information from large amounts of internal documentation | Internal Wiki, Manuals, FAQs |
| **Customer Support**         | Generate answers from product knowledge base                      | Help Center, Chatbots        |
| **Academic Research**        | Extract relevant information from paper databases                 | Literature review support    |
| **Legal Support**            | Similarity search of contracts and case law                       | Finding similar clauses      |

**What RAG Excels At**: Finding information that is "semantically similar" from large amounts of unstructured text.

### 3.3 RAG Limitations

However, RAG has structural limitations.

#### Loss of Context Through Chunk Splitting

```
Original Context:
  "1006 indicates abnormal closure and
   MUST NOT be included in Close frames."

After Chunking:
  Chunk A: "1006 indicates abnormal closure"          â† Retrieved
  Chunk B: "MUST NOT be included in Close frames"     â† May not be retrieved

â†’ Risk of losing the important MUST NOT requirement
```

#### Insufficient Structure Understanding

```
What RAG Returns:
  "1006 indicates abnormal closure" (text fragment)

What RAG Cannot Return:
  - That this is defined in Section 7.4.1
  - That it is a MUST NOT level requirement
  - The relationship with Close frame format in Section 5.5.1
  - Its position in RFC 6455 as a whole
```

#### Search Precision Limitations

Vector similarity search returns things that are "semantically similar" but not necessarily "exactly matching."

```
Question: "What is the meaning of RFC 6455 status code 1002?"

Chunks that Might Be Returned:
  âœ… "1002 indicates a protocol error" (correct)
  âŒ "1006 indicates abnormal closure" (semantically similar, but not what was asked)
  âŒ "1000 indicates normal closure" (same category but different code)
```

## Chapter 4: Essential Differences Between RAG and MCP

### 4.1 Fundamental Difference in Approach

Both RAG and MCP "provide external knowledge to LLMs," but their approaches differ fundamentally.

```mermaid
flowchart TB
    subgraph RAG_APPROACH["RAG: Search by Text Similarity"]
        direction TB
        R1[Documents] --> R2[Chunk Splitting]
        R2 --> R3[Vectorization]
        R3 --> R4[Similarity Search]
        R4 --> R5["Fragmented Results<bn>(Risk of Context Loss)"]
    end

    subgraph MCP_APPROACH["MCP: Search by Domain Structure"]
        direction TB
        M1[Structured Data] --> M2[Domain Understanding]
        M2 --> M3["Structured Query<bn>get_requirements()"]
        M3 --> M4["Accurate Results<bn>+ Metadata"]
    end

    style RAG_APPROACH fill:#fff3e0,color:#333
    style MCP_APPROACH fill:#e8f5e9,color:#333
```

| Aspect               | RAG                                   | MCP                                             |
| -------------------- | ------------------------------------- | ----------------------------------------------- |
| **Search Principle** | Semantic similarity of text           | Precise query based on domain structure         |
| **Prerequisite**     | Can chunk documents                   | Exists an API that understands domain structure |
| **Result Nature**    | "Probably relevant" text fragments    | "Definitely applicable" structured data         |
| **Source Clarity**   | Ambiguous (hard to trace which chunk) | Clear (RFC 6455 Section 7.4.1, etc.)            |

### 4.2 Comparison by the 5 Characteristics of "Unshakeable References"

Comparing by the five characteristics of "unshakeable references" defined in [02-reference-sources.md](./02-reference-sources.md) makes the differences even clearer.

| Characteristic                       | RAG | MCP (Reference MCP) | Description                                                                           |
| ------------------------------------ | --- | ------------------- | ------------------------------------------------------------------------------------- |
| **Authority**                        | â–³   | â—Ž                   | RAG chunk origins are ambiguous. MCP accesses the original source directly            |
| **Immutability, Version Management** | â–³   | â—Ž                   | RAG depends on index update timing. MCP reflects original version management          |
| **Structuring**                      | âœ—   | â—Ž                   | RAG loses structure through chunking. MCP preserves sections and requirement levels   |
| **Verifiability**                    | â–³   | â—Ž                   | RAG makes it difficult to trace "which chunk generated this." MCP shows exact sources |
| **Accessibility**                    | â—‹   | â—Ž                   | Both are programmatically accessible, but MCP uses a standard protocol                |

### 4.3 Comparison with Concrete Examples

#### Example: "What is the meaning of Close code 1006 in RFC 6455?"

**With RAG:**

```
1. Pre-process RFC 6455 full text into chunks and store in vector DB
2. Vectorize question and search similar chunks
3. Returned chunk:
   "1006 is a reserved value and MUST NOT be set as a status code
    in a Close control frame by an endpoint."

Problems:
- Unclear that this chunk comes from Section 7.4.1
- Requirement level MUST NOT not attached as metadata
- Surrounding context (why MUST NOT) may be missing
- May return a different chunk (explanation of 1002, etc.)
```

**With rfcxml-mcp:**

```
1. Call get_requirements(rfc=6455, section="7.4.1")
2. Returned result:
   {
     section: "7.4.1",
     requirement: "1006 is a reserved value and MUST NOT be set
                   as a status code in a Close control frame
                   by an endpoint.",
     level: "MUST NOT",
     context: "It is designated for use in applications
               expecting a status code to indicate that
               the connection was closed abnormally"
   }

Benefits:
- Section number is clear (Section 7.4.1)
- Requirement level is structured (MUST NOT)
- Surrounding context is preserved
- Can even verify implementation compliance with validate_statement()
```

#### Example: "What are the requirements of Article 2 of the Electronic Signature Act?"

**With RAG:**

```
Chunk the entire law â†’ Search chunks related to "Article 2"
â†’ Law structure (articles, subsections, items) is lost
â†’ Risk of mixing pre-amendment and post-amendment versions
```

**With hourei-mcp (e-gov-law MCP):**

```
Call find_law_article(law_name="Electronic Signature Act", article_number="2")
â†’ Can retrieve the law text structure (subsections, items) intact
â†’ Get latest law data (real-time from e-Gov API)
```

### 4.4 Distribution Capability Difference

MCP has a decisive advantage: "it can be distributed as a standard protocol."

```
Sharing RAG Pipeline:
  1. Document preparation
  2. Implement chunking logic
  3. Select Embedding model
  4. Build and operate vector DB
  5. Tune search parameters
  â†’ Each organization must build independently

Sharing MCP Server:
  npx @shuji-bonji/rfcxml-mcp
  â†’ Anyone can get structured RFC access with just this
```

| Aspect                  | RAG                                  | MCP                                     |
| ----------------------- | ------------------------------------ | --------------------------------------- |
| **Distribution Method** | Independent construction required    | Can be distributed as npm package, etc. |
| **Deployment Cost**     | Vector DB construction + indexing    | Single configuration file               |
| **Quality Consistency** | Depends on builder's skills          | Developer ensures quality               |
| **Maintenance**         | Each organization handles separately | Developer updates centrally             |

## Chapter 5: MCP Servers in This Project vs RAG

### 5.1 "Isn't This Just RAG in Disguise?" Question

Looking at this project's related MCP servers (rfcxml-mcp, w3c-mcp, pdf-spec-mcp, epsg-mcp, etc.), one might think "searching external specifications and passing them to LLM" is the same as RAG.

However, there is a fundamental difference.

### 5.2 "Text Search" vs "Domain Knowledge Codification"

Each MCP server provides **an API that understands the target domain's structure and semantics**. This is not merely text search; it is **the codification of domain knowledge**.

| MCP Server         | Structure It Understands                                                                         | What RAG Loses                                                           |
| ------------------ | ------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------ |
| **rfcxml-mcp**     | Section hierarchy, MUST/SHOULD/MAY classification, RFC cross-references (obsoletes/updates)      | Distinction of requirement levels, relationships between sections        |
| **w3c-mcp**        | WebIDL definitions, CSS specification structure, HTML element attributes and content models      | Type information of interfaces, inheritance relationships of properties  |
| **pdf-spec-mcp**   | ISO 32000 chapter structure, requirement tables, term definitions                                | Table structure, differences between specification versions              |
| **epsg-mcp**       | Recommended uses of coordinate reference systems, transformation paths, accuracy characteristics | Spatial scope of applicability, transformation accuracy information      |
| **pdf-reader-mcp** | Internal object structure of PDFs, tag hierarchy, font information                               | Binary structure interpretation, reference relationships between objects |

### 5.3 Practical Differences

```mermaid
sequenceDiagram
    participant U as User
    participant AI as AI

    Note over U,AI: RAG Approach
    U->>AI: Tell me the implementation requirements for WebSocket
    AI->>AI: Retrieve related chunks via vector search
    AI-->>U: "According to RFC 6455..."<br/>(based on chunk fragments)<br/>âš ï¸ No guarantee of requirement completeness

    Note over U,AI: MCP Approach
    U->>AI: Tell me the implementation requirements for WebSocket
    AI->>AI: Call get_requirements(rfc=6455, role="client")
    AI->>AI: Call generate_checklist(rfc=6455, role="client")
    AI-->>U: âœ… MUST requirements: 47<br/>âœ… SHOULD requirements: 23<br/>âœ… Implementation checklist included<br/>âœ… Source section specified
```

## Chapter 6: When to Use RAG vs MCP

### 6.1 Decision Flow

```mermaid
flowchart TB
    START[External Knowledge Needed] --> Q1{Does Target Data<br/>Have Structure?}

    Q1 -->|Yes| Q2{Does Structured API<br/>Exist?}
    Q1 -->|No| Q3{Need Large-scale<br/>Text Search?}

    Q2 -->|Yes| MCP[Use MCP]
    Q2 -->|No| Q4{Worth Creating<br/>MCP?}

    Q3 -->|Yes| RAG[Use RAG]
    Q3 -->|No| PE[Prompt Engineering<bn>for Now]

    Q4 -->|Yes| BUILD_MCP[Build MCP]
    Q4 -->|No| RAG

    MCP --> COMBINE{Worth Combining<br/>with RAG?}
    RAG --> COMBINE
    BUILD_MCP --> COMBINE

    COMBINE -->|Yes| BOTH[Use RAG + MCP]
    COMBINE -->|No| DONE[Done]

    style MCP fill:#e8f5e9,color:#333
    style RAG fill:#fff3e0,color:#333
    style BOTH fill:#e3f2fd,color:#333
```

### 6.2 Selection Guide

| Scenario                           | Recommended          | Reason                                               |
| ---------------------------------- | -------------------- | ---------------------------------------------------- |
| **Verify RFC/W3C compliance**      | **MCP**              | Need structured requirement extraction               |
| **Search internal documents**      | **RAG**              | Large-scale unstructured text search                 |
| **Get law article text**           | **MCP**              | Need to preserve article, subsection, item structure |
| **Customer support FAQs**          | **RAG**              | Flexible handling of diverse questions               |
| **Translation quality evaluation** | **MCP**              | Structured scores and error detection                |
| **Summarize research papers**      | **RAG**              | Process large volumes of unstructured text           |
| **PDF spec requirement check**     | **MCP**              | Accurate retrieval of tables and requirement levels  |
| **Team knowledge sharing**         | **RAG** or **Skill** | Choose based on context                              |

### 6.3 Combined Patterns

RAG and MCP are not mutually exclusive. The following combined patterns are conceivable.

**Pattern: Understand Overview with RAG â†’ Verify Accuracy with MCP**

```mermaid
sequenceDiagram
    participant U as User
    participant AI as AI
    participant RAG as RAG<br/>(Internal Wiki)
    participant MCP as rfcxml-mcp

    U->>AI: Review WebSocket implementation<br/>considering both internal design policy<br/>and standard specifications

    AI->>RAG: Search "WebSocket Design Policy"
    RAG-->>AI: Related internal Wiki documents

    AI->>MCP: get_requirements(6455, role="client")
    MCP-->>AI: RFC compliance requirements

    AI-->>U: Internal policy: ã€‡ã€‡ (Source: Internal Wiki)<br/>Standard requirements: â–³â–³ (Source: RFC 6455 Â§5.2)<br/>âš ï¸ Differences between policy and RFC requirements: ...
```

## Chapter 7: Why This Project Chooses MCP

### 7.1 Alignment with Project Philosophy

The core philosophy of this project is "unshakeable references" (see [01-vision.md](./01-vision.md)).

```
RAG returns "probably relevant information"    â†’ Can be unreliable
MCP returns "definitely applicable information" â†’ Reliable
```

To give AI output **verifiable foundations**, clear sources and structured data access are essential. This is the fundamental reason why this project centers on MCP.

### 7.2 The 3 Values of MCP

The value that MCP provides in this project's context can be summarized in three points.

```mermaid
graph TB
    subgraph MCPValues["The 3 Values of MCP"]
        V1["â‘  Accuracy<bn>Structure-aware Access"]
        V2["â‘¡ Verifiability<bn>Clear Sources"]
        V3["â‘¢ Democratization<bn>Distribution via Standard Protocol"]
    end

    V1 --> RESULT[Trustworthiness of AI Output]
    V2 --> RESULT
    V3 --> RESULT

    style V1 fill:#e8f5e9,color:#333
    style V2 fill:#e3f2fd,color:#333
    style V3 fill:#f3e5f5,color:#333
    style RESULT fill:#ffd700,color:#333
```

1. **Accuracy**: Retrieve accurate information through APIs that understand domain structure
2. **Verifiability**: Source (RFC number, section number, etc.) is always explicit
3. **Democratization**: Can be distributed as npm packages, providing everyone equal quality access

### 7.3 We Are Not Rejecting RAG

As an important caveat, this project is not rejecting RAG. RAG is a very powerful technique for the purpose of "finding relevant information from large amounts of unstructured text."

However, **for the purpose of providing "unshakeable references" to AI judgment**, MCP's approach is more appropriate. Each pattern has appropriate use cases.

```
RAG's appropriate use:  "Want to find likely related items from lots of documents"
MCP's appropriate use:  "Want to get accurate information from specific standards/regulations"

â†’ Different purposes, so it's about choosing the right tool, not ranking
```

## Summary

### Core Messages

1. **Generative AI has various design patterns** â€” RAG, MCP, Fine-tuning, Agentic AI, etc., each solves different problems
2. **RAG searches by "text similarity"** â€” Strong at finding related information from large amounts of unstructured text
3. **MCP searches by "domain structure"** â€” Retrieves accurate information through structured APIs
4. **MCP is better suited for "unshakeable references"** â€” MCP has advantages in authority, structuring, verifiability, and distributability
5. **RAG and MCP are not mutually exclusive** â€” Each has appropriate use cases, and combined use is possible
6. **Each MCP server codifies domain knowledge** â€” Not merely text search, but provides understanding of structure

### Related Documents

- [01-vision.md](./01-vision.md) â€” AI limitations and the need for "unshakeable references"
- [02-reference-sources.md](./02-reference-sources.md) â€” System of reference sources by five characteristics
- [03-architecture.md](./03-architecture.md) â€” Composition theory of MCP/Skills/Agents
- [mcp/what-is-mcp.md](../mcp/what-is-mcp.md) â€” MCP details
- [skills/vs-mcp.md](../skills/vs-mcp.md) â€” Choosing between MCP and Skills

---

## Solving AI Limitations â€” Practical Approaches Available Today

Source: https://shuji-bonji.github.io/ai-agent-architecture/concepts/05-solving-ai-limitations/

# Solving AI Limitations â€” Practical Approaches Available Today

> Organizing what we can actually do now against AI's four fundamental limitations.

## About This Document

In [01-vision.md](./01-vision.md) and [02-reference-sources.md](./02-reference-sources.md), we **defined the problem** of AI's four fundamental limitations (accuracy, currency, authority, and accountability). In [04-ai-design-patterns.md](./04-ai-design-patterns.md), we organized **design patterns** such as RAG and MCP.

This document organizes **practical solution approaches available today** to address these limitations. While perfect solutions don't exist, by understanding the nature of each constraint and combining appropriate approaches, we can reduce risks to a practical level.

```mermaid
flowchart LR
    subgraph EXISTING["Existing Documents"]
        V["01: Problem Definition"]
        R["02: Reference Source System"]
        A["03: Architecture"]
        D["04: Design Patterns"]
    end

    subgraph THIS["This Document"]
        S["05: Solution Approaches"]
    end

    V --> S
    R --> S
    D --> S

    style S fill:#90EE90,color:#333,stroke:#333
```

## Four Constraints and Solution Feasibility Overview

First, let's understand the full picture. The four constraints have **very different possibilities for solutions** depending on their nature.

```mermaid
flowchart TB
    subgraph SOLVABLE["Solvable by Technology"]
        CURRENCY["Currency<bn>Knowledge Cutoff"]
    end

    subgraph MITIGABLE["Mitigable by Technology"]
        ACCURACY["Accuracy<bn>Hallucination"]
        AUTHORITY["Authority<bn>Interpretation Authority"]
    end

    subgraph SYSTEMIC["Institutional Design Required"]
        ACCOUNTABILITY["Accountability<bn>Legal & Ethical Basis"]
    end

    style CURRENCY fill:#90EE90,color:#333,stroke:#333
    style ACCURACY fill:#FFE4B5,color:#333,stroke:#333
    style AUTHORITY fill:#FFE4B5,color:#333,stroke:#333
    style ACCOUNTABILITY fill:#FFB6C1,color:#333,stroke:#333
```

| Constraint         | Solvability                             | Reason                                                                                                         |
| ------------------ | --------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| **Currency**       | â—Ž Largely Solvable                      | Can be addressed through web search and real-time access via MCP                                               |
| **Accuracy**       | â–³ Mitigable, Not Completely Preventable | Due to the fundamental probabilistic nature of LLM generation, complete elimination is impossible in principle |
| **Authority**      | â–³ Mitigable, Not Completely Solvable    | AI output is ultimately "one interpretation" and cannot become official authority                              |
| **Accountability** | âœ— Not Solvable by Technology Alone      | This is a matter of legal and ethical institutional design; technology only provides the foundation            |

## Chapter 1: Solving Currency â€” The Constraint with the Clearest Solutions

### 1.1 The Nature of the Problem

LLM knowledge is fixed at the point of training data (details: [02-reference-sources.md 1.2.2](./02-reference-sources.md)). However, for this constraint, there is a **clear solution: connecting to external information sources**.

### 1.2 Solution Approaches

```mermaid
flowchart TB
    PROBLEM["Currency Constraint<bn>Knowledge Cutoff"]

    PROBLEM --> WEB["Web Search<bn>(Real-time Information Retrieval)"]
    PROBLEM --> MCP_RT["Real-time Access via MCP<bn>(Direct Connection to Authoritative Sources)"]
    PROBLEM --> RAG_UP["Regular RAG Index Updates<bn>(Keeping Organizational Knowledge Current)"]

    WEB --> EVAL["âœ… Largely Solvable"]
    MCP_RT --> EVAL
    RAG_UP --> EVAL

    style EVAL fill:#90EE90,color:#333,stroke:#333
```

#### Retrieving Current Information via Web Search

The most convenient approach. AI assistants like Claude can retrieve real-time information using built-in web search functionality.

| Advantages                     | Constraints                              |
| ------------------------------ | ---------------------------------------- |
| No additional cost             | Search result reliability not guaranteed |
| Available immediately          | Information structure is insufficient    |
| Covers a wide range of sources | High noise                               |

#### Real-time Access via MCP

**Directly accessing** authoritative information sources in a **structured manner**. This is the approach this project promotes.

```
rfcxml-mcp   â†’ Get latest RFCs directly from IETF
hourei-mcp   â†’ Get latest laws from e-Gov API
w3c-mcp      â†’ Get latest specs from W3C/WHATWG
```

| Advantages                              | Constraints                                     |
| --------------------------------------- | ----------------------------------------------- |
| Get directly from authoritative sources | MCP server development and maintenance required |
| Structured data                         | MCP needed for each target domain               |
| Verifiable sources                      | Cannot cover all information sources            |

#### Regular RAG Index Updates

For organizational documents, ensuring currency is possible by regularly updating RAG indexes.

### 1.3 Implementation Evaluation

Currency is **the constraint with the clearest solution among the four**, and can be practically solved by combining appropriate tools. The remaining challenge is "the practical difficulty of covering all information sources in real-time," which is manageable as an operational issue.

## Chapter 2: Mitigating Accuracy â€” Complete Elimination is Impossible in Principle

### 2.1 The Nature of the Problem

Hallucination (generating information that contradicts facts) stems from the **fundamental nature** that LLMs generate probabilistically "plausible" rather than "correct" output (details: [02-reference-sources.md 1.2.1](./02-reference-sources.md)).

This is not a "bug" but a "feature," and **it is impossible to eliminate it completely in principle**.

### 2.2 Mitigation Approaches

```mermaid
flowchart TB
    PROBLEM["Accuracy Constraint<bn>Hallucination"]

    PROBLEM --> INJECT["External Knowledge Injection<bn>(MCP / RAG)"]
    PROBLEM --> VERIFY["Output Verification<bn>(Multi-stage Checks)"]
    PROBLEM --> DECLARE["Explicit Uncertainty<bn>(AI Communicates Its Limits)"]
    PROBLEM --> HUMAN["Human Review<bn>(Final Confirmation Process)"]

    INJECT --> EVAL["â–³ Mitigable<bn>Complete Elimination Not Possible"]
    VERIFY --> EVAL
    DECLARE --> EVAL
    HUMAN --> EVAL

    style EVAL fill:#FFE4B5,color:#333,stroke:#333
```

#### External Knowledge Injection (MCP / RAG)

Reduce the frequency of hallucinations by providing AI with accurate information sources.

```
MCP Effect:
  Question: "What does status code 1006 in RFC 6455 mean?"

  Without MCP â†’ AI generates "plausible" answer from training data (may be wrong)
  With MCP â†’ rfcxml-mcp retrieves original text â†’ accurate answer possible

  â†’ Hallucination rate decreases dramatically
```

However, hallucination may still occur in the **interpretation** of data retrieved by MCP.

#### Output Verification (Multi-stage Checks)

A workflow to verify AI output through alternative means.

```mermaid
sequenceDiagram
    participant U as User
    participant AI as AI
    participant MCP as MCP Server

    U->>AI: Question
    AI->>MCP: Data Retrieval
    MCP-->>AI: Original Data
    AI->>AI: Generate Answer
    AI->>MCP: Verify with validate_statement()
    MCP-->>AI: Verification Result
    AI-->>U: Answer + Verification Status + Source
```

The `validate_statement()` of rfcxml-mcp in this project is precisely designed for this purpose.

#### Explicit Uncertainty

A mechanism for AI to make explicit when it cannot be confident in its answer.

```
Confidence Levels:
  âœ… Verified: Information verified through MCP/original source
  âš ï¸ Estimated: Based on training data but not verified from source
  â“ Uncertain: Information not found or contradictory
```

#### Human Review

Establish a human review process as final quality assurance. Especially critical for important judgments (legal decisions, security requirements, etc.).

### 2.3 Implementation Evaluation

Complete accuracy assurance is **impossible in principle**, but by combining the above approaches, we can significantly reduce practical risks. The key is building a culture that "doesn't simply trust AI output" and creating verifiable workflows.

## Chapter 3: Ensuring Authority â€” Risk Management Rather Than Complete Solution

### 3.1 The Nature of the Problem

AI output is "one interpretation" and **not an official view** (details: [02-reference-sources.md 1.2.3](./02-reference-sources.md)). Only the creators (IETF, legislative bodies, etc.) can provide the "official interpretation" of RFCs, laws, and standard specifications.

This constraint arises from **the nature of information authority itself** rather than AI characteristics, making it impossible to completely solve with technology alone.

### 3.2 Response Approaches

```mermaid
flowchart TB
    PROBLEM["Authority Constraint<bn>Interpretation Authority"]

    PROBLEM --> DIRECT["Direct Access to Original Sources<bn>(Retrieve Primary Sources via MCP)"]
    PROBLEM --> CITE["Explicit Citation<bn>(Identify Down to Section Number)"]
    PROBLEM --> WORKFLOW["Human Review Workflow<bn>(Humans Make the Decision)"]
    PROBLEM --> MULTI["Multi-angle Verification<bn>(Cross-check with Multiple MCPs)"]

    DIRECT --> EVAL["â–³ Manage as Risk<bn>Complete Solution Not Possible"]
    CITE --> EVAL
    WORKFLOW --> EVAL
    MULTI --> EVAL

    style EVAL fill:#FFE4B5,color:#333,stroke:#333
```

#### Direct Access to Original Sources

Access primary information sources directly through MCP and **present the original text** rather than AI interpretation.

```
Rather than authorize AI output,
present the original source itself so humans can decide.

Example:
  AI: "The original text of RFC 6455 Section 7.4.1 is as follows:"
      â†“ Present original text
  Human: "I see, this case should be interpreted this way"
      â†“ Human decides
```

#### Explicit Citation

Explicitly indicate section numbers of information sources in all AI output. This allows humans to **independently verify**.

> For details on output templates, see [02-reference-sources.md Chapter 4](./02-reference-sources.md).

#### Human Review Workflow

For judgments where authority is required (legal decisions, spec interpretation, etc.), build a workflow that treats AI output as **draft/reference information** and has humans make the final decision.

```
AI's Role: Information collection, organization, candidate presentation
Human's Role: Final decision and approval

â†’ AI is "an excellent research assistant" not "an omniscient answerer"
```

#### Multi-angle Verification

Verify information from different angles using multiple MCPs.

```mermaid
sequenceDiagram
    participant U as User
    participant AI as AI
    participant RFC as rfcxml-mcp
    participant LAW as hourei-mcp

    U->>AI: Is timestamp implementation legally problematic?
    AI->>RFC: get_requirements(3161)
    RFC-->>AI: Technical Requirements (75 MUST)
    AI->>LAW: find_law_article("Digital Signature Law", "2")
    LAW-->>AI: Legal Requirements
    AI->>AI: Map Technical Requirements â†” Legal Requirements
    AI-->>U: Analysis from Both Technical & Legal Perspectives<bn>âš ï¸ Expert confirmation recommended for final judgment
```

### 3.3 Implementation Evaluation

Rather than "completely solving" authority, the mindset of **managing it as a risk** is important. AI **improves efficiency** of access to authoritative information sources but cannot **replace** the authority itself.

## Chapter 4: Ensuring Accountability â€” The Intersection of Technology and Institutional Design

### 4.1 The Nature of the Problem

AI output has **no clear subject of accountability** (details: [02-reference-sources.md 1.2.4](./02-reference-sources.md)). This is more a legal and ethical issue than a technical one.

### 4.2 Foundation Technology Can Provide

While technology alone cannot completely solve accountability, it can provide the **foundation** supporting it.

```mermaid
flowchart TB
    PROBLEM["Accountability Constraint<bn>Lack of Legal & Ethical Basis"]

    PROBLEM --> AUDIT["Ensuring Audit Trail"]
    PROBLEM --> TRACE["Traceability<bn>(Record Decision Process)"]
    PROBLEM --> INTEGRITY["Data Integrity Assurance<bn>(Digital Signature, Timestamp)"]
    PROBLEM --> GOVERNANCE["Building Governance Framework<bn>(Clarify Human Responsibility)"]

    AUDIT --> EVAL["âœ— Technology Provides Foundation<bn>Institutional Design Essential"]
    TRACE --> EVAL
    INTEGRITY --> EVAL
    GOVERNANCE --> EVAL

    style EVAL fill:#FFB6C1,color:#333,stroke:#333
```

#### Ensuring Audit Trail

Recording what data AI references, how it processes it, and how it generates output.

```
Information to Record:
  - When: Timestamp
  - What: Referenced data sources (MCP call logs)
  - How: Process steps (prompts, tool call chains)
  - What Output: Final output
```

#### Traceability

The ability to trace back from AI output to the original sources referenced. Structured source information provided by MCP makes this possible.

```
AI Output: "Status code 1006 must not be included in Close frame"
    â†“ Trace
Reference: rfcxml-mcp â†’ get_requirements(6455, section="7.4.1")
    â†“ Trace
Original: RFC 6455, Section 7.4.1, MUST NOT requirement
    â†“ Verify
Humans can verify the original source directly
```

Here is where **transparency of open-source MCP** has value. If MCP server source code is publicly available, we can verify "how data is obtained and processed" at the code level. Proprietary pipelines make this verification impossible, breaking the chain of traceability.

#### Data Integrity Assurance

A mechanism ensuring that data retrieved by MCP from external services has not been tampered with. The following technologies will be necessary in the future.

| Technology                 | Purpose                           | Standard                      |
| -------------------------- | --------------------------------- | ----------------------------- |
| **Timestamp**              | Prove time of data existence      | RFC 3161                      |
| **HTTP Message Signature** | Ensure communication authenticity | RFC 9421                      |
| **Digital Signature**      | Prove data non-tampering          | Digital Signature Law / eIDAS |

```mermaid
flowchart LR
    subgraph CURRENT["Current MCP"]
        C1["MCP Server"] --> C2["External API"]
        C2 --> C3["Data Retrieval"]
        C3 --> C4["Provide to AI"]
    end

    subgraph FUTURE["Future MCP (Enhanced Trustworthiness)"]
        F1["MCP Server"] --> F2["External API"]
        F2 --> F3["Data Retrieval"]
        F3 --> F4["Signature Verification âœ“"]
        F4 --> F5["Attach Timestamp ðŸ•"]
        F5 --> F6["Provide to AI<bn>+ Completeness Proof"]
    end

    CURRENT -.->|"Evolution"| FUTURE

    style FUTURE fill:#e8f5e9,color:#333,stroke:#333
```

Currently, such mechanisms are not built into the MCP protocol, but since MCP handles connections to external services, ensuring integrity of connection paths and retrieved data is an **unavoidable future challenge**.

#### Building Governance Framework

Beyond technology scope, organizations need to systematically establish responsibility for AI output.

```
Who: Who approves AI output finally
Based on What: By what guidelines to decide
How to Record: How to maintain approval process evidence
When Issues Arise: Who responds and how
```

### 4.3 Implementation Evaluation

Accountability is **an area of institutional design beyond technology**. Technology (audit trail, traceability, data integrity) provides its foundation, but ultimately requires legal frameworks, organizational structures, and industry standard improvements.

What individuals and small teams can do now is **establish technological foundations as much as possible and prepare for future institutional design**. This project's MCP approach (open-source, explicit sourcing, structured access) is precisely building this foundation.

## Chapter 5: Overall Picture of Four Approaches

### 5.1 Summary Table

| Constraint         | Solvability                     | Primary Means                                            | This Project's Response                 |
| ------------------ | ------------------------------- | -------------------------------------------------------- | --------------------------------------- |
| **Currency**       | â—Ž Largely Solvable              | Web search, MCP, RAG updates                             | Real-time retrieval via rfcxml-mcp etc. |
| **Accuracy**       | â–³ Mitigable                     | MCP/RAG injection, verification, uncertainty declaration | validate_statement(), explicit sourcing |
| **Authority**      | â–³ Risk Management               | Original source access, explicit citation, human review  | Access to primary sources via MCP       |
| **Accountability** | âœ— Institutional Design Required | Audit trail, traceability, signatures                    | Transparency through open-source MCP    |

### 5.2 Mapping Approaches and Solutions

```mermaid
flowchart LR
    subgraph TECH["Technical Approaches"]
        direction LR
        MCP_APPROACH["MCP<bn>Structured Access"]
        RAG_APPROACH["RAG<bn>Similarity Search"]
        WEBSEARCH["Web Search<bn>Real-time Information"]
        VALIDATION["Verification Workflow<bn>Multi-stage Checks"]
    end

    subgraph ORG["Organizational Approaches"]
        direction LR
        REVIEW["Human Review<bn>Final Approval"]
        GOVERNANCE["Governance<bn>Responsibility Framework"]
    end

    subgraph FUTURE_TECH["Future Technology"]
        direction LR
        SIGNATURE["Digital Signature<bn>Data Integrity"]
        TIMESTAMP["Timestamp<bn>Existence Proof"]
    end

    MCP_APPROACH --> ACCURACY["Accuracy â–³"]
    MCP_APPROACH --> CURRENCY["Currency â—Ž"]
    MCP_APPROACH --> AUTHORITY["Authority â–³"]
    RAG_APPROACH --> CURRENCY
    RAG_APPROACH --> ACCURACY
    WEBSEARCH --> CURRENCY
    VALIDATION --> ACCURACY
    REVIEW --> AUTHORITY
    REVIEW --> ACCOUNTABILITY["Accountability âœ—"]
    GOVERNANCE --> ACCOUNTABILITY
    SIGNATURE --> ACCOUNTABILITY
    TIMESTAMP --> ACCOUNTABILITY

    style CURRENCY fill:#90EE90,color:#333,stroke:#333
    style ACCURACY fill:#FFE4B5,color:#333,stroke:#333
    style AUTHORITY fill:#FFE4B5,color:#333,stroke:#333
    style ACCOUNTABILITY fill:#FFB6C1,color:#333,stroke:#333
```

### 5.3 Key Understanding

```
We cannot solve all AI constraints with technology alone.

Accuracy â†’ Mitigate with technology, accept residual risk
Currency â†’ Largely solvable with technology
Authority â†’ Manage risk with technology, humans make final decisions
Accountability â†’ Technology provides foundation, defer to institutional design

â†’ The important thing is not aiming for "complete solution"
  but understanding each constraint's nature and selecting appropriate approaches
```

This project's MCP approach contributes partially to all four constraints. Particularly, improving accuracy, currency, and authority through "unshakeable reference sources," and building the foundation for accountability through open-source transparency, is the best approach practically achievable today.

## Related Documents

- [01-vision.md](./01-vision.md) â€” Definition of AI limitations and the need for "unshakeable reference sources"
- [02-reference-sources.md](./02-reference-sources.md) â€” System of reference sources by five characteristics
- [03-architecture.md](./03-architecture.md) â€” Composition of MCP/Skills/Agent
- [04-ai-design-patterns.md](./04-ai-design-patterns.md) â€” Comparison of design patterns like RAG/MCP
- [mcp/what-is-mcp.md](../mcp/what-is-mcp.md) â€” Details about MCP

---

## What is MCP?

Source: https://shuji-bonji.github.io/ai-agent-architecture/mcp/what-is-mcp/

# What is MCP?

> A standard protocol for AI agents to safely access external tools and data

## About This Document

This guide covers the core concepts, categories, and trade-offs of MCP. If you're new to MCP, start here. For hands-on implementation details, see [development.md](./development.md).

## What is MCP?

**MCP (Model Context Protocol)** is an open standard protocol led by Anthropic.

In short: **a common protocol that enables AI agents to safely access external tools and data.**

### The USB-C Analogy

Just as USB-C connects various devices (mice, keyboards, external drives) to a PC with one standard, MCP connects various tools and services (RFC specifications, translation APIs, legal databases) to AI with one protocol.

### The Essence: Giving AI a "Hand"

AI excels at text input and output, but by default it cannot interact with the outside worldâ€”no network access, no file operations. MCP standardizes this gap and gives AI the tools it needs to act.

## Why MCP?

### The Problem: AI's Knowledge Cutoff and Dynamic Data

AI can only answer within its training data. For example:

- It doesn't know the latest RFC specifications (RFC 6455 and beyond)
- It cannot use translation services like DeepL or Google Translate
- It cannot search legal databases or proprietary knowledge bases

### Before MCP: The NÃ—M Problem

Before MCP, each AI tool (Claude Code, Cursor, VS Code) had to individually integrate with each service (RFC, translation, legal databases).

```
N AI tools Ã— M services = NÃ—M integrations needed
```

### After MCP: Reduced to N+M

With MCP standardization, each service publishes one MCP server, and all AI tools automatically gain access to it.

```
N AI tools + M MCP servers = N+M implementations total
```

## MCP's Three-Layer Architecture

MCP has three clearly defined layers with distinct roles.

```mermaid
block-beta
    columns 1

    block:HOST_BLOCK:1
        HOST["Host (Application)<br/>Claude Code, Cursor, VS Code"]
    end

    block:CLIENT_BLOCK:1
        CLIENT["Client (MCP Client)<br/>Built into Host / Protocol Handler"]
    end

    block:SERVER_BLOCK:1
        SERVER["Server (MCP Server)<br/>Tools & Resource Provider / Actual Processing"]
    end

    HOST --> CLIENT
    CLIENT --"JSON-RPC 2.0"--> SERVER

    style HOST fill:#87CEEB,color:#333,stroke:#333
    style CLIENT fill:#FFE4B5,color:#333,stroke:#333
    style SERVER fill:#FFB6C1,color:#333,stroke:#333
```

### Roles and Developer Involvement

The following table summarizes each layer's responsibilities and how developers interact with them.

| Layer      | Role                                              | Example                      | Developer Role      |
| ---------- | ------------------------------------------------- | ---------------------------- | ------------------- |
| **Host**   | UI, session management, user interface            | Claude Code, Cursor, VS Code | User                |
| **Client** | JSON-RPC communication, request/response handling | Built into Host              | Usually transparent |
| **Server** | Tool/resource provision, actual implementation    | rfcxml-mcp, deepl-mcp        | **You build this**  |

### Key Insight

**When developing an MCP server, you only implement the Server layer.** The Client is built into the Host, so you don't need to worry about protocol details.

## MCP Categories

MCP servers are classified into four categories based on data sourcing and processing patterns.

| Pattern           | Characteristics                                    | Examples                           |
| ----------------- | -------------------------------------------------- | ---------------------------------- |
| **Local Data**    | No external communication; data bundled in package | epsg-mcp, pdf-spec-mcp             |
| **External API**  | Communicates with external APIs via HTTP/HTTPS     | rfcxml-mcp, w3c-mcp, hourei-mcp    |
| **Model Loading** | Loads ML models for local inference                | xcomet-mcp-server                  |
| **Hybrid**        | Combination of multiple patterns                   | pdf-reader-mcp (local + URL fetch) |

### Selection Flowchart

When building a new MCP server, use the following flowchart to determine which category applies.

```mermaid
flowchart TD
    Q1{External API needed?}
    Q1 -->|Yes| Q2{Real-time needed?}
    Q1 -->|No| Q3{ML model needed?}
    Q2 -->|Yes| API["External API"]
    Q2 -->|No| HYBRID["Hybrid"]
    Q3 -->|Yes| MODEL["Model Loading"]
    Q3 -->|No| LOCAL["Local Data"]

    style API fill:#FFB6C1,color:#333,stroke:#333
    style MODEL fill:#87CEEB,color:#333,stroke:#333
    style LOCAL fill:#90EE90,color:#333,stroke:#333
    style HYBRID fill:#FFE4B5,color:#333,stroke:#333
```

## Core Features of MCP Servers

MCP servers provide three core capabilities.

### Tools - The Most Common

Functions that AI can invoke, similar to Remote Procedure Calls (RPC).

**Examples:**

- `rfcxml:get_rfc_structure` - Fetch RFC specification structure
- `deepl:translate-text` - Translate text
- `xcomet:xcomet_evaluate` - Evaluate translation quality

### Resources

Data sources that AI can read, accessed via URI.

**Examples:**

- `file:///path/to/data` - File system data
- `rfc://6455` - RFC specification document

### Prompts

Reusable prompt templates, formalized as repeatable workflows.

**Examples:**

- Translation quality evaluation template
- Code review template

### Feature Comparison

The following table contrasts these three capabilities.

| Feature       | Data Direction | Description                     | Usage Frequency |
| ------------- | -------------- | ------------------------------- | --------------- |
| **Tools**     | AI â†’ Server    | AI calls server functions       | â˜…â˜…â˜… Most common |
| **Resources** | Server â†’ AI    | Server provides data without UI | â˜…â˜… Moderate     |
| **Prompts**   | Server â†’ AI    | Template provision              | â˜… Limited       |

## Additional Utility Features

Beyond the core capabilities (Tools/Resources/Prompts), MCP defines several utility features. None are mandatory, but they become valuable for advanced use cases.

### Sampling

Server requests AI inference in reverse. Useful when delegating complex decisions to the AI.

### Roots

Limits the file system scope that the server can access. Critical for security.

### Logging

Structured log output for debugging and monitoring.

### Progress

Progress reporting for long-running operations to improve user experience.

### Implementation Note

Most MCP servers function perfectly with **Tools alone.** Add features incrementally as needed.

## Benefits

Adopting MCP provides the following advantages.

- âœ… **Standardization**  
  Once built, your server works with multiple AI hosts (Claude Code, Cursor, VS Code). Protocol unification drastically reduces integration costs.

- âœ… **Reusability**  
  Publish on npm and users can start using it instantly with `npx`. Deployment and maintenance are simple.

- âœ… **Dynamic Processing**  
  Enable real-time data fetching and processing. Complement AI's knowledge cutoff.

- âœ… **Authority**  
  Direct access to authoritative sources (RFC originals, legal databases). Reduces AI hallucinations.

- âœ… **Separation of Concerns**  
  Tool logic and AI logic are cleanly separated. Changes have limited scope.

## Drawbacks and Risks

MCP also comes with trade-offs and risks to be aware of.

- âŒ **Context Consumption**  
  Tool definitions consume tokens just to load. With many tools, context window pressure becomes real.

- âŒ **Startup Overhead**  
  Requires server process management. Overkill for simple cases.

- âŒ **Security Risks**  
  Input validation gaps or permission misconfigurations can cause serious damage. See [security.md](./security.md) for details.

- âŒ **Maintenance Cost**  
  You must track external API changes. Long-term sustainability requires careful design.

- âŒ **Over-MCP-ification**  
  Resist the temptation to MCP everything. CLI + Skills often suffice.

### Key Insight

> Services with official CLIs (gh, aws, gcloud) are better served by **CLI + Skills**, not MCP. See [03-architecture.md](../concepts/03-architecture.md) ("CLI vs MCP") for the decision framework.

## MCP Implementations in This Repository

The ai-agent-architecture repository accumulates practical knowledge from developing and operating MCPs.

### Custom MCPs (Published on npm)

Seven MCP servers designed, implemented, and released:

- **rfcxml-mcp** - Search and fetch IETF RFC specifications
- **w3c-mcp** - Search and reference W3C/WHATWG web specifications
- **xcomet-mcp** - Evaluate translation quality (uses machine learning models)
- **rxjs-mcp** - RxJS operator guide and code execution
- **epsg-mcp** - Search and transform coordinate reference systems (CRS)
- **pdf-spec-mcp** - Search PDF specifications (ISO 32000)
- **pdf-reader-mcp** - Read and extract text from PDFs

### Integrated MCPs (External Development)

Five MCP servers we integrate and extend:

- **deepl-mcp** - DeepL translation API
- **hourei-mcp** - Japanese legal database
- **mermaid-mcp** - Mermaid diagram generation
- **svelte-mcp** - Svelte 5 documentation
- **shadcn-svelte-mcp** - shadcn/ui v4 components

### Learn More

See [catalog.md](./catalog.md) for the complete list and detailed specifications.

## What to Read Next

To dive deeper into MCP, explore the following documents.

| Goal                          | Document                                             |
| ----------------------------- | ---------------------------------------------------- |
| **Build an MCP**              | [development.md](./development.md)                   |
| **Explore built MCPs**        | [catalog.md](./catalog.md)                           |
| **Understand security**       | [security.md](./security.md)                         |
| **Choose between Skills/A2A** | [03-architecture.md](../concepts/03-architecture.md) |
| **Learn about Skills**        | [what-is-skills.md](../skills/what-is-skills.md)     |

**Last Updated:** 2026-02-12
**Repository:** [ai-agent-architecture](https://github.com/shuji-bonji/ai-agent-architecture)

---

## MCP Catalog

Source: https://shuji-bonji.github.io/ai-agent-architecture/mcp/catalog/

# MCP Catalog

> A comprehensive list of MCP servers built and used, along with their features, use cases, and achievements.

## About This Document

This document is a catalog listing the MCP servers currently built and in use. It describes the features, provided tools, and practical usage examples for each MCP.

Use this as a reference when considering the development of new MCPs, or as a guide for understanding how to use existing MCPs. While each MCP provides value on its own, combining multiple MCPs can enable more powerful workflows. This document provides insights into such combinations.

## Overview Map

This map provides a visual overview of the MCP ecosystem, showing how different MCPs are organized into categories.

```mermaid
mindmap
  root((MCP<br/>Ecosystem))
    Custom MCPs
      rfcxml-mcp
      w3c-mcp
      xcomet-mcp-server
      rxjs-mcp-server
      epsg-mcp
      pdf-spec-mcp
      pdf-reader-mcp
      pwa-mcp
    Integration MCPs
      deepl-mcp
      hourei-mcp-server
      mermaid-mcp
      svelte-mcp
      shadcn-svelte-mcp
    Planned
      OpenAPI MCP
      OWASP MCP
      Angular MCP
```

## Custom MCP Servers

### [rfcxml-mcp](https://www.npmjs.com/package/@shuji-bonji/rfcxml-mcp)

Provides structured access to IETF RFC documents.

| Item           | Description                                                         |
| -------------- | ------------------------------------------------------------------- |
| **Repository** | [shuji-bonji/rfcxml-mcp](https://github.com/shuji-bonji/rfcxml-mcp) |
| **npm**        | [`@shuji-bonji/rfcxml-mcp`](https://www.npmjs.com/package/@shuji-bonji/rfcxml-mcp) |
| **Purpose**    | RFC specification search, analysis, and requirements extraction     |
| **Status**     | Published                                                           |

#### Main Tools

| Tool                   | Function                                            |
| ---------------------- | --------------------------------------------------- |
| `get_rfc_structure`    | Get RFC section hierarchy and metadata              |
| `get_requirements`     | Structured extraction of MUST/SHOULD/MAY requirements |
| `get_definitions`      | Get term definitions                                |
| `get_rfc_dependencies` | Get references (normative/informative)              |
| `get_related_sections` | Get related sections                                |
| `generate_checklist`   | Generate implementation checklist in Markdown       |
| `validate_statement`   | Verify if implementation conforms to specification  |

#### Achievements

- Used for Japanese translation of RFC 6455 (WebSocket)
- Used for mapping between Electronic Signature Act and RFC 3161
- Automatically extracted 75 MUST requirements and 23 SHOULD requirements

### [w3c-mcp](https://www.npmjs.com/package/@shuji-bonji/w3c-mcp)

Provides access to W3C/WHATWG/IETF Web standard specifications.

| Item           | Description                                                   |
| -------------- | ------------------------------------------------------------- |
| **Repository** | [shuji-bonji/w3c-mcp](https://github.com/shuji-bonji/w3c-mcp) |
| **npm**        | [`@shuji-bonji/w3c-mcp`](https://www.npmjs.com/package/@shuji-bonji/w3c-mcp) |
| **Purpose**    | Web standard specification search, WebIDL, CSS, HTML elements |
| **Status**     | Published (npm v0.1.7)                                        |

#### Main Tools

| Tool                    | Function                                                |
| ----------------------- | ------------------------------------------------------- |
| `list_w3c_specs`        | List specifications (filter by organization, category, keyword) |
| `get_w3c_spec`          | Get specification details                               |
| `search_w3c_specs`      | Search specifications                                   |
| `get_webidl`            | Get WebIDL interface definitions                        |
| `get_css_properties`    | Get CSS property definitions                            |
| `get_html_elements`     | Get HTML element definitions                            |
| `get_pwa_specs`         | List PWA-related specifications                         |
| `get_spec_dependencies` | Get specification dependencies                          |

### [xcomet-mcp-server](https://www.npmjs.com/package/xcomet-mcp-server)

Provides translation quality evaluation using the xCOMET model.

| Item           | Description                                                                       |
| -------------- | --------------------------------------------------------------------------------- |
| **Repository** | [shuji-bonji/xcomet-mcp-server](https://github.com/shuji-bonji/xcomet-mcp-server) |
| **npm**        | [`xcomet-mcp-server`](https://www.npmjs.com/package/xcomet-mcp-server) |
| **Purpose**    | Quantitative translation quality evaluation and error detection                   |
| **Status**     | Published (1 star, 1 fork)                                                        |

#### Main Tools

| Tool                    | Function                                                   |
| ----------------------- | ---------------------------------------------------------- |
| `xcomet_evaluate`       | Translation quality score (0-1) and error span detection   |
| `xcomet_detect_errors`  | Detailed error detection (severity: minor/major/critical)  |
| `xcomet_batch_evaluate` | Batch evaluation of multiple translation pairs             |

#### Features

- Persistent model loading (fast inference after initialization)
- GPU support
- Batch processing support

#### Achievements

- Translated and quality-evaluated 180-page technical document (1.5 million characters) in one day
- Cost of approximately $12 (less than 1/100 of conventional methods)

### [rxjs-mcp-server](https://www.npmjs.com/package/@shuji-bonji/rxjs-mcp)

Provides RxJS stream execution, visualization, and analysis.

| Item           | Description                                                                   |
| -------------- | ----------------------------------------------------------------------------- |
| **Repository** | [shuji-bonji/rxjs-mcp-server](https://github.com/shuji-bonji/rxjs-mcp-server) |
| **Purpose**    | RxJS code execution, marble diagram generation, and analysis                  |
| **Status**     | Published                                                                     |

#### Main Tools

| Tool                 | Function                                     |
| -------------------- | -------------------------------------------- |
| `execute_stream`     | Execute RxJS code and capture results        |
| `generate_marble`    | Generate ASCII marble diagrams               |
| `analyze_operators`  | Operator analysis and performance checking   |
| `detect_memory_leak` | Memory leak detection                        |
| `suggest_pattern`    | Pattern suggestions based on use cases       |

### [epsg-mcp](https://www.npmjs.com/package/@shuji-bonji/epsg-mcp)

Provides access to the EPSG coordinate reference system database.

| Item           | Description                                                     |
| -------------- | --------------------------------------------------------------- |
| **Repository** | [shuji-bonji/epsg-mcp](https://github.com/shuji-bonji/epsg-mcp) |
| **npm**        | [`@shuji-bonji/epsg-mcp`](https://www.npmjs.com/package/@shuji-bonji/epsg-mcp) |
| **Purpose**    | Coordinate Reference System (CRS) knowledge base with global coverage |
| **Status**     | Published (npm v0.9.8)                                          |

#### Main Tools

| Tool                      | Function                                     |
| ------------------------- | -------------------------------------------- |
| `search_crs`              | Search EPSG CRS by keyword                   |
| `get_crs_detail`          | Get detailed info for specific EPSG code     |
| `list_crs_by_region`      | List CRS by region with recommendations      |
| `recommend_crs`           | Recommend optimal CRS for purpose/location   |
| `validate_crs_usage`      | Validate CRS appropriateness                 |
| `suggest_transformation`  | Suggest transformation paths between CRS     |
| `compare_crs`             | Compare two CRS from various perspectives    |
| `get_best_practices`      | Get CRS best practices for specific topics   |
| `troubleshoot`            | Troubleshoot CRS-related problems            |

#### Features

- Full support for Japan Plane Rectangular CS (Zones I-XIX)
- Global coverage (WGS84, UTM zones, etc.)
- Offline operation with local database
- Regional packs (Japan, US, UK)

### [pdf-spec-mcp](https://www.npmjs.com/package/@shuji-bonji/pdf-spec-mcp)

Provides structured access to PDF specifications (ISO 32000).

| Item           | Description                                                                    |
| -------------- | ------------------------------------------------------------------------------ |
| **Repository** | [shuji-bonji/pdf-spec-mcp](https://github.com/shuji-bonji/pdf-spec-mcp)        |
| **npm**        | [`@shuji-bonji/pdf-spec-mcp`](https://www.npmjs.com/package/@shuji-bonji/pdf-spec-mcp) |
| **Purpose**    | PDF specification (ISO 32000-1/2) structured reference and requirements extraction |
| **Status**     | Published (npm v0.2.2)                                                         |

#### Main Tools

| Tool               | Function                                         |
| ------------------- | ------------------------------------------------ |
| `list_specs`        | List available PDF specification documents       |
| `get_structure`     | Get section hierarchy of PDF specification       |
| `get_section`       | Get content of a specific section                |
| `search_spec`       | Full-text search of PDF specification            |
| `get_requirements`  | Extract normative requirements (shall/must/may)  |
| `get_definitions`   | Get term definitions                             |
| `get_tables`        | Extract table structures                         |
| `compare_versions`  | Compare sections between PDF 1.7 and PDF 2.0    |

### [pdf-reader-mcp](https://www.npmjs.com/package/@shuji-bonji/pdf-reader-mcp)

Provides PDF internal structure analysis and reading capabilities.

| Item           | Description                                                                        |
| -------------- | ---------------------------------------------------------------------------------- |
| **Repository** | [shuji-bonji/pdf-reader-mcp](https://github.com/shuji-bonji/pdf-reader-mcp)        |
| **npm**        | [`@shuji-bonji/pdf-reader-mcp`](https://www.npmjs.com/package/@shuji-bonji/pdf-reader-mcp) |
| **Purpose**    | PDF reading, structure analysis, and accessibility validation                      |
| **Status**     | Published (npm v0.2.0)                                                             |

#### Main Tools

| Tool                  | Function                                    |
| --------------------- | ------------------------------------------- |
| `read_text`           | Text extraction with reading order          |
| `read_images`         | Image extraction                            |
| `search_text`         | Text search within PDF                      |
| `get_metadata`        | Metadata extraction                         |
| `inspect_structure`   | Internal object structure inspection        |
| `inspect_tags`        | Tagged PDF structure analysis               |
| `inspect_fonts`       | Font information listing                    |
| `inspect_annotations` | Annotation listing                          |
| `inspect_signatures`  | Digital signature field inspection          |
| `validate_tagged`     | PDF/UA tag structure validation             |
| `validate_metadata`   | Metadata conformance validation             |
| `compare_structure`   | Compare structures of two PDFs              |
| `read_url`            | Fetch and read PDF from URL                 |
| `summarize`           | Generate PDF overview report                |

#### Features

- 15 specialized tools across 3 tiers (basic / inspection / validation)
- PDF/UA accessibility compliance checking
- 185 tests (146 E2E tests)

### pwa-mcp

Provides PWA (Progressive Web App) development support.

| Item           | Description         |
| -------------- | ------------------- |
| **Repository** | shuji-bonji/pwa-mcp |
| **Purpose**    | PWA development support |
| **Status**     | Private             |

## Integration MCP Servers

MCPs that are not custom-built but are integrated into workflows.

### deepl-mcp

| Item         | Description                                           |
| ------------ | ----------------------------------------------------- |
| **Provider** | DeepL Official                                        |
| **Use Case** | High-quality translation, glossary support            |
| **Integration** | Combined with xcomet-mcp-server for translation workflow |

#### Main Tools

- `translate-text` - Text translation
- `translate-document` - Document translation
- `rephrase-text` - Text rephrasing
- Glossary support

### hourei-mcp-server (e-gov-law-mcp)

| Item         | Description                                                     |
| ------------ | --------------------------------------------------------------- |
| **Provider** | [ryoooo/e-gov-law-mcp](https://github.com/ryoooo/e-gov-law-mcp) |
| **Use Case** | Japanese law search and article retrieval                       |
| **Integration** | Combined with rfcxml-mcp for law-to-technical-specification mapping |

#### Main Tools

- `search_law` - Law search
- `get_law_data` - Get law details
- `find_law_article` - Article search
- `get_law_revision` - Revision history

#### Achievements

- Created mapping table between Electronic Signature Act and RFC 3161

### mermaid-mcp

| Item         | Description                              |
| ------------ | ---------------------------------------- |
| **Use Case** | Mermaid diagram generation and rendering |
| **Integration** | Document generation workflow          |

### svelte-mcp / shadcn-svelte-mcp

| Item         | Description                                    |
| ------------ | ---------------------------------------------- |
| **Use Case** | Svelte/SvelteKit development support, UI components |
| **Integration** | Frontend development                        |

## MCP Categories

The available MCPs can be organized by their primary function and use case, as shown in the following diagram.

```mermaid
graph TB
    subgraph Standard Reference
        RFC[rfcxml-mcp<br/>IETF RFC]
        W3C[w3c-mcp<br/>Web Standards]
        LAW[hourei-mcp<br/>Japanese Law]
        PDFSPEC[pdf-spec-mcp<br/>PDF Spec]
    end

    subgraph "Translation & Quality"
        DEEPL[deepl-mcp<br/>Translation]
        XCOMET[xcomet-mcp<br/>Quality Evaluation]
    end

    subgraph Development Support
        RXJS[rxjs-mcp<br/>RxJS]
        SVELTE[svelte-mcp<br/>Svelte]
        SHADCN[shadcn-svelte<br/>UI Components]
    end

    subgraph Visualization
        MERMAID[mermaid-mcp<br/>Diagram Generation]
    end

    subgraph Specialized Domains
        EPSG[epsg-mcp<br/>Coordinate Systems]
        PWA[pwa-mcp<br/>PWA]
        PDFREADER[pdf-reader-mcp<br/>PDF Analysis]
    end
```

## Workflow-Based MCP Combinations

### Technical Document Translation Workflow

```mermaid
sequenceDiagram
    participant User as User
    participant Claude as Claude
    participant DeepL as deepl-mcp
    participant xCOMET as xcomet-mcp

    User->>Claude: Translate this technical document
    Claude->>DeepL: translate-text
    DeepL-->>Claude: Translation result
    Claude->>xCOMET: xcomet_evaluate
    xCOMET-->>Claude: Quality score + errors
    alt Score < 0.85
        Claude->>DeepL: Re-translate (with corrections)
    end
    Claude-->>User: High-quality translation
```

### RFC Specification Review Workflow

```mermaid
sequenceDiagram
    participant User as User
    participant Claude as Claude
    participant RFC as rfcxml-mcp
    participant W3C as w3c-mcp

    User->>Claude: Check the WebSocket specification
    Claude->>RFC: get_rfc_structure(6455)
    RFC-->>Claude: Section hierarchy
    Claude->>RFC: get_requirements(6455)
    RFC-->>Claude: MUST/SHOULD requirements
    Claude->>W3C: get_webidl("websockets")
    W3C-->>Claude: WebSocket API definition
    Claude-->>User: Specification summary + checklist
```

### Law-to-Technical-Specification Mapping Workflow

```mermaid
sequenceDiagram
    participant User as User
    participant Claude as Claude
    participant Hourei as hourei-mcp
    participant RFC as rfcxml-mcp

    User->>Claude: Does timestamp implementation comply with Electronic Signature Act?
    Claude->>Hourei: find_law_article(Electronic Signature Act, 2)
    Hourei-->>Claude: Article 2 requirements
    Claude->>RFC: get_requirements(3161)
    RFC-->>Claude: RFC 3161 technical requirements
    Claude->>Claude: Map legal requirements to technical requirements
    Claude-->>User: Compliance status report
```

## Planned MCPs

The following MCPs are currently in the planning phase or under development and represent the future direction of the ecosystem.

| MCP              | Target        | Priority | Notes                    |
| ---------------- | ------------- | -------- | ------------------------ |
| **OpenAPI MCP**  | OpenAPI Spec  | High     | API design support       |
| **OWASP MCP**    | OWASP Top 10  | High     | Security checking        |
| **Angular MCP**  | Angular       | Medium   | Specialized domain usage |
| **NgRx MCP**     | NgRx          | Medium   | State management patterns |
| **ISO MCP**      | ISO Standards | Medium   | International standard reference |
| ~~**PDF Spec MCP**~~ | ~~ISO 32000~~ | ~~Low~~ | âœ… **Published** `@shuji-bonji/pdf-spec-mcp` |
| **BIM/IFC MCP**  | buildingSMART | Low      | Building information modeling |
| **HL7 FHIR MCP** | HL7 FHIR      | Low      | Healthcare information exchange |

## npm Publication Status

The following table lists the MCPs that have been published to npm, including their current versions and descriptions.

| Package                           | Version | Description                     |
| --------------------------------- | ------- | ------------------------------- |
| [`@shuji-bonji/rfcxml-mcp`](https://www.npmjs.com/package/@shuji-bonji/rfcxml-mcp) | v0.4.5  | IETF RFC Structured Reference   |
| [`xcomet-mcp-server`](https://www.npmjs.com/package/xcomet-mcp-server) | v0.3.6  | Translation Quality Evaluation  |
| [`@shuji-bonji/w3c-mcp`](https://www.npmjs.com/package/@shuji-bonji/w3c-mcp) | v0.1.7  | W3C Web Standards               |
| [`@shuji-bonji/epsg-mcp`](https://www.npmjs.com/package/@shuji-bonji/epsg-mcp) | v0.9.8  | EPSG Coordinate Reference Systems |
| [`@shuji-bonji/pdf-spec-mcp`](https://www.npmjs.com/package/@shuji-bonji/pdf-spec-mcp) | v0.2.2  | PDF Specification (ISO 32000)   |
| [`@shuji-bonji/pdf-reader-mcp`](https://www.npmjs.com/package/@shuji-bonji/pdf-reader-mcp) | v0.2.0  | PDF Internal Structure Analysis |

## Reference Links

Here are the key references and resources for MCP catalog information and repositories.

- [npm: @shuji-bonji](https://www.npmjs.com/~shuji-bonji)
- [GitHub: shuji-bonji](https://github.com/shuji-bonji)

---

## Security Considerations for MCP Development

Source: https://shuji-bonji.github.io/ai-agent-architecture/mcp/security/

# Security Considerations for MCP Development

> Organizing security risks and countermeasures for MCP server development and operation.

## About This Document

MCP servers connect to external APIs and databases, which can lead to serious risks without proper security measures. According to LY Corporation's research, many MCPs rely on static API keys, indicating that security practices are still evolving.

This document organizes the main risk categories for MCP server development and operation, and provides specific countermeasures for each. It also leverages **OWASP MCP Top 10 (2025)** as a reliable reference and provides checklists that can be used during development.

## Reference: OWASP MCP Top 10

### Overview

We reference **OWASP MCP Top 10 (2025)** as the security guideline for MCP server development.

| Item           | Content                                   |
| -------------- | ----------------------------------------- |
| **URL**        | https://owasp.org/www-project-mcp-top-10/ |
| **Status**     | Phase 3 - Beta Release and Pilot Testing  |
| **License**    | CC BY-NC-SA 4.0                           |
| **Leaders**    | Vandana Verma Sehgal, Liran Tal           |

> **Note**: This is a separate project from the traditional "OWASP Top 10 (Web Application Vulnerabilities)" and is **a security guideline specifically for MCP server development**.

### Differences from OWASP Top 10

The following table highlights key differences between traditional OWASP Top 10 for web applications and the MCP-specific version.

| Item              | OWASP Top 10 (Traditional)  | OWASP MCP Top 10 (2025)             |
| ----------------- | --------------------------- | ----------------------------------- |
| **Target**        | Web Applications            | MCP Server Development              |
| **Vulnerability Examples** | SQLi, XSS, CSRF    | Token Mismanagement, Tool Poisoning |
| **Use Case**      | Web Security Audits         | Design Guidelines for MCP Development |

### OWASP MCP Top 10 List

The ten vulnerability categories are organized into thematic groups as illustrated below.

```mermaid
mindmap
  root((OWASP MCP<br/>Top 10))
    Authentication & Authorization
      MCP01: Token Mismanagement
      MCP02: Privilege Escalation
      MCP07: Insufficient Auth
    Supply Chain
      MCP03: Tool Poisoning
      MCP04: Supply Chain Attacks
      MCP09: Shadow MCP Servers
    Injection
      MCP05: Command Injection
      MCP06: Prompt Injection
    Data & Monitoring
      MCP08: Lack of Audit
      MCP10: Context Over-Sharing
```

| ID        | Name                                        | Overview                                                                                          |
| --------- | ------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| **MCP01** | Token Mismanagement & Secret Exposure       | Hardcoded credentials, long-lived tokens, credential leakage in logs                              |
| **MCP02** | Privilege Escalation via Scope Creep        | Privilege escalation through loose permission definitions, scope expansion                        |
| **MCP03** | Tool Poisoning                              | Context injection by malicious tools/plugins (rug pull, schema poisoning, tool shadowing)         |
| **MCP04** | Supply Chain Attacks & Dependency Tampering | Tampering with dependencies, modification of agent behavior                                       |
| **MCP05** | Command Injection & Execution               | System command execution through unvalidated input                                                |
| **MCP06** | Prompt Injection via Contextual Payloads    | Text-based injection attacks, attacks targeting the model                                         |
| **MCP07** | Insufficient Authentication & Authorization | Weak identity verification in multi-agent environments                                            |
| **MCP08** | Lack of Audit and Telemetry                 | Difficulty in incident response due to insufficient logging and monitoring                        |
| **MCP09** | Shadow MCP Servers                          | Unauthorized MCP deployment outside security governance (MCP version of Shadow IT)                |
| **MCP10** | Context Injection & Over-Sharing            | Sensitive information disclosure in shared context windows                                        |

### Detailed Vulnerabilities and Countermeasures

#### MCP01: Token Mismanagement & Secret Exposure

**Risk**: Credentials remain in source code, logs, and model memory

```typescript
// âŒ Bad example: Hardcoded
const API_KEY = 'sk-1234567890abcdef';

// âœ… Good example: Retrieved from environment variables
const API_KEY = process.env.DEEPL_API_KEY;
```

**Countermeasures**:

- Retrieve credentials from environment variables or secret management services
- Do not output credentials to logs
- Use short-lived tokens
- Implement token rotation

#### MCP02: Privilege Escalation via Scope Creep

**Risk**: Initially limited permissions expand over time

**Countermeasures**:

- Strictly follow the principle of least privilege
- Conduct regular permission reviews
- Explicitly define required permissions for each tool

#### MCP03: Tool Poisoning

**Risk**: Malicious MCP servers inject harmful information into the context

```
Attack patterns:
â”œâ”€â”€ Rug Pull: Changes to malicious behavior after gaining trust
â”œâ”€â”€ Schema Poisoning: Embedding malicious code in schema definitions
â””â”€â”€ Tool Shadowing: Impersonating and replacing legitimate tools
```

**Countermeasures**:

- Only adopt MCPs from trusted sources
- Conduct source code reviews
- Manage through allowlists

#### MCP04: Supply Chain Attacks & Dependency Tampering

**Risk**: Dependencies are tampered with, modifying agent behavior

**Countermeasures**:

```bash
# Regular vulnerability checks
npm audit
pip-audit

# Use lock files
package-lock.json
poetry.lock
```

#### MCP05: Command Injection & Execution

**Risk**: Unvalidated input is executed as system commands

```typescript
// âŒ Bad example: Direct command execution
exec(`ls ${userInput}`);

// âœ… Good example: Input validation + escaping
const sanitizedInput = sanitize(userInput);
execFile('ls', [sanitizedInput]);
```

**Countermeasures**:

- Validate all inputs
- Use parameterized command execution
- Execute in sandbox environments

#### MCP06: Prompt Injection via Contextual Payloads

**Risk**: Malicious instructions embedded in text alter model behavior

**Countermeasures**:

- Input sanitization
- Context isolation
- Output validation

#### MCP07: Insufficient Authentication & Authorization

**Risk**: Weak identity verification in multi-agent environments

**Countermeasures**:

- Strong authentication mechanisms (OAuth 2.0 recommended)
- Mutual authentication between agents
- Principle of least privilege

#### MCP08: Lack of Audit and Telemetry

**Risk**: Insufficient logging and monitoring makes incident detection and response difficult

**Countermeasures**:

- Implement structured logging
- Configure monitoring and alerts
- Maintain audit trails

#### MCP09: Shadow MCP Servers

**Risk**: Unauthorized MCP servers operate outside security governance

**Countermeasures**:

- Maintain MCP server allowlists
- Conduct regular inventory audits
- Communicate security policies

#### MCP10: Context Injection & Over-Sharing

**Risk**: Sensitive information is unintentionally disclosed in shared context windows

**Countermeasures**:

- Minimize information added to context
- Mask sensitive information
- Consider context isolation

### Relationship with OWASP LLM Top 10

Since MCP works closely with LLMs, **OWASP LLM Top 10** (2025) is also an important reference.

> **Reference**: https://owasp.org/www-project-top-10-for-large-language-model-applications/

#### Overlapping and Related Vulnerabilities

```mermaid
graph LR
    subgraph "OWASP MCP Top 10"
        MCP01[MCP01: Token Mismanagement]
        MCP03[MCP03: Tool Poisoning]
        MCP04[MCP04: Supply Chain]
        MCP06[MCP06: Prompt Injection]
        MCP10[MCP10: Context Over-Sharing]
    end

    subgraph "OWASP LLM Top 10"
        LLM01[LLM01: Prompt Injection]
        LLM05[LLM05: Supply Chain]
        LLM06[LLM06: Sensitive Info Disclosure]
        LLM07[LLM07: Insecure Plugin Design]
        LLM08[LLM08: Excessive Agency]
    end

    MCP06 <-->|"Overlap"| LLM01
    MCP04 <-->|"Overlap"| LLM05
    MCP10 <-->|"Overlap"| LLM06
    MCP03 <-->|"Overlap"| LLM07
    MCP01 -.->|"Related"| LLM08
```

| MCP Top 10                  | LLM Top 10                              | Relationship                                |
| --------------------------- | --------------------------------------- | ------------------------------------------- |
| MCP06: Prompt Injection     | LLM01: Prompt Injection                 | **Complete overlap** - Same threat          |
| MCP04: Supply Chain         | LLM05: Supply Chain Vulnerabilities     | **Complete overlap** - Dependency vulnerabilities |
| MCP10: Context Over-Sharing | LLM06: Sensitive Information Disclosure | **Highly related** - Sensitive information leakage paths |
| MCP03: Tool Poisoning       | LLM07: Insecure Plugin Design           | **Highly related** - Plugin/tool security   |
| MCP02: Privilege Escalation | LLM08: Excessive Agency                 | **Related** - Excessive permissions/autonomy |

#### LLM Top 10 Overview

The following table provides a summary of all ten LLM vulnerabilities and their relationship to MCP security concerns.

| ID    | Vulnerability                    | Overview                                      | MCP Related       |
| ----- | -------------------------------- | --------------------------------------------- | ----------------- |
| LLM01 | Prompt Injection                 | Manipulating model behavior through malicious input | MCP06             |
| LLM02 | Insecure Output Handling         | Improper handling of outputs                  | Tool output handling |
| LLM03 | Training Data Poisoning          | Contamination of training data                | -                 |
| LLM04 | Model Denial of Service          | Resource exhaustion attacks                   | Context exhaustion |
| LLM05 | Supply Chain Vulnerabilities     | Supply chain attacks                          | MCP04             |
| LLM06 | Sensitive Information Disclosure | Leakage of sensitive information              | MCP10             |
| LLM07 | Insecure Plugin Design           | Vulnerable plugin design                      | MCP03             |
| LLM08 | Excessive Agency                 | Excessive autonomy and permissions            | MCP02             |
| LLM09 | Overreliance                     | Excessive dependence on LLM outputs           | -                 |
| LLM10 | Model Theft                      | Theft of the model                            | -                 |

#### Why Both Should Be Referenced

Understanding both frameworks is essential for comprehensive security, as MCP development spans both MCP-specific concerns and broader LLM application security.

```
MCP server development requires both perspectives:

OWASP MCP Top 10
â””â”€â”€ Security of the MCP server "itself"
    â”œâ”€â”€ Tool definition safety
    â”œâ”€â”€ Credential management
    â””â”€â”€ Supply chain

OWASP LLM Top 10
â””â”€â”€ Security of LLM applications "using" MCP
    â”œâ”€â”€ Prompt injection countermeasures
    â”œâ”€â”€ Output validation
    â””â”€â”€ Permission restrictions
```

## Current State of MCP Security

### LY Corporation Research Findings

Results from LY Corporation's investigation of the MCP ecosystem are presented below, revealing important trends in authentication practices.

| Item                           | Percentage | Risk                                    |
| ------------------------------ | ---------- | --------------------------------------- |
| Requires some form of authentication | **88%**    | Credential management is necessary      |
| Relies on static API keys/PATs | **53%**    | Risk of long-lived token leakage        |
| Uses secure methods like OAuth | **8.5%**   | Most use legacy methods                 |

**Conclusion**: MCP server authentication is still evolving and requires careful management.

## Risk Categories (Traditional Organization)

MCP security risks can be organized into four major categories, as visualized in the following mind map.

```mermaid
mindmap
  root((MCP Security<br/>Risks))
    Authentication & Authorization
      API Key Leakage
      Excessive Permissions
      Token Management
    Data
      Sensitive Information Exposure
      Insufficient Input Validation
      Leakage to Logs
    Supply Chain
      Malicious MCPs
      Dependency Packages
      Update Reliability
    Operations
      Configuration Errors
      Insufficient Monitoring
      Incident Response
```

## Risk 1: Authentication & Authorization

### Problems

- **Long-term use of static API keys** - High impact when leaked
- **Excessive permissions** - Requesting more scopes than necessary
- **Hardcoded credentials** - Written directly in source code

### Countermeasures

#### 1. Secure Credential Management

```bash
# âŒ Bad example: Hardcoded
export API_KEY="sk-1234567890abcdef"

# âœ… Good example: Environment variables (.env file in .gitignore)
# .env
DEEPL_API_KEY=${DEEPL_API_KEY}

# Even better: Secret management services
# AWS Secrets Manager, HashiCorp Vault, etc.
```

#### 2. Principle of Least Privilege

```markdown
## Permission Checklist for MCP Tool Design

- [ ] Is that permission really necessary?
- [ ] Don't request write permissions if read-only access is sufficient
- [ ] Minimize scope
```

#### 3. Token Rotation

```mermaid
flowchart LR
    A[Initial Token Issuance] --> B[Regular Rotation]
    B --> C[Old Token Revocation]
    C --> D[New Token Usage]
    D --> B
```

## Risk 2: Data Security

### Problems

- **Sending sensitive information via MCP** - Unintended data exposure
- **Insufficient input validation** - Injection attacks
- **Sensitive information leakage to logs** - Credentials in debug logs

### Countermeasures

#### 1. Input Validation

```typescript
// Input validation example for MCP tool implementation
export const getRfcRequirements = {
	name: 'get_requirements',
	description: 'Get RFC requirements',
	inputSchema: {
		type: 'object',
		properties: {
			rfc: {
				type: 'number',
				minimum: 1,
				maximum: 99999, // Set reasonable range
				description: 'RFC number',
			},
			level: {
				type: 'string',
				enum: ['MUST', 'SHOULD', 'MAY'], // Limit allowed values
				description: 'Requirement level',
			},
		},
		required: ['rfc'],
	},
};
```

#### 2. Log Sanitization

```typescript
// âŒ Bad example
console.log(`API call: key=${apiKey}, query=${query}`);

// âœ… Good example
console.log(`API call: key=*****, query=${query}`);
```

#### 3. Sensitive Data Classification

```markdown
## Data Classification

### Data That Must Not Be Sent

- Credentials (API keys, passwords)
- Personal Identifiable Information (PII)
- Internal confidential information

### Data That May Be Sent

- Public specification references
- General technical information
- Anonymized data
```

## Risk 3: Supply Chain

### Problems

- **Malicious MCP servers** - Malware inclusion
- **Dependency package vulnerabilities** - npm/pip dependencies
- **Update reliability** - Compromised packages

### Countermeasures

#### 1. MCP Allowlist

Referencing LY Corporation's approach:

```markdown
## Approved MCP Server List

### Official / Trusted Sources

- @modelcontextprotocol/\* (Anthropic official)
- DeepL official MCP

### Self-developed (Internally audited)

- @shuji-bonji/rfcxml-mcp
- @shuji-bonji/xcomet-mcp-server

### Pending Approval

- (Under security review)

### Prohibited

- MCPs of unknown origin
- MCPs that send credentials externally
```

#### 2. Dependency Auditing

```bash
# Check vulnerabilities with npm audit
npm audit

# Regular updates
npm update

# Address critical vulnerabilities immediately
npm audit fix
```

#### 3. Source Code Review

```markdown
## Pre-deployment Checklist for MCP Servers

- [ ] Is the source code publicly available?
- [ ] Are credentials handled appropriately?
- [ ] Are there any suspicious external communications?
- [ ] Are the dependencies trustworthy?
- [ ] Is maintenance ongoing?
```

## Risk 4: Operational Security

### Problems

- **Configuration errors** - Misconfigurations in production
- **Insufficient monitoring** - Delayed anomaly detection
- **Incident response** - Inadequate response procedures

### Countermeasures

#### 1. Environment Isolation

```mermaid
graph LR
    subgraph Development Environment
        DEV_MCP[MCP Server<br/>Test API]
    end

    subgraph Production Environment
        PROD_MCP[MCP Server<br/>Production API]
    end

    DEV_MCP -.->|"Do not reuse configurations"| PROD_MCP
```

#### 2. Logging & Monitoring

```markdown
## Items to Monitor

- [ ] Abnormal increase in API call volume
- [ ] Rising error rates
- [ ] Frequent authentication failures
- [ ] Access to unexpected endpoints
```

#### 3. Incident Response Procedures

```markdown
## MCP Security Incident Response

### 1. Detection

- Monitoring alerts
- User reports
- External notifications

### 2. Initial Response

- Immediately disable the affected MCP
- Revoke API keys/tokens
- Identify scope of impact

### 3. Investigation

- Log analysis
- Identify intrusion path
- Identify leaked data

### 4. Recovery

- Issue new credentials
- Fix configurations
- Re-enable the MCP

### 5. Prevention

- Root cause analysis
- Implement countermeasures
- Update procedures
```

## Security Checklist for MCP Development

### Design Phase

```markdown
- [ ] Is the principle of least privilege applied?
- [ ] Is the authentication method appropriate? (OAuth recommended)
- [ ] Is handling of sensitive data defined?
- [ ] Has OWASP MCP Top 10 been reviewed?
```

### Implementation Phase

```markdown
- [ ] Is input validation implemented? (MCP05 countermeasure)
- [ ] Are credentials not hardcoded? (MCP01 countermeasure)
- [ ] Are sensitive information not output to logs? (MCP01 countermeasure)
- [ ] Do error messages not contain internal information?
- [ ] Have dependencies been audited? (MCP04 countermeasure)
```

### Testing Phase

```markdown
- [ ] Has security testing been performed?
- [ ] Have dependency vulnerabilities been checked?
- [ ] Has behavior against abnormal input been verified?
- [ ] Has resistance to prompt injection been confirmed? (MCP06 countermeasure)
```

### Operations Phase

```markdown
- [ ] Is there a credential rotation plan?
- [ ] Are monitoring and alerts configured? (MCP08 countermeasure)
- [ ] Are incident response procedures in place?
- [ ] Are regular security reviews conducted?
- [ ] Is an MCP server allowlist maintained? (MCP09 countermeasure)
```

## Security Policy Example for CLAUDE.md

```markdown
# Security Policy

## References

- OWASP MCP Top 10: https://owasp.org/www-project-mcp-top-10/

## Prohibited MCPs

- MCP servers of unknown origin
- MCPs that send credentials externally

## Credential Handling

- Retrieve API keys from environment variables
- Do not output credentials to logs
- Do not hardcode credentials in code

## Data Handling

- Do not send personal information via MCP
- Anonymize internal confidential information before processing
```

## Summary

### Key Principles

These seven key principles form the foundation of MCP security best practices.

1. **Reference OWASP MCP Top 10** - The reliable reference for MCP server development
2. **Use only trusted MCPs** - Manage through allowlists
3. **Least privilege** - Grant only necessary permissions
4. **Secure credential management** - No hardcoding, implement rotation
5. **Input validation** - Validate all inputs
6. **Monitoring and logging** - Anomaly detection, but exclude sensitive information
7. **Incident response** - Prepare procedures in advance

### MCP Security Maturity

MCP security can be assessed through different maturity levels, with progression indicated in the following diagram.

```mermaid
graph LR
    L1[Level 1<br/>Unmanaged] --> L2[Level 2<br/>List Management]
    L2 --> L3[Level 3<br/>Monitoring & Auditing]
    L3 --> L4[Level 4<br/>Automation]
```

Currently, aiming for **Level 2 (List Management)** is realistic.

## Reference Links

### OWASP Related

- [OWASP MCP Top 10](https://owasp.org/www-project-mcp-top-10/) - MCP Server Development Security
- [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/) - LLM Application Security
- [OWASP API Security Top 10](https://owasp.org/API-Security/) - API Security
- [OWASP Top 10](https://owasp.org/www-project-top-ten/) - Web Application Security

### Other References

- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework) - AI Risk Management Framework
- [MITRE ATLAS](https://atlas.mitre.org/) - AI Threat Matrix
- [LY Corporation's MCP Use Cases](https://techblog.lycorp.co.jp/) - Enterprise MCP Operations

---

## MCP Development Guide

Source: https://shuji-bonji.github.io/ai-agent-architecture/mcp/development/

# MCP Development Guide

> A practical guide from planning and design through implementation to publishing MCP servers.

## About This Document

This is a practical guide for not just "using" MCP servers but "creating" them. Based on experience building 7 MCP servers, we have systematized the knowledge gainedâ€”including decision criteria at the planning stage, architectural patterns during design, best practices for implementation, and the workflow for npm publishing.

The goal is to make the decision of "should this really be an MCP?" before building, and if the answer is yes, to enable you to build a high-quality server in the shortest time possible.

## Prerequisites

Before reading this document, it is desirable to have an understanding of the following:

- [MCP/Skills/Agent Architecture](../concepts/03-architecture.md) â€” Overview of the three-tier architecture
- [MCP vs Skills Selection Guide](../skills/vs-mcp.md) â€” What should be MCP
- [MCP Security](./security.md) â€” OWASP MCP Top 10

## Decision: Should This Be MCP?

### Decision Flow

```mermaid
flowchart TD
    START[New feature needed] --> Q1{External data source/<br/>API access needed?}

    Q1 -->|No| NOT_MCP[Not MCP<br/>â†’ Skill or sub-agent]
    Q1 -->|Yes| Q2{Official MCP<br/>already exists?}

    Q2 -->|Yes| USE_OFFICIAL[Use official MCP]
    Q2 -->|No| Q3{Official CLI available?}

    Q3 -->|Yes| Q4{Complex authentication?<br/>OAuth etc.}
    Q4 -->|No| CLI_SKILL[CLI + Skill approach<br/>Token efficiency â—Ž]
    Q4 -->|Yes| BUILD[Build MCP]

    Q3 -->|No| BUILD

    style NOT_MCP fill:#90EE90,color:#333
    style CLI_SKILL fill:#90EE90,color:#333
    style BUILD fill:#FFB6C1,color:#333
    style USE_OFFICIAL fill:#87CEEB,color:#333
```

### Decision Criteria Checklist

Use the following checklist to systematically evaluate whether building an MCP is the right choice for your use case.

```markdown
## MCP Development Decision

### Conditions When MCP Should Be Built (Consider building if all are Yes)
- [ ] Access to external data sources or APIs is required
- [ ] Official MCP does not exist
- [ ] Official CLI is insufficient (complex authentication, missing features, etc.)
- [ ] Used repeatedly (not just once)

### Conditions When MCP Should NOT Be Built (Use alternative if any is Yes)
- [ ] Team internal guidelines â†’ Skill
- [ ] Static knowledge/principles â†’ Skill
- [ ] Official CLI is sufficient â†’ CLI + Skill
- [ ] Simple one-time processing â†’ Script
```

> See [MCP vs Skills Selection Guide](../skills/vs-mcp.md) for details

## MCP Design Based on "Authoritative Reference Sources"

### Core Philosophy

The greatest value of MCP is providing AI with structured access to **authoritative information sources**.

```
MCP Value = "Authoritative Reference Sources" Ã— Structured Ã— Accessibility

Information generated by AI alone â†’ Risk of hallucination
Information sourced from "authoritative reference sources" â†’ Accurate, verifiable
```

### Four-Layer Hierarchy of Reference Sources and MCP

| Layer | Reference Source | MCP Example | Build Priority |
| --- | --- | --- | --- |
| 1 | International standards / Regulations | rfcxml-mcp, pdf-spec-mcp | Highest |
| 2 | Industry standards / De facto | w3c-mcp, (OpenAPI MCP) | High |
| 3 | Organization / Project guidelines | â€” (handled by Skill) | â€” |
| 4 | Best practices | â€” (handled by Skill) | â€” |

**Important**: Layers 1 and 2 are suited for MCP, while layers 3 and 4 are suited for Skills.

> See [Taxonomy of "Authoritative Reference Sources"](../concepts/02-reference-sources.md) for details

## Design Phase

### Architecture Patterns

Based on experience building MCPs, we recommend the following three architecture patterns.

#### Pattern 1: Local Data Type

Data is embedded in the package and operates without external communication.

```mermaid
graph LR
    CLIENT[MCP Client] -->|JSON-RPC| SERVER[MCP Server]
    SERVER --> DATA[(Local Data<br/>JSON/SQLite)]

    style DATA fill:#90EE90,color:#333
```

| Characteristic | Description |
| --- | --- |
| **Communication** | None (offline operation) |
| **Data** | Embedded in package |
| **Advantages** | Fast, no authentication required, privacy |
| **Use Cases** | epsg-mcp, pdf-spec-mcp |

#### Pattern 2: External API Type

Calls external APIs and returns structured results.

```mermaid
graph LR
    CLIENT[MCP Client] -->|JSON-RPC| SERVER[MCP Server]
    SERVER -->|HTTP/HTTPS| API[External API]

    style API fill:#FFB6C1,color:#333
```

| Characteristic | Description |
| --- | --- |
| **Communication** | HTTP requests to external APIs |
| **Data** | Fetched in real-time |
| **Advantages** | Always up-to-date, handles large-scale data |
| **Use Cases** | rfcxml-mcp (RFC Editor XML), w3c-mcp |

#### Pattern 3: Model Loading Type

Loads ML models and performs inference.

```mermaid
graph LR
    CLIENT[MCP Client] -->|JSON-RPC| SERVER[MCP Server]
    SERVER --> MODEL[ML Model<br/>Persistent Load]

    style MODEL fill:#87CEEB,color:#333
```

| Characteristic | Description |
| --- | --- |
| **Communication** | None (local inference) |
| **Data** | Embedded in model |
| **Advantages** | No external dependencies, fast inference (after warmup) |
| **Use Cases** | xcomet-mcp-server |

### Tool Design Principles

#### 1. Single Responsibility

One tool = One clear responsibility.

```typescript
// âœ… Good example: Clear responsibilities
get_rfc_structure    // Section hierarchy only
get_requirements     // MUST/SHOULD requirements only
validate_statement   // Compliance verification only

// âŒ Bad example: Ambiguous responsibilities
get_rfc_everything   // All-in-one
```

#### 2. Progressive Detail Discovery

Tool design that allows information retrieval in the order: overview â†’ details.

```mermaid
graph LR
    OVERVIEW[Overview<br/>get_structure] --> DETAIL[Details<br/>get_section]
    DETAIL --> SPECIFIC[Specialized<br/>get_requirements]
```

```typescript
// Step 1: Understand structure
get_rfc_structure(6455)          // â†’ List of sections

// Step 2: Deep dive into specific section
get_section(6455, "5.2")         // â†’ Section content

// Step 3: Extract requirements
get_requirements(6455, "MUST")   // â†’ MUST requirements only
```

#### 3. Input Validation

Implement validation for all tool inputs.

```typescript
const schema = {
  type: 'object',
  properties: {
    rfc: {
      type: 'number',
      minimum: 1,
      maximum: 99999,
      description: 'RFC number'
    },
    level: {
      type: 'string',
      enum: ['MUST', 'SHOULD', 'MAY'],
      description: 'Requirement level'
    }
  },
  required: ['rfc']
};
```

> For security details, see [MCP Security](./security.md) section MCP05 (Command Injection)

#### 4. Response Design

Provide both structured output and human-readable output.

```typescript
// Switch via response_format parameter
tool: get_requirements
params:
  rfc: 6455
  response_format: "json"     // â†’ Structured data
  // or
  response_format: "markdown" // â†’ Human-readable Markdown
```

### Tool Count Guidelines

The following guidelines provide recommended ranges for tool count based on MCP complexity and scope.

```
Small MCP: 3-5 tools (single data source)
Medium MCP: 5-10 tools (multiple views)
Large MCP: 10-15 tools (3-tier structure)

Example: pdf-reader-mcp (15 tools)
â”œâ”€â”€ Basic Operations Layer (5): read_text, read_images, search_text, ...
â”œâ”€â”€ Structure Inspection Layer (5): inspect_structure, inspect_tags, ...
â””â”€â”€ Validation/Analysis Layer (5): validate_tagged, validate_metadata, ...
```

## Implementation Phase

### Technology Stack

| Component | Recommended | Rationale |
| --- | --- | --- |
| **Language** | TypeScript | Type safety, MCP SDK support |
| **SDK** | `@modelcontextprotocol/sdk` | Official SDK |
| **Build** | tsup / esbuild | Fast builds |
| **Testing** | Vitest | TypeScript friendly |
| **Package Management** | npm | Standard for MCP distribution |

### Project Structure

```
my-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Entry point
â”‚   â”œâ”€â”€ server.ts             # MCP server definition
â”‚   â”œâ”€â”€ tools/                # Tool implementations
â”‚   â”‚   â”œâ”€â”€ search.ts
â”‚   â”‚   â”œâ”€â”€ get-detail.ts
â”‚   â”‚   â””â”€â”€ validate.ts
â”‚   â”œâ”€â”€ data/                 # Data and parsers
â”‚   â”‚   â”œâ”€â”€ loader.ts
â”‚   â”‚   â””â”€â”€ parser.ts
â”‚   â””â”€â”€ utils/                # Utilities
â”‚       â””â”€â”€ format.ts
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vitest.config.ts
â””â”€â”€ README.md
```

### Implementation Checklist

```markdown
## Before Implementation
- [ ] Define tool list and schemas
- [ ] Determine input validation rules
- [ ] Design response format (JSON / Markdown)
- [ ] Decide on error handling policy

## During Implementation
- [ ] Review OWASP MCP Top 10 (especially MCP01, MCP05)
- [ ] Implement input validation for all tools
- [ ] Implement structured error responses
- [ ] Ensure logs don't contain sensitive information

## After Implementation
- [ ] Create unit tests (80%+ coverage)
- [ ] Create E2E tests (main flows)
- [ ] Create README.md (tool list, usage examples)
- [ ] Create CHANGELOG.md
```

## Testing Phase

### Test Strategy

```mermaid
graph TB
    subgraph Unit Tests
        PARSER[Parser Tests]
        VALIDATE[Validation Tests]
        FORMAT[Format Tests]
    end

    subgraph Integration Tests
        TOOL[Tool Call Tests]
        DATA[Data Retrieval Tests]
    end

    subgraph E2E Tests
        FLOW[Workflow Tests]
        MCP_PROTO[MCP Protocol Tests]
    end

    Unit Tests --> Integration Tests --> E2E Tests
```

### Test Results (Reference Values)

| MCP | Unit Tests | E2E | Total |
| --- | --- | --- | --- |
| pdf-reader-mcp | 39 | 146 | 185 |
| rfcxml-mcp | â€” | â€” | â€” |
| epsg-mcp | â€” | â€” | â€” |

### Importance of E2E Tests

The interface of an MCP server is everythingâ€”"tool call â†’ response". Running E2E tests via actual MCP protocol is critical for quality assurance.

```typescript
// E2E test example
describe('rfcxml-mcp E2E', () => {
  it('should get RFC structure', async () => {
    const result = await callTool('get_rfc_structure', { rfc: 6455 });
    expect(result.sections).toBeDefined();
    expect(result.sections.length).toBeGreaterThan(0);
  });

  it('should extract MUST requirements', async () => {
    const result = await callTool('get_requirements', {
      rfc: 6455,
      level: 'MUST'
    });
    expect(result.requirements.length).toBeGreaterThan(0);
  });
});
```

## Publishing Phase

### npm Publishing Flow

```mermaid
flowchart LR
    DEV[Development Complete] --> TEST[Tests Pass]
    TEST --> VERSION[Versioning<br/>semver]
    VERSION --> BUILD[Build]
    BUILD --> PUBLISH[npm publish]
    PUBLISH --> README_UPDATE[Update README]
    README_UPDATE --> ANNOUNCE[Announce]
```

### package.json Design

A well-structured package.json is essential for npm publishing and defining your MCP's configuration and dependencies.

```json
{
  "name": "@shuji-bonji/my-mcp",
  "version": "0.1.0",
  "description": "MCP server for ...",
  "type": "module",
  "bin": {
    "my-mcp": "dist/index.js"
  },
  "files": ["dist"],
  "keywords": ["mcp", "model-context-protocol"],
  "engines": {
    "node": ">=18"
  },
  "scripts": {
    "build": "tsup src/index.ts --format esm",
    "test": "vitest",
    "prepublishOnly": "npm run build && npm test"
  }
}
```

### Versioning Policy

| Version Change | Timing | Example |
| --- | --- | --- |
| **patch** (0.0.x) | Bug fixes, documentation updates | 0.1.0 â†’ 0.1.1 |
| **minor** (0.x.0) | New tools added, features enhanced | 0.1.1 â†’ 0.2.0 |
| **major** (x.0.0) | Breaking changes, tool schema changes | 0.9.0 â†’ 1.0.0 |

### README.md Structure

A good README determines first impressions of users. We recommend the following structure:

```markdown
# my-mcp

> One-line description

## Features

## Quick Start

## Available Tools

| Tool | Description |
|------|-------------|

## Examples

## Configuration

## Development

## License
```

## Lessons Learned from Built MCPs

### Lesson 1: Data Preprocessing Determines Quality

In rfcxml-mcp, instead of directly parsing RFC Editor XML, we designed it to structure the data first before passing it to tools. This significantly improved response speed and accuracy.

### Lesson 2: response_format Should Be Designed From the Start

In pdf-reader-mcp, we added the `response_format` parameter partway through. We should have designed it from the beginning to output both "JSON (for programs) and Markdown (for humans)".

### Lesson 3: Tool Granularity Should Enable Progressive Detail Discovery

The 9 tools in epsg-mcp were designed to follow a progressive information retrieval flow: `search â†’ detail â†’ recommend â†’ validate`. This allows users to drill down only to the depth they need, optimizing token consumption.

### Lesson 4: E2E Tests From the Beginning

The 185 tests in pdf-reader-mcp (146 of which are E2E) serve as proof of quality. E2E tests guarantee that the tool "works as expected via the MCP protocol", providing confidence during refactoring.

### Lesson 5: Model Loading Type Requires Careful Initialization Strategy

xcomet-mcp-server uses persistent ML model loading. The first startup is slow, but subsequent inferences are fast. Progress display during startup and timeout settings are critical.

## MCP Coverage by Development Phase

Current MCPs mainly cover the "implementation" phase. The direction of future coverage expansion is as follows, visualized in the diagram below.

```mermaid
graph LR
    subgraph "Coverage: Low"
        STRATEGY[Strategy/Planning]
        OPS[Operations/Maintenance]
    end

    subgraph "Coverage: Medium"
        DESIGN[Design]
        TEST[Testing]
    end

    subgraph "Coverage: High"
        IMPL[Implementation]
        DOC[Documentation]
    end

    STRATEGY --> DESIGN --> IMPL --> TEST --> DOC --> OPS

    style STRATEGY fill:#FFB6C1,color:#333
    style OPS fill:#FFB6C1,color:#333
    style DESIGN fill:#FFE4B5,color:#333
    style TEST fill:#FFE4B5,color:#333
    style IMPL fill:#90EE90,color:#333
    style DOC fill:#90EE90,color:#333
```

> See [Development Phases Ã— MCP Support](../workflows/development-phases.md) for details

## Related Documents

- [Built MCP Catalog](./catalog.md) â€” List and details of built MCPs
- [MCP Security](./security.md) â€” OWASP MCP Top 10
- [MCP/Skills/Agent Architecture](../concepts/03-architecture.md) â€” Three-tier architecture
- [MCP vs Skills Selection Guide](../skills/vs-mcp.md) â€” What should be MCP
- [Integration Patterns and Workflows](../workflows/patterns.md) â€” Workflows utilizing MCP
- [Anti-patterns Collection](../skills/anti-patterns.md) â€” Patterns to avoid

## Reference Links

- [Model Context Protocol Official](https://modelcontextprotocol.io/)
- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)
- [MCP Inspector](https://github.com/modelcontextprotocol/inspector) â€” Debugging tool for MCP servers
- [npm: @shuji-bonji](https://www.npmjs.com/~shuji-bonji) â€” Published packages

---

## What are Skills?

Source: https://shuji-bonji.github.io/ai-agent-architecture/skills/what-is-skills/

# What are Skills?

> A static knowledge layer that provides AI agents with domain expertise, guidelines, and decision criteria.

## About This Document

This document explains the fundamental concepts, types, benefits, and limitations of Skills. For instructions on creating Skills, refer to [creating-skills.md](./creating-skills.md).

## What are Skills?

**Vercel Skills** is a standardized framework for expressing domain knowledge designed for AI agents.

Unlike MCPs, Skills enable agents to acquire and leverage **executable know-how specific to a domain or task**.

### Key Information

Here is a summary of Skills' essential details.

- **Specification**: Agent Skills Specification (https://agentskills.io)
- **Format**: Markdown file (`SKILL.md`)
- **Location**:
  - Project-level: `.claude/skills/xxx/SKILL.md`
  - User-level: `~/.claude/skills/xxx/SKILL.md`
- **One-line description**: "A mechanism to teach AI **what it should know**"

### Four Key Characteristics of Skills

The core characteristics of Skills are the following four points.

- **Knowledge Base**: Structures domain expertise and best practices that AI should reference
- **Executable Guidelines**: Clarifies decision criteria and proceduresâ€”not abstract rules
- **Scoped Management**: Organize knowledge at the project or team level
- **Evolutionary Learning**: Continuously updatable based on feedback

## Why Separate "Knowledge"?

### The Problem

AI agents have broad general knowledge, but lack:

- Rules specific to your project
- Your team's quality standards and decision criteria
- Domain-specific expertise
- Your organization's best practices

### The Solution

By structuring knowledge as Skills and exposing it to your AI agent, the agent can make **project-specific decisions**.

### How Skills Differ from MCPs

The following table compares Skills and MCPs side by side.

| Perspective    | MCP                               | Skills                                          |
| -------------- | --------------------------------- | ----------------------------------------------- |
| Provides       | "What can be done" (tools & APIs) | "What should be known" (knowledge & guidelines) |
| Implementation | Server (dynamic)                  | Markdown or JSON (static)                       |
| Use Case       | External service integration      | Internal knowledge alignment                    |

### Architecture Diagram

The diagram below illustrates how Agent, Skills, and MCP interact as three layers. Skills serve as the intermediate knowledge layer.

```mermaid
block-beta
    columns 1

    block:AGENT_BLOCK:1
        A["Agent<br/>Decision & Orchestration"]
    end

    space

    block:SKILLS_BLOCK:1
        S["Skills â† Here<br/>Knowledge, Guidelines, Decision Criteria"]
    end

    space

    block:MCP_BLOCK:1
        M["MCP<br/>External Tools & APIs"]
    end

    A --"Reference"--> S
    A --"Execute"--> M

    style A fill:#87CEEB,color:#333,stroke:#333
    style S fill:#90EE90,color:#333,stroke:#333
    style M fill:#FFB6C1,color:#333,stroke:#333
```

## Types of Skills

Skills can be classified by their purpose:

| Type                | Description                      | Examples                                                   |
| ------------------- | -------------------------------- | ---------------------------------------------------------- |
| Workflow Definition | Defines procedures and processes | Translation workflow, code review process                  |
| Quality Criteria    | Defines thresholds and standards | Translation quality score â‰¥ 0.85, test coverage thresholds |
| Guideline           | Best practices and principles    | Coding conventions, naming rules                           |
| Template            | Defines standard output formats  | Documentation templates, PR description templates          |

You can combine these types to create more sophisticated Skills.

## Skill Components

### Metadata (YAML Front Matter)

Skill files begin with metadata in YAML format. Below is an example from the translation quality Skill.

```yaml
name: translation-quality
version: 1.0.0
description: Translation Quality Assessment Guidelines
author: @shuji-bonji
tags:
  - translation
  - quality-assurance
  - deepl
agent-support:
  - claude-code
  - cursor
```

### Required Sections

Following the metadata, the following sections are recommended in the body of the Skill document.

| Section               | Content                                    | Example                                                                |
| --------------------- | ------------------------------------------ | ---------------------------------------------------------------------- |
| **Purpose**           | Purpose, background, and rationale         | "Ensure consistent translation quality with a minimum score of 0.85"   |
| **Inputs / Outputs**  | Input and output definitions               | Input: source text / Output: translated text + quality score           |
| **Constraints**       | Constraints using MUST / SHOULD / MUST NOT | MUST: score â‰¥ 0.85 / MUST NOT: rely on automated translation alone     |
| **Workflow**          | Concrete steps and procedures              | "1. Perform machine translation, 2. Native review, 3. Calculate score" |
| **Decision Criteria** | Decision thresholds and criteria           | Score formula, quality metric definitions                              |
| **Examples**          | Concrete use cases and examples            | Good examples, anti-examples                                           |
| **Anti-Patterns**     | Examples of what not to do                 | "Literal translation ignoring context"                                 |

## Benefits

Skills adoption provides the following advantages:

- âœ… **Low Context Overhead**: Loaded only when referenced; doesn't run constantly like MCPs
- âœ… **Editable by Anyone**: Markdown format allows updates without coding knowledge
- âœ… **Immediate Effect**: Changes apply on the next interaction after saving
- âœ… **Knowledge Consolidation**: Makes implicit, often-siloed knowledge explicit and visible
- âœ… **Standards Compliance**: Interoperability based on Agent Skills Specification
- âœ… **Version Control**: Easy history tracking with Git

## Drawbacks and Limitations

Skills have the following constraints:

- âŒ **No Dynamic Processing**: Cannot call external APIs or perform computations (MCPs required)
- âŒ **Static Content**: Cannot reference real-time data
- âŒ **Manual Updates**: Cannot automatically follow external specification changes
- âŒ **Scope Limited**: Project or user level only (global sharing is managed via Git, not npm)

> **Note**: If you need capabilities beyond Skills' scope, refer to [what-is-mcp.md](../mcp/what-is-mcp.md).

## Supported Agents

Skills are available in the following AI agents:

| Agent               | CLI Argument     | Project Path          |
| ------------------- | ---------------- | --------------------- |
| Claude Code         | `claude-code`    | `.claude/skills/`     |
| Cursor              | `cursor`         | `.cursor/skills/`     |
| Codex               | `codex`          | `.codex/skills/`      |
| OpenCode            | `opencode`       | `.opencode/skills/`   |
| GitHub Copilot      | `github-copilot` | `.github/skills/`     |
| Windsurf            | `windsurf`       | `.windsurf/skills/`   |
| Cline               | `cline`          | `.cline/skills/`      |
| Roo Code            | `roo-code`       | `.roo/skills/`        |
| Gemini CLI          | `gemini-cli`     | `.gemini/skills/`     |
| Continue            | `continue`       | `.continue/skills/`   |
| Aide                | `aide`           | `.aide/skills/`       |
| Cosine              | `cosine`         | `.cosine/skills/`     |
| Bolt.new            | `bolt`           | `.bolt/skills/`       |
| Claude.dev          | `claude-dev`     | `.claude-dev/skills/` |
| BasedHardware Agent | `based-hw`       | `.based/skills/`      |
| val-town Agent      | `val-town`       | `.val-town/skills/`   |

Details: https://github.com/vercel-labs/skills#supported-agents

## Integration with Vercel Skills CLI

The Vercel Skills CLI makes it easy to find, add, and manage Skills.

### Finding Skills

Use the `npx skills` command to search the Skill registry.

```bash
npx skills find "code review"
npx skills search "translation"
```

### Adding Skills

Once you find a Skill, add it to your project with the following commands.

```bash
# Add a specific Skill
npx skills add vercel-labs/agent-skills --skill frontend-design

# Add for multiple agents
npx skills add vercel-labs/agent-skills -a claude-code -a cursor

# Register a local Skill
npx skills add ./local-skill
```

### Skill Discovery Flow

The following sequence diagram shows how an agent discovers and applies a Skill.

```mermaid
sequenceDiagram
    participant User
    participant Agent as AI Agent
    participant SkillRepo as Skill Repository
    participant Config as .claude/config.json

    User->>Agent: Task Request
    Agent->>Config: Load Skill List
    Config-->>Agent: Applicable Skills List
    Agent->>SkillRepo: Get Skill Details
    SkillRepo-->>Agent: Skill Metadata + Workflow
    Agent->>Agent: Apply Skill Decision Criteria
    Agent-->>User: Return Result
```

### Skill Dynamic Extension Flow

When existing Skills don't cover a new task requirement, the extension flow below shows how to add one.

```mermaid
flowchart TD
    A["New Task Requirement"] -->|Skill missing| B["Use Skill Template"]
    B --> C["Write Domain Knowledge"]
    C --> D["Create .claude/skills/xxx/SKILL.md"]
    D --> E["Agent Auto-discovers"]
    E --> F["Available from Next Request"]

    style A fill:#FFE4B5,color:#333,stroke:#333
    style B fill:#87CEEB,color:#333,stroke:#333
    style C fill:#87CEEB,color:#333,stroke:#333
    style D fill:#90EE90,color:#333,stroke:#333
    style E fill:#DDA0DD,color:#333,stroke:#333
    style F fill:#FFB6C1,color:#333,stroke:#333
```

## Implementations in This Repository

This repository implements and maintains the following Skills:

### Implemented Skills

| Skill                 | Lines | Description                                                               |
| --------------------- | ----- | ------------------------------------------------------------------------- |
| `translation-quality` | 279   | Translation Quality Assessment Guidelines (with xCOMET score integration) |

### Templates

We provide templates to help you create new Skills quickly.

- `templates/skill/SKILL.ja.md.template` - Template for creating new Skills
- `templates/skill/SKILL.en.md.template` - English version template

### Goals

- **Phase 1**: Define 3+ Skills/Agent implementations (currently 1, planned expansion)
- **Next Skill Candidates**:
  - `translation-workflow` - Translation process definition
  - `rfc-compliance` - RFC specification compliance checks
  - `code-review` - Code review guidelines

## What to Read Next

To learn more about Skills, explore the following documents.

| Purpose                        | Document                                             |
| ------------------------------ | ---------------------------------------------------- |
| Want to create a Skill         | [creating-skills.md](./creating-skills.md)           |
| Deciding between MCP vs Skills | [vs-mcp.md](./vs-mcp.md)                             |
| Anti-patterns                  | [anti-patterns.md](./anti-patterns.md)               |
| Learn about MCPs               | [what-is-mcp.md](../mcp/what-is-mcp.md)              |
| Overall architecture           | [03-architecture.md](../concepts/03-architecture.md) |
| What is Skills (intro)         | [what-is-skills.md](./what-is-skills.md)             |

**Last Updated**: February 2025

**Related Resources**:

- [Agent Skills Specification](https://agentskills.io)
- [Vercel Labs Skills GitHub](https://github.com/vercel-labs/skills)
- [Skill Creation Guide](./creating-skills.md)

---

## Skill Creation Guide

Source: https://shuji-bonji.github.io/ai-agent-architecture/skills/creating-skills/

# Skill Creation Guide

> Creating high-quality Skill definitions and practical best practices.

## About This Document

A Skill is a static Markdown file that provides domain knowledge, guidelines, and decision criteria to AI agents. While MCPs provide "what you can do (tools)," Skills provide "how to execute (knowledge)."

This document explains the full lifecycle of Skills from design through creation, testing, and maintenance. It is based on existing Skills (like `translation-quality`) and templates.

## Positioning of Skills

### Role in Three-Layer Architecture

Skills occupy the middle layer of the AI agent architecture, sitting between the orchestration layer above and the MCP tool layer below. The following diagram illustrates this positioning:

```mermaid
graph TB
    subgraph Agent["Agent Layer"]
        A[Orchestration<br/>Decision & Execution]
    end

    subgraph Skills["Skills Layer â† Here"]
        S[Domain Knowledge<br/>Guidelines & Decision Criteria]
    end

    subgraph MCP["MCP Layer"]
        M[External Tools<br/>APIs & Data Retrieval]
    end

    Agent -->|"Reference"| Skills
    Agent -->|"Execute"| MCP
    Skills -.->|"Define how to use MCPs"| MCP

    style Skills fill:#90EE90,stroke:#333
```

### Cases Where Skills Are Appropriate

The following table identifies scenarios where defining a Skill is the correct choice:

| Case                      | Example                             | Reason                                          |
| ------------------------- | ----------------------------------- | ----------------------------------------------- |
| Defining quality criteria | Translation quality score â‰¥ 0.85    | Criteria are knowledge, not tools               |
| Workflow definition       | Translate â†’ Evaluate â†’ Fix sequence | Procedures are knowledge; MCPs handle execution |
| Coding conventions        | SOLID principles, naming rules      | Team knowledge is static                        |
| Review perspectives       | Security check items                | Check items are knowledge                       |

### Cases Where Skills Are Not Appropriate

The following table identifies when Skills should not be used and what alternative approach is better:

| Case                     | Better Approach | Reason                           |
| ------------------------ | --------------- | -------------------------------- |
| Calling external APIs    | MCP             | Dynamic execution is needed      |
| Real-time data retrieval | MCP             | External communication is needed |
| Complex orchestration    | Sub-agents      | Decision delegation is needed    |

> When unsure, refer to the [MCP vs Skills Decision Guide](./vs-mcp.md)

## Skill Structure

### File Organization

Skills are organized in a directory structure that groups related Skills by name:

```
.claude/skills/
â”œâ”€â”€ translation-quality/       # â† Skill name directory
â”‚   â””â”€â”€ SKILL.md               # â† Body (required)
â”œâ”€â”€ code-review/
â”‚   â””â”€â”€ SKILL.md
â””â”€â”€ translation-workflow/
    â””â”€â”€ SKILL.md
```

### Required Sections in SKILL.md

The following section structure is recommended to ensure Skill quality. This flow diagram shows the logical progression of content:

```mermaid
graph TB
    META[Metadata<br/>name, version, owner] --> PURPOSE[Purpose<br/>Objectives & Background]
    PURPOSE --> IO[Inputs / Outputs<br/>Input/Output Definition]
    IO --> CONSTRAINTS[Constraints<br/>MUST / SHOULD / MUST NOT]
    CONSTRAINTS --> WORKFLOW[Workflow<br/>Concrete Steps]
    WORKFLOW --> CRITERIA[Decision Criteria<br/>Judgment Standards & Thresholds]
    CRITERIA --> EXAMPLES[Examples<br/>Concrete Examples]
    EXAMPLES --> ANTI[Anti-Patterns<br/>What NOT to Do]
    ANTI --> RELATED[Related MCPs<br/>Related MCPs]
```

## Creation Steps

### Step 1: Define Metadata

Describe basic information using YAML Front Matter. This metadata identifies and tracks the Skill throughout its lifecycle:

```yaml
---
name: code-review
description: Code review guidelines for TypeScript/Angular projects
version: 1.0.0
owner: @shuji-bonji
last_reviewed: 2026-02-11
---
```

The following table describes each metadata field:

| Field           | Required | Description                                                   |
| --------------- | -------- | ------------------------------------------------------------- |
| `name`          | âœ…       | Skill identifier (kebab-case)                                 |
| `description`   | âœ…       | One-line description                                          |
| `version`       | âœ…       | Semantic versioning                                           |
| `owner`         | âœ…       | Owner (person responsible for updates)                        |
| `last_reviewed` | âœ…       | Last review date (prevents anti-pattern "unmaintained Skill") |

### Step 2: Write Purpose

Clearly explain why this Skill is needed. Vague descriptions are anti-patterns. Here is the recommended structure:

```markdown
## Purpose

Ensure quality and consistency of code reviews in TypeScript/Angular projects.

### Why This Skill?

- Reviewers often have inconsistent perspectives
- Want to auto-check compliance with SOLID principles and Angular best practices
- Enables consistent review quality even with new team members
```

### Step 3: Define Inputs / Outputs

Clearly specify what the Skill receives and what it produces. Use table format for clarity:

```markdown
## Inputs

| Input          | Type             | Description           |
| -------------- | ---------------- | --------------------- |
| source_files   | TypeScript files | Files to be reviewed  |
| pr_description | Markdown         | PR description text   |
| changed_lines  | diff             | Diff of changed lines |

## Outputs

| Output          | Type     | Description                         |
| --------------- | -------- | ----------------------------------- |
| review_report   | Markdown | Review results report               |
| action_items    | List     | List of required fixes              |
| approval_status | enum     | approve / request-changes / comment |
```

### Step 4: Define Constraints

Define clear constraints using RFC 2119 keywords (MUST/SHOULD/MUST NOT). This establishes the guardrails for execution:

```markdown
## Constraints

### MUST (Required)

- Verify ESLint errors are zero
- Validate type safety (no `any` type usage)
- Require test coverage â‰¥ 80%

### SHOULD (Recommended)

- Verify compliance with Single Responsibility Principle (SRP)
- Check RxJS subscription management
- Recommend Angular ChangeDetectionStrategy.OnPush usage

### MUST NOT (Prohibited)

- Do not skip security-related reviews
- Do not approve code without tests
- Do not leave console.log in production code
```

**Key Point**: Include numeric criteria and specific conditions. Vague descriptions like "write good code" are anti-patterns.

### Step 5: Write Workflow

Describe the concrete steps the agent will execute. Each step should specify a clear action:

```markdown
## Workflow

### Step 1: Understand Changes

Review the PR description and changed file list to understand the goal and scope of the changes.

### Step 2: Static Analysis

Check ESLint and TypeScript compiler results.
If errors exist, immediately return `request-changes`.

### Step 3: Code Quality Check

Verify code from the following perspectives:

1. Compliance with SOLID principles
2. Angular best practices
3. RxJS patterns appropriateness
4. Test coverage

### Step 4: Generate Report

Output verification results as a Markdown report.
```

### Step 6: Define Decision Criteria

Clearly present quantitative decision criteria in a table. These thresholds guide the agent's decision-making:

```markdown
## Decision Criteria

| Condition               | Action                  | Rationale              |
| ----------------------- | ----------------------- | ---------------------- |
| ESLint errors > 0       | âŒ request-changes      | Basic quality not met  |
| `any` type usage found  | âŒ request-changes      | Type safety violation  |
| Coverage < 80%          | âš ï¸ request-changes      | Insufficient tests     |
| Suspected SRP violation | ðŸ’¬ comment              | Improvement suggestion |
| Minor style issues      | âœ… approve with comment | Do not block           |
```

### Step 7: Write Examples

Provide concrete input/output examples. Agents will use these as reference for understanding expected behavior:

```markdown
## Examples

### Example 1: PR with ESLint Errors

**Input:**
PR contains 3 instances of `any` type usage

**Process:**

1. Check ESLint results â†’ 3 errors found
2. Check type safety â†’ violations found

**Output:**
âŒ request-changes

- `src/service.ts:25` - `any` â†’ change to appropriate type
- `src/service.ts:42` - `any` â†’ recommend interface definition
- `src/component.ts:15` - `any` â†’ recommend generic type usage
```

### Step 8: Write Anti-Patterns

Document common mistakes and what to avoid by providing examples of incorrect approaches:

```markdown
## Anti-Patterns

### Pattern: Style-Only Reviews

**Problematic Approach:**
Point out only indentation and naming issues without verifying logic correctness.

**Why It's a Problem:** Miss essential issues.

**Correct Approach:**
Verify in order: Logic â†’ Design â†’ Type Safety â†’ Style.
```

## Template Usage

Templates are available in `templates/skill/`. These provide starting points for common Skill types:

```bash
# Copy template
cp templates/skill/SKILL.ja.md.template .claude/skills/my-skill/SKILL.md
```

Available templates include:

| Template                     | Path                                                  |
| ---------------------------- | ----------------------------------------------------- |
| Japanese template            | `templates/skill/SKILL.ja.md.template`                |
| English template             | `templates/skill/SKILL.md.template`                   |
| Code review example          | `templates/skill/examples/code-review.ja.md`          |
| Translation workflow example | `templates/skill/examples/translation-workflow.ja.md` |

## Real-World Examples of Existing Skills

### translation-quality (Implemented)

A Skill definition with 279 lines exists at `.claude/skills/translation-quality/SKILL.md`. It demonstrates best practices for a well-structured Skill:

```
Structure:
â”œâ”€â”€ Metadata (name, version, owner, last_reviewed)
â”œâ”€â”€ Purpose + Why This Skill?
â”œâ”€â”€ Inputs / Outputs (table format)
â”œâ”€â”€ Constraints (MUST / SHOULD / MUST NOT)
â”œâ”€â”€ Workflow (5 steps)
â”œâ”€â”€ Decision Criteria (average score + segments)
â”œâ”€â”€ Examples (2 patterns: single file / batch directory)
â”œâ”€â”€ Anti-Patterns (2 patterns)
â””â”€â”€ Related MCPs (xcomet, deepl)
```

**Learning Points**:

- Clear thresholds (0.85, 0.90, 0.95)
- Specific workflow (5 steps)
- Output examples in embeddable Markdown format
- Explicit MCP integration

## Skill Quality Checklist

A checklist to verify whether your created Skill is of high quality. Use this to validate completeness and effectiveness:

```markdown
## Basic Checks

- [ ] Metadata (name, version, owner, last_reviewed) is complete
- [ ] Purpose is specific and background is explained
- [ ] Inputs/Outputs are defined in table format

## Constraint Checks

- [ ] MUST/SHOULD/MUST NOT classification is appropriate
- [ ] Numeric criteria and specific conditions are included
- [ ] Vague expressions ("good", "appropriate") are avoided

## Workflow Checks

- [ ] Steps are numbered and clear
- [ ] Each step specifies what to do concretely
- [ ] Decision Criteria are defined in table format

## Example Checks

- [ ] At least one concrete usage example is provided
- [ ] Input â†’ Process â†’ Output flow is shown
- [ ] Anti-Patterns are included

## Design Principle Checks

- [ ] Single Responsibility (1 Skill = 1 responsibility) is maintained
- [ ] Does not depend on internal implementation of specific MCPs
- [ ] Related MCPs are explicitly listed
```

## Lifecycle Management

### Update Cycle

Skills should follow a continuous improvement cycle from creation through ongoing operation. The diagram below shows this process:

```mermaid
flowchart LR
    CREATE[Create] --> USE[Operate]
    USE --> FEEDBACK[Feedback]
    FEEDBACK --> REVIEW[Periodic Review]
    REVIEW --> UPDATE[Update]
    UPDATE --> USE

    REVIEW -->|No issues| USE
```

### Addressing Anti-Pattern: Unmaintained Skills

Prevent Skills from becoming stale by implementing these measures:

| Measure                   | Method                                     |
| ------------------------- | ------------------------------------------ |
| **Specify Owner**         | List responsibility owner in `owner` field |
| **Last Review Date**      | Regularly update `last_reviewed`           |
| **Review Cycle**          | Recommend quarterly review                 |
| **Operational Alignment** | Verify consistency with actual workflows   |

> For details, see [Anti-Patterns Guide](./anti-patterns.md) "6. Unmaintained Skill"

## Compatibility with Vercel Skills CLI

### Agent Skills Specification Support

By creating Skills in a format compatible with Vercel Skills CLI, they become usable with agents beyond Claude Code (Cursor, Windsurf, etc.). The following commands show how to integrate Skills with different agents:

```bash
# For Claude Code
npx skills add ./my-skills -a claude-code

# For multiple agents
npx skills add ./my-skills -a claude-code -a cursor -a windsurf
```

> For details, see [What is Skills](./what-is-skills) "Vercel Skills CLI Integration"

## Roadmap Goals

Current status and targets:

This table shows the current state of Skill development and the targets for Phase 1:

| Metric            | Current                 | Goal (Phase 1) |
| ----------------- | ----------------------- | -------------- |
| Skill definitions | 1 (translation-quality) | 3+             |
| Templates         | âœ… Created              | â€”              |
| Documentation     | âœ… This document        | â€”              |

### Candidate Skills to Create Next

The following Skills are identified as high-priority candidates for future development:

| Skill Name           | Overview                             | Priority | Related MCP   |
| -------------------- | ------------------------------------ | -------- | ------------- |
| translation-workflow | Workflow: Translate â†’ Evaluate â†’ Fix | â­â­â­â­ | deepl, xcomet |
| rfc-compliance       | RFC compliance check guidelines      | â­â­â­â­ | rfcxml        |
| code-review          | TypeScript/Angular review guidelines | â­â­â­   | â€”             |

## Related Documents

- [What is Skills](./what-is-skills) â€” Vercel Skills / Agent Skills Specification
- [MCP vs Skills Decision Guide](./vs-mcp.md) â€” What should be a Skill?
- [Anti-Patterns Guide](./anti-patterns.md) â€” Patterns to avoid
- [MCP/Skills/Agent Architecture](../concepts/03-architecture.md) â€” Three-layer architecture
- [Integration Patterns & Workflows](../workflows/patterns.md) â€” Skill + MCP combination examples

## Reference Links

- [Agent Skills Specification](https://agentskills.io) â€” Standard specification
- [Vercel Skills CLI](https://github.com/vercel-labs/skills) â€” CLI tool
- [templates/skill/](https://github.com/shuji-bonji/ai-agent-architecture/tree/main/templates/skill) â€” Template collection
- [.claude/skills/translation-quality/SKILL.md](https://github.com/shuji-bonji/ai-agent-architecture/blob/main/.claude/skills/translation-quality/SKILL.md) â€” Implementation example

---

## MCP vs Skills: Fundamental Differences and Selection Criteria

Source: https://shuji-bonji.github.io/ai-agent-architecture/skills/vs-mcp/

# MCP vs Skills: Fundamental Differences and Selection Criteria

## Overview Comparison Table

The following table provides a side-by-side comparison of the core attributes distinguishing MCPs from Skills across various operational and strategic dimensions.

| Aspect | MCP | Skills |
| ------ | --- | ------ |
| **Definition** | Model Context Protocol - Standard for external tool and API integration | Agent Skills - Standard for domain knowledge and execution patterns |
| **Primary Use** | Providing access to external systems | Extending agent knowledge and execution capabilities |
| **Implementation Location** | Server process (independent) | Within agent (integrated) |
| **Update Frequency** | Low (stable operation) | High (task and feedback driven) |
| **Operational Responsibility** | Provider (DevOps) | Agent owner (AI/ML team) |

## Fundamental Differences

### MCP: Declares "What Can Be Done"

MCPs act as a bridge between external systems and the agent by exposing their capabilities as callable tools and services. Here is the basic flow:

```
[External System]
    â†“
[MCP Server]
    â†“ (Tool Definition)
[Claude/Agent]
```

MCP **transforms external system capabilities into tools**.

**Example**: Providing RFC search engine to Claude

- MCP Server: IETF RFC full-text search and analysis
- Tools: `search_rfc()`, `get_rfc_details()`
- Usage: "Look up the URI specification in RFC 3986"

### Skills: Teaches "How to Execute"

Skills embed domain knowledge and execution patterns directly into the agent, allowing it to apply best practices and guidelines when making decisions. The following diagram shows how knowledge flows into the agent's decision-making process:

```
[Domain Knowledge]
    â†“
[Skill Representation]
    â†“ (Learn/Execute)
[Claude/Agent]
```

Skills **embed execution patterns and best practices within the agent**.

**Example**: React Frontend Design Skill

- Metadata: Design principles and recommended patterns
- Learning Content: File structure, component hierarchy, testing strategy
- Execution: Agent automatically applies these to new projects

## Selection Decision Flow

### Decision Flowchart

Use this flowchart to navigate the decision process when determining whether a new capability should be implemented as an MCP or a Skill:

```mermaid
flowchart TD
    START[New capability needed] --> Q1{External API/service<br/>required?}

    Q1 -->|Yes| Q1A{Official MCP<br/>exists?}
    Q1A -->|Yes| USE_OFFICIAL[Use official MCP<br/>e.g., @eslint/mcp]
    Q1A -->|No| BUILD_MCP[Build MCP]

    Q1 -->|No| Q2{Domain knowledge/<br/>guidelines?}

    Q2 -->|Yes| Q2A{Team-specific<br/>knowledge?}
    Q2A -->|Yes| PROJECT_SKILL[Project Skill<br/>.claude/skills/]
    Q2A -->|No| GLOBAL_SKILL[Global Skill<br/>~/.claude/skills/]

    Q2 -->|No| Q3{Complex<br/>orchestration?}
    Q3 -->|Yes| SUBAGENT[Define sub-agent]
    Q3 -->|No| BUILTIN[Use built-in features]

    BUILD_MCP --> Q_GUIDE{Usage guide<br/>needed?}
    Q_GUIDE -->|Yes| ADD_SKILL[Add complementary Skill]
    Q_GUIDE -->|No| DONE[Done]

    USE_OFFICIAL --> Q_GUIDE
    ADD_SKILL --> DONE
    PROJECT_SKILL --> DONE
    GLOBAL_SKILL --> DONE
    SUBAGENT --> DONE
    BUILTIN --> DONE
```

### Specific Decision Examples

The following table provides concrete use case examples demonstrating how the decision logic applies in real-world scenarios:

| Use Case | Decision | Reason |
|----------|----------|--------|
| Want to translate using DeepL API | MCP | Requires external API call |
| Want to define translation quality standards | Skill | Domain knowledge and guidelines |
| Want to follow SOLID principles | Skill | Static knowledge |
| Want to check code with ESLint | MCP (official) | @eslint/mcp exists |
| Team coding conventions | Skill (project) | Team-specific knowledge |
| Want to search RFC specifications | MCP | Requires external data retrieval |
| Automate translation â†’ quality evaluation â†’ correction | Sub-agent | Complex orchestration |

### Quick Decision Diagram

Here is a visual representation of the fundamental decision point between MCP and Skills:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  What capability is needed?     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Access to   â”‚ â”‚ Internal knowledge â”‚
â”‚ external    â”‚ â”‚ and patterns       â”‚
â”‚ services    â”‚ â”‚ (team know-how)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                    â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ MCP  â”‚           â”‚ Skills   â”‚
  â””â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Choose MCP

Choose MCP when the capability requires access to or interaction with external systems. The following characteristics indicate MCP is the right choice:

âœ… **Use MCP when:**

- External API or tool integration is needed
- Real-time data retrieval is required
- Integration with third-party systems
- Authentication and token management is necessary

**Examples**:

- `rfcxml-mcp`: IETF RFC search
- `deepl-mcp`: DeepL Translation API
- `github-mcp`: GitHub repository operations

### When to Choose Skills

Choose Skills when you need to embed static domain knowledge, best practices, and execution guidelines into the agent. The following characteristics indicate Skills is the right choice:

âœ… **Use Skills when:**

- Sharing best practices within the team
- Standardizing implementation patterns and design principles
- Agent needs to learn "how to do" something and execute it
- Continuous improvement and feedback cycles

**Examples**:

- `frontend-design`: React/Next.js optimal design
- `doc-coauthoring`: Document co-authoring guidelines
- `testing-strategy`: Testing strategy and coverage requirements

## Anti-Patterns: Over-Allocation

### Over-MCPization: Excessive Use of MCP

This anti-pattern occurs when team knowledge or static information is implemented as an MCP server instead of being defined as a Skill. Here is a concrete example:

âŒ **Anti-pattern example**:

```
// âŒ This should be implemented as Skills, not MCP
- MCP: "Fetch company-wide coding standards"
- Reason: This is team knowledge, not an external system
- Correct approach: Provide a "Coding Standards Skill"
```

**Problems**:

- MCP server responsibilities become bloated
- Increased operational costs
- Difficult to customize on the agent side

### Over-Skillization: Excessive Use of Skills

This anti-pattern occurs when external API integration or real-time data retrieval is described in a Skill instead of being implemented as an MCP. Here is a concrete example:

âŒ **Anti-pattern example**:

```
// âŒ This should be implemented as MCP
- Skill: "This business process uses DeepL translation"
- Reason: This is an external API, not team knowledge
- Correct approach: Use `deepl-mcp`
```

**Problems**:

- Skills become bloated and complex
- Difficult to respond to external system updates
- Confusion in authentication and token management

## Combined Usage Patterns

In actual operations, MCP and Skills are **used complementarily**.

### Pattern 1: Providing Translation Functionality

This pattern shows how a Skill and MCP work together to provide comprehensive translation functionality combining knowledge and execution capability:

```
[Translation Guidelines Skill]
           â†“
[DeepL API] â†â”€â”€â”€ deepl-mcp
           â†“
[Agent]
    â†“
"Translate customer service email" â†’ Learn "tone and style" from Skill
                                   â†’ Execute "accurate translation" via MCP
```

### Pattern 2: Frontend Development

In frontend development, a Skill provides design standards while an MCP offers access to the component library, creating a synergistic workflow:

```
[Design Standards Skill] + [Component Library MCP]
           â†“
[Agent]
    â†“
"Create new UI component"
    â†’ Learn "design principles" from Skill
    â†’ Reference "existing components" via MCP
```

### Pattern 3: Code Quality Check

This pattern demonstrates how a Skill encoding best practices pairs with an MCP that provides the actual analysis and detection tools for comprehensive code quality checking:

```
[SOLID Principles Skill]
    â”œâ”€ Definition and purpose of 5 principles
    â”œâ”€ Identifying violation patterns
    â””â”€ Refactoring guidelines

    â†’ Knowledge of "what to adhere to"
           â†“
[ESLint Official MCP (@eslint/mcp)]
    â”œâ”€ Run lint
    â”œâ”€ Auto-fix
    â””â”€ Detect rule violations

    â†’ Tool that "actually detects" issues
```

**Key Point**: No need to build a custom SOLID principles MCP

- Knowledge and principles â†’ Define in Skill
- Detection and correction â†’ Leverage official MCP

### Usage Summary

The following table summarizes how Skills and MCPs divide responsibilities in three common scenarios:

| Area | Skill (Knowledge) | MCP (Tool) |
| ---- | ----------------- | ---------- |
| **Translation** | Translation guidelines | DeepL official + xCOMET |
| **Code Quality** | SOLID principles | ESLint official |
| **RFC Compliance** | Implementation checklist | rfcxml-mcp |

> **Principle**: Use official MCPs when available. Define knowledge and principles in Skills.

## Operational Considerations

| Operational Activity | MCP | Skills |
| -------------------- | --- | ------ |
| **Deployment** | Server-side (DevOps) | Agent-side (AI team) |
| **Version Control** | Semantic versioning | Task/Feedback driven |
| **Testing** | Integration tests (API compatibility) | Use case tests (execution quality) |
| **Documentation** | API reference | Execution guides and knowledge base |

## Best Practices

### 1. **Clear Separation of Responsibilities**

Establish clear boundaries between what MCPs and Skills handle:

- MCP: Focus on declaring "what can be done"
- Skills: Focus on guidelines for "how to use it"

### 2. **Gradual Adoption**

Introduce MCPs and Skills progressively, building competency at each phase:

- Phase 1: Implement external integrations with MCP
- Phase 2: Systematize internal knowledge with Skills
- Phase 3: Mutual complementation of MCP and Skills

### 3. **Continuous Improvement**

Keep your MCP and Skill implementations aligned with operational needs and team feedback:

- Maintain stable MCP server operations
- Evolve Skills through feedback-driven development

## CLI vs MCP: When CLI is Enough

Before building an MCP, check if a dedicated CLI already exists.

### Why This Matters

| Factor | CLI + Skill | MCP |
|--------|-------------|-----|
| **Token consumption** | Low (command only) | High (loads all tool definitions) |
| **Purpose-built** | âœ… (CLI is specialized) | â–³ (generic interface) |
| **Startup cost** | None (already installed) | Server process required |
| **Auth handling** | Local (already configured) | MCP manages credentials |

### Decision Flow

Before building an MCP, evaluate whether an existing CLI can serve the purpose more efficiently. This flowchart helps determine the best approach:

```mermaid
flowchart TD
    START[Need external service integration] --> CLI{Official CLI exists?}
    CLI -->|Yes| OPEN{API is open?<br/>Auth is simple?}
    OPEN -->|Yes| USE_CLI[Use CLI + Skill<br/>Token efficient âœ…]
    OPEN -->|No| USE_MCP2[Use MCP<br/>Delegate auth handling]
    CLI -->|No| USE_MCP[Use MCP<br/>Required]

    style USE_CLI fill:#90EE90,color:#333
    style USE_MCP fill:#FFB6C1,color:#333
    style USE_MCP2 fill:#FFB6C1,color:#333
```

### Decision Criteria

Use these criteria to determine whether to use a CLI with a Skill or build a full MCP:

| Check | CLI + Skill | MCP |
|-------|-------------|-----|
| Official CLI exists | âœ… | - |
| API is open/documented | âœ… | - |
| Simple auth (local) | âœ… | - |
| Complex auth (OAuth) | - | âœ… |
| No CLI available | - | âœ… |

### Examples

Here are practical examples of services and whether a CLI-based approach or MCP is recommended:

| Service | CLI | Recommendation |
|---------|-----|----------------|
| GitHub | `gh` | CLI + Skill |
| AWS | `aws` | CLI + Skill |
| Google Cloud | `gcloud` | CLI + Skill |
| PostgreSQL | `psql` | CLI + Skill |
| Linear | âŒ | MCP |
| Greptile | âŒ | MCP |
| Slack | Partial | MCP (for full features) |

### Pattern: CLI + Skill

When using a CLI instead of MCP, follow this pattern to maximize clarity and effectiveness:

1. **Skill defines**: How to use the CLI effectively
2. **Tool calls**: Direct CLI commands (e.g., `gh pr list`)
3. **Auth**: Handled locally (already authenticated)

```markdown
<!-- Example: GitHub Skill using gh CLI -->
## Tools Available

The following CLI tools and their most common operations are available for GitHub interactions:

Use `gh` CLI for GitHub operations:
- `gh pr list` - List pull requests
- `gh pr create` - Create PR
- `gh issue list` - List issues

## When to Use

- Checking PR status: `gh pr status`
- Creating issues: `gh issue create --title "..." --body "..."`
```

### Key Insight

> **CLI exists â†’ CLI + Skill (token efficient)**
> **No CLI â†’ MCP (required)**

This pattern emerged from community discussion on r/ClaudeAI and reflects real-world usage patterns where MCPs can be "token hungry" for services that already have well-designed CLIs.

## Related Documentation

- [What is Skills](./what-is-skills) - Skills overview
- [MCP Catalog](../mcp/catalog.md) - Pre-built MCP catalog
- [Architecture](../concepts/03-architecture.md) - MCP/Skills/Agent architecture

---

## MCP/Skills Anti-Pattern Collection

Source: https://shuji-bonji.github.io/ai-agent-architecture/skills/anti-patterns/

# MCP/Skills Anti-Pattern Collection

This document organizes common failure patterns in MCP and Skills design and operation, along with how to avoid them.

## 1. over-MCPization (Excessive Use of MCP)

### Symptoms

Implementing internal team knowledge and guidelines as MCP servers.

### Problematic Approach

This anti-pattern manifests in several common ways:

```
âŒ Building an MCP server to retrieve team coding standards
âŒ Providing design principles as an API
âŒ Converting internal workflows into MCP tools
```

### Why This Is a Problem

Over-MCPization creates several operational and maintenance issues:

- MCP server responsibilities become bloated
- Increased server operation costs
- Difficult to customize on the agent side
- Authentication and deployment become complex

### Correct Approach

The proper solution separates team knowledge from external integration:

```
âœ… Internal team knowledge â†’ Define as a Skill
âœ… Access to external APIs â†’ Implement as MCP
```

**Decision Criteria**: "Is this an external service, or team knowledge?"

## 2. over-Skillization (Excessive Use of Skills)

### Symptoms

Attempting to explain external API calls and real-time data retrieval through Skills.

### Problematic Approach

This anti-pattern appears when external services are documented as Skills:

```
âŒ Skill: "How to translate using DeepL" (detailing API call procedures)
âŒ Skill: "How to search RFCs" (explaining search API usage)
âŒ Skill: "GitHub repository operation procedures"
```

### Why This Is a Problem

Over-Skillization creates several practical challenges:

- Skills become bloated and complex
- Difficult to keep up with external system updates
- Authentication credential management becomes ambiguous
- Agent cannot execute (reference only)

### Correct Approach

Separate external APIs from usage guidelines:

```
âœ… External API integration â†’ Implement as MCP
âœ… MCP usage and guidelines â†’ Supplement with Skills
```

**Decision Criteria**: "Is dynamic execution required, or is this static knowledge?"

## 3. Ambiguous Skill Definitions

### Symptoms

Skill content is too abstract, preventing the agent from taking concrete actions.

### Problematic Approach

Vague Skills lack the specificity needed for reliable execution:

```markdown
âŒ # Code Review Skill

Code review is important.
Write good code.
Check for bugs.
```

### Why This Is a Problem

Ambiguous Skills lead to inconsistent and unreliable execution:

- Agent cannot establish decision criteria
- Execution results vary each time
- Quality cannot be guaranteed

### Correct Approach

Define clear, measurable criteria that guide consistent execution:

```markdown
âœ… # Code Review Skill

## Checklist

1. Zero ESLint errors
2. No violations of SOLID principles
3. Test coverage at 80% or higher

## Decision Criteria

| Condition             | Action                     |
| --------------------- | -------------------------- |
| ESLint errors present | Correction required        |
| Coverage below 80%    | Request additional tests   |
```

**Countermeasure**: Define numerical standards, specific conditions, and clear actions

## 4. Excessive Coupling with MCP Tool Dependencies

### Symptoms

Skills are strongly dependent on specific MCP internal implementations.

### Problematic Approach

Coupling Skills to internal MCP details creates fragility:

```markdown
âŒ # Translation Skill

Use translate-text from deepl MCP version 1.2.3.
Specify "nonewlines" for the split_sentences parameter.
Cache takes effect internally, so the second call is faster.
```

### Why This Is a Problem

Over-specifying MCP details reduces flexibility and portability:

- Breaks when MCP version is upgraded
- Dependency on internal implementation is difficult to maintain
- Cannot be replaced with other MCPs

### Correct Approach

Define Skills at the interface level, abstracting away implementation details:

```markdown
âœ… # Translation Skill

## MCP Usage

| MCP                                   | Purpose          |
| ------------------------------------- | ---------------- |
| deepl (or equivalent translation MCP) | Text translation |

## Workflow

1. Execute translation (formality: formal)
2. Check quality score
3. Re-translate if below threshold
```

**Countermeasure**: Describe at the MCP interface level, do not depend on implementation details

## 5. Violation of Single Responsibility Principle

### Symptoms

Packing multiple different responsibilities into a single Skill.

### Problematic Approach

Monolithic Skills combine unrelated tasks:

```markdown
âŒ # Development Skill

## Code Review

...

## Deployment Procedures

...

## Incident Response

...

## New Employee Onboarding

...
```

### Why This Is a Problem

Monolithic Skills create multiple maintenance and usage challenges:

- Large impact scope when updating
- Cannot reference only the needed parts
- Wasteful context consumption increases

### Correct Approach

Organize Skills by responsibility, keeping each one focused:

```
âœ… skills/
    â”œâ”€â”€ code-review/SKILL.md
    â”œâ”€â”€ deployment/SKILL.md
    â”œâ”€â”€ incident-response/SKILL.md
    â””â”€â”€ onboarding/SKILL.md
```

**Countermeasure**: 1 Skill = 1 Responsibility

## 6. Unmaintained Skills

### Symptoms

Skills that are left unchanged after creation, diverging from actual operations.

### Problematic Approach

Neglected Skills drift away from operational reality:

```
âŒ Using a Skill created six months ago without changes
âŒ Team standards have changed but Skill hasn't been updated
âŒ Unknown who the owner is
```

### Why This Is a Problem

Unmaintained Skills undermine agent reliability and decision quality:

- Agent operates with outdated information
- Leads to incorrect decisions
- Decreased reliability

### Correct Approach

Establish clear ownership and regular review cycles:

```markdown
âœ… ---
name: code-review
description: Code review guidelines
owner: @frontend-team
last_reviewed: 2025-01-15
```

**Countermeasures**:

Implement these practices to keep Skills current and reliable:

- Specify an owner
- Set up a regular review cycle
- Record the last review date

## Anti-Pattern Quick Reference

The following table provides a quick lookup for identifying and addressing each anti-pattern:

| Pattern                | Symptom                         | Countermeasure                        |
| ---------------------- | ------------------------------- | ------------------------------------- |
| over-MCPization        | Converting internal knowledge to MCP | Migrate to Skills              |
| over-Skillization      | Explaining external APIs in Skills | Migrate to MCP                   |
| Ambiguous Skills       | Too abstract                    | Clarify with numbers and conditions   |
| Excessive Coupling     | Dependency on MCP internals     | Describe at interface level           |
| Single Responsibility Violation | Multiple responsibilities in 1 Skill | Split Skills          |
| Unmaintained           | Divergence from operations      | Set owner and review cycle            |

## Related Documentation

- [MCP vs Skills](./vs-mcp.md) - Essential differences and selection criteria
- [What is Skills](./what-is-skills) - Skills overview
- [Architecture](../concepts/03-architecture.md) - MCP/Skills/Agent architecture theory

---

## Skills Overview

Source: https://shuji-bonji.github.io/ai-agent-architecture/skills/overview/

> âš ï¸ **This document has been merged into [what-is-skills.md](./what-is-skills.md).**
> Please refer to that document instead.

# Skills Overview

## What are Vercel Skills?

Vercel Skills is a standardized domain knowledge representation framework for AI agents. Unlike MCP, it enables agents to acquire and utilize **executable know-how for specific domains and tasks**.

### Features

- **Systematized Domain Knowledge**: Structures expertise and best practices for specific fields
- **Interactive Discovery**: Agents can interactively explore available Skills
- **Standards Compliance**: Interoperability based on the Agent Skills Specification
- **Open Source**: [Vercel Skills v1.1.1](https://vercel.com/changelog/skills-v1-1-1-interactive-discovery-open-source-release-and-agent-support) has been released

## Agent Skills Specification

A specification standardized at [https://agentskills.io](https://agentskills.io).

## Supported Agents (27 types)

Vercel Skills CLI supports the following agents:

| Agent | CLI Argument | Project Path |
|-------|--------------|--------------|
| Claude Code | `claude-code` | `.claude/skills/` |
| Cursor | `cursor` | `.cursor/skills/` |
| Codex | `codex` | `.codex/skills/` |
| OpenCode | `opencode` | `.opencode/skills/` |
| GitHub Copilot | `github-copilot` | `.github/skills/` |
| Windsurf | `windsurf` | `.windsurf/skills/` |
| Cline | `cline` | `.cline/skills/` |
| Roo Code | `roo` | `.roo/skills/` |
| Gemini CLI | `gemini-cli` | `.gemini/skills/` |
| Others | ... | ... |

> For the complete list, see [Vercel Skills README](https://github.com/vercel-labs/skills#supported-agents)

## Skill Components

### 1. Metadata

```json
{
	"name": "frontend-design",
	"version": "1.0.0",
	"description": "Best practices for React/Next.js frontend design",
	"author": "example-org",
	"tags": ["frontend", "react", "design"]
}
```

### 2. Executable Guidelines

- Recommended directory structure patterns
- Component design principles
- Test coverage requirements
- Performance optimization guidelines

### 3. Real-time Learning

- Agents acquire Skills through dialogue
- Implementation within context during task execution

## Choosing Between MCP and Skills

| Aspect | MCP | Skills |
|--------|-----|--------|
| **Purpose** | External tool/API integration | Domain knowledge/executable know-how |
| **Target** | External systems | Implementation patterns/best practices |
| **Use Cases** | rfcxml-mcp, deepl-mcp | frontend-design, doc-coauthoring |
| **Operation Mode** | Server process | In-memory (Skill model) |

> For details, see [vs-mcp.md](./vs-mcp.md).

## Skills Creation and Utilization Patterns

1. **Documentation Phase**
   - Convert team best practices into Skills
   - Example: Figma design guide â†’ `design-system-skill`

2. **Agent Acquisition Phase**
   - Agents acquire domain knowledge through Skills
   - Deepen understanding through interactive queries

3. **Operation and Improvement Phase**
   - Feedback from agent execution results
   - Continuously optimize Skill content

## Integration with Vercel Skills CLI

### Skills Discovery Flow with find-skills

```mermaid
sequenceDiagram
    participant U as User/Agent
    participant CLI as npx skills
    participant Registry as Skills Registry
    participant Local as Local Skills

    U->>CLI: npx skills find "translation"
    CLI->>Registry: Search skills.sh
    Registry-->>CLI: [translation-workflow, deepl-guidelines, ...]
    CLI->>U: Interactive selection
    U->>CLI: Select & Install
    CLI->>Local: Install to .claude/skills/
    Local-->>U: Ready to use
```

### Dynamic Skills Extension Pattern

```mermaid
flowchart LR
    subgraph Discovery["Skills Discovery"]
        FIND[npx skills find]
        REGISTRY[(skills.sh)]
    end

    subgraph Installation["Installation"]
        PROJECT[Project Skills<br/>.claude/skills/]
        GLOBAL[Global Skills<br/>~/.claude/skills/]
    end

    subgraph Usage["Runtime"]
        AGENT[Agent]
        MCP[MCP Servers]
    end

    FIND --> REGISTRY
    REGISTRY --> PROJECT
    REGISTRY --> GLOBAL
    PROJECT --> AGENT
    GLOBAL --> AGENT
    AGENT --> MCP
```

### Installation Command Examples

```bash
# Search for Skills
npx skills find "code review"

# Install a specific Skill
npx skills add vercel-labs/agent-skills --skill frontend-design

# Support multiple agents
npx skills add vercel-labs/agent-skills -a claude-code -a cursor

# Install at project scope (default)
npx skills add ./my-skills

# Install at global scope
npx skills add ./my-skills -g
```

## Reference Links

- [Agent Skills Specification](https://agentskills.io)
- [Vercel Skills Official Documentation](https://vercel.com/changelog/skills-v1-1-1-interactive-discovery-open-source-release-and-agent-support)

---

## A2A (Agent-to-Agent Protocol): What is it?

Source: https://shuji-bonji.github.io/ai-agent-architecture/agents/what-is-a2a/

# A2A (Agent-to-Agent Protocol): What is it?

> An open standard protocol enabling agents to collaborate and delegate tasks over networks

## About This Document

This document explains A2A's core concepts, key differences from MCP, benefits and challenges, and future outlook. For detailed comparison with sub-agents, also refer to [what-is-subagent.md](./what-is-subagent.md).

## What is A2A?

**A2A (Agent-to-Agent Protocol)** is an open standard protocol that enables different AI agents to communicate and collaborate in peer-to-peer relationships over networks.

### Background and Leadership

Here is a brief history of A2A's origins and standardization.

- **Google led** the effort, announcing A2A in April 2025
- Subsequently, **Linux Foundation** will take over stewardship for open standardization
- Like MCP, it is positioned as foundational infrastructure for the agent economy

### The Essence of A2A

A2A's defining characteristic is enabling **agent â†” agent** peer communication:

- **MCP**: AI agent â†” **tools/APIs** (master-slave relationship)
- **A2A**: AI agent â†” **AI agent** (peer relationship)

### In One Sentence

"A protocol allowing different AI agents to request work from each other"

### Architectural Model

Three-layer structure for agent development:

- **Build with ADK**: Construct the agent itself
- **Equip with MCP**: Connect tools and APIs
- **Communicate with A2A**: Communicate with other agents

## Why A2A?

### Current Challenges

As AI agent technology evolves rapidly, companies and organizations develop and operate their own agents. However, there is no standard communication mechanism between these agents.

**The Silo Problem**:

- Internal Sales Analysis Agent â†’ wants to query Salesforce AI Agent
- But there's no standard communication protocol
- MCP enables "agent â†” tools" but not "agent â†” agent"
- Result: **agents operate in isolation**, making cross-organization collaboration difficult

### Before and After A2A

**Before A2A**:

- Agent-to-agent communication handled by custom implementations (API integration, etc.)
- Without standards, each integration requires custom specification negotiation
- Not scalable

**After A2A**:

- Standardized protocol enables agent-to-agent communication
- Authentication, authorization, and trust models are unified
- Agents from different organizations can collaborate seamlessly

### Communication Flow

The diagram below illustrates the basic flow of agents from different organizations communicating via the A2A protocol.

```mermaid
flowchart LR
    AGENT_A["Internal Agent<br/>Sales Analysis"]
    PROTOCOL["A2A Protocol<br/>Standardized Communication"]
    AGENT_B["External Agent<br/>Salesforce AI"]

    AGENT_A --"Task Request"--> PROTOCOL
    PROTOCOL --"Return Result"--> AGENT_A
    PROTOCOL --"Accept Task"--> AGENT_B

    style AGENT_A fill:#FFB6C1,color:#333,stroke:#333
    style PROTOCOL fill:#666,color:#000,stroke:#333
    style AGENT_B fill:#90EE90,color:#333,stroke:#333
```

## Fundamental Differences from MCP

While both A2A and MCP enable "connections," their **connection targets are fundamentally different**. The comparison table below clarifies the distinctions.

### Feature Comparison

The following table contrasts MCP and A2A.

| Aspect                  | MCP                          | A2A                                           |
| ----------------------- | ---------------------------- | --------------------------------------------- |
| **Led by**              | Anthropic                    | Google â†’ Linux Foundation                     |
| **Purpose**             | Agent â†” **Tools**            | Agent â†” **Agent**                             |
| **Connection Target**   | MCP servers (you manage)     | Other agents (**including external parties**) |
| **Communication Model** | Master-Slave (agent directs) | **Peer-to-peer** (both can request)           |
| **Context Sharing**     | Shareable with parent agent  | **Fully isolated** (expects opaque parties)   |
| **Owner**               | Self                         | Self or **others**                            |
| **Trust Model**         | Implicit trust               | **Authentication/authorization required**     |

### Decision Flowchart: Which Should You Choose?

Use the following flowchart to determine the right choice among MCP, A2A, and custom sub-agents.

```mermaid
flowchart TD
    Q1{What's the target?}
    Q1 -->|Tools/APIs| MCP["ðŸ”§ MCP"]
    Q1 -->|Other AI Agents| Q2{Who owns it?}
    Q2 -->|Self| Q3{Same process?}
    Q2 -->|Others| A2A["ðŸ¤ A2A"]
    Q3 -->|Yes| SUB["ðŸ‘¥ Custom Sub-agent"]
    Q3 -->|No| A2A

    style MCP fill:#FFB6C1,color:#333,stroke:#333
    style A2A fill:#87CEEB,color:#333,stroke:#333
    style SUB fill:#90EE90,color:#333,stroke:#333
```

## Core Concepts of A2A

Three key concepts are essential in A2A.

### 1. Agent Card

An agent's "self-introduction card" that provides information helping other agents and discovery systems understand what capabilities an agent offers.

**Format**: JSON

**Included Information**:

- Agent name and description
- Supported Capabilities
- Authentication method
- Supported A2A versions
- Endpoint information

**Location**: Discoverable via `/.well-known/agent.json`

### 2. Task

A "unit of work" agents request from each other. Handles both brief interactions and extended processes.

**Lifecycle**:

- `submitted`: Immediately after task receipt
- `working`: Processing
- `input-required`: Additional information needed
- `completed`: Success
- `failed`: Failure

**Characteristics**:

- Asynchronous execution
- Long-running task support
- Polling or callback mechanisms

### 3. Artifact

Data generated as a task execution result. Not limited to textâ€”includes files and structured data.

**Supported Formats**:

- Text (plain text, markdown, etc.)
- Files (PDF, images, etc.)
- Structured data (JSON, XML, etc.)
- Multimodal (images, audio anticipated)

## Benefits of A2A

Adopting A2A provides the following advantages.

### âœ… Standardized Cross-Organization Collaboration

Agents from different organizations can communicate via a standard protocol. This marks a shift from "custom per-company integration" to "standards-based collaboration."

### âœ… Agent Specialization and Cooperation

Each agent can specialize in its domain, while complex tasks benefit from multi-agent collaboration. For example:

- Sales Agent â† retrieves forecast data from Market Analysis Agent
- Sales Agent â† retrieves customer info from CRM Agent

### âœ… Multimodal Support

Information exchange isn't limited to textâ€”images, audio, and files enable richer communication.

### âœ… Asynchronous Task Support

Long-running operations like report generation can execute in the background, with results retrieved later.

### âœ… Vendor Independence

As an open standard under Linux Foundation stewardship, there's no vendor lock-in.

## Drawbacks and Challenges

A2A also comes with challenges that remain to be addressed.

### âŒ Implementation Complexity

Authentication, authorization, and encryption are mandatoryâ€”requirements stricter than MCP.

### âŒ Network Dependency

Requires handling network latency, connection dropouts, and other failures. Timeout configuration and retry logic are essential.

### âŒ Debugging Difficulty

Tracing inter-agent communication is complex, making troubleshooting challenging. Logging strategy is critical.

### âŒ Maturity is Still Low

Compared to MCP (released November 2024), A2A is even newer. Implementation patterns and operational best practices remain limited.

### âŒ Nascent Ecosystem

Only a limited number of agents and tools support A2A yet. Broader adoption will take time.

### âŒ Trust Challenges

You cannot fully guarantee the quality or security of agents owned by others. Risks of misuse by malicious agents must be considered.

## Choosing Between Sub-agents and A2A

For collaboration between agents you manage, use "custom sub-agents." For external agent collaboration including other organizations, use "A2A."

### Comparison

The following table contrasts custom sub-agents with A2A agents.

| Dimension              | Custom Sub-agent             | A2A Agent                             |
| ---------------------- | ---------------------------- | ------------------------------------- |
| **Location**           | Within same process          | Over the network                      |
| **Owner**              | Self                         | Self or others                        |
| **Trust Relationship** | Full trust                   | Authentication/authorization required |
| **Context**            | Partially shared with parent | Fully isolated                        |
| **Lifecycle**          | Session-scoped               | Persistent service                    |

### Understanding via Metaphor

- **Sub-agents** = "In-house specialist department"
  - Located in the same building (process)
  - Under supervisor (parent agent) oversight
  - Fully trustworthy

- **A2A agents** = "Outsourced partner / vendor"
  - Located at separate facilities (separate processes)
  - Communicate over networks
  - Relationship based on contracts (authentication/authorization)

### Complementary, Not Competing

Sub-agents and A2A agents don't competeâ€”they complement each other. Most systems use both:

- Internal task decomposition â†’ **Custom sub-agents**
- External resource utilization â†’ **A2A agents**

## Current Maturity and Future Outlook

### Timeline

Key milestones from the emergence of MCP and A2A to the present.

- **November 2024**: Anthropic releases MCP
- **April 2025**: Google announces A2A
- **2025**: Migration to Linux Foundation planned
- **2025â€“2026**: Ecosystem development phase

### Current Status

The [03-architecture.md](../concepts/03-architecture.md) document in this repository describes A2A's architectural positioning.

### Future Projections

While A2A implementations remain limited, these scenarios are anticipated:

1. **Early Stage (2025)**: Major players begin A2A support
2. **Growth Stage (2025â€“2026)**: Mid-market companies start adopting
3. **Maturity Stage (2026+)**: MCP + A2A combined use becomes standard

### Recommended Architecture

**Build with ADK, equip with MCP, communicate with A2A**

This model is expected to become the standard for future agent development.

## What to Read Next

Explore these documents to deepen your A2A understanding:

| Purpose              | Document                                             |
| -------------------- | ---------------------------------------------------- |
| Sub-agent details    | [what-is-subagent.md](./what-is-subagent.md)         |
| MCP details          | [what-is-mcp.md](../mcp/what-is-mcp.md)              |
| Overall architecture | [03-architecture.md](../concepts/03-architecture.md) |
| About Skills         | [what-is-skills.md](../skills/what-is-skills.md)     |

**Last Updated**: April 2025
**Status**: Initial Release (Post A2A Announcement)

---

## What are Custom Sub-agents?

Source: https://shuji-bonji.github.io/ai-agent-architecture/agents/what-is-subagent/

# What are Custom Sub-agents?

> Specialized AI assistants defined within Claude Code for specific tasks

## About This Document

This document explains the fundamental concepts, definition methods, use patterns, benefits, and limitations of custom sub-agents. For differences with A2A agents, see [what-is-a2a.md](./what-is-a2a.md).

## What are Sub-agents?

**Custom sub-agents** are specialized AI assistants defined within Claude Code that focus on specific tasks.

### Key Characteristics

Custom sub-agents have the following characteristics.

- **Markdown file format**: Defined as `.claude/agents/xxx.md`
- **Task-specialized**: Specialize in specific work like translation, RFC verification, code review, etc.
- **Delegation pattern**: Receive specific tasks "delegated" from the main Claude (Orchestrator)
- **Lightweight implementation**: No deployment neededâ€”just file editing

### Think of it as

**"A team of expert specialists within AI"** â€” translators, reviewers, RFC experts, testers, and more. Each specialist has their domain expertise, and the main Claude delegates work to the appropriate specialist as needed.

If MCP is the tools (hands), then sub-agents are the specialists (brains). They are entities equipped with judgment and specialized knowledge to use tools effectively.

## Why Sub-agents?

### Problem: Main Claude's Limitations

While the main Claude is versatile and handles many tasks, specific expert tasks require repetitive, verbose instructions every time.

**Example: Every time RFC specifications are needed**

```
"Use the rfcxml tool to check Section 5.1 of RFC 6455,
explain in Japanese, output in table format..."
```

Such instructions become repetitive.

### Solution: Specialization Through Sub-agents

By pre-defining specialization in sub-agents, instructions from the main Claude become simpler.

**Improved example:**

```
"Check the WebSocket protocol in RFC 6455"
â†’ RFC expert sub-agent automatically handles with proper procedures
```

### Benefits Gained

- **Context savings**: No repetitive verbose instructions needed
- **Consistent quality**: Always processed by the same rules and procedures (no prompt drift)
- **Reusability**: Once defined, sub-agents can be used across the entire project and team
- **Maintainability**: When processing rules change, update just one sub-agent definition file

## Positioning of Sub-agents

To understand the structure within Claude Code, let's examine the relationship between MCP Client, MCP Servers, and main Claude.

```mermaid
block-beta
    columns 2

    block:CLAUDE_CODE:2
        columns 2
        USER["User"]:2
        MAIN["Main Claude\n(Orchestrator)"]:1 SUBAGENT["Custom Sub-agents\n(.claude/agents/)"]:1
        MCP_CLIENT["MCP Client\n(Built into Claude Code)"]:2
    end

    MCP_SERVERS["MCP Servers\n(rfcxml, deepl, etc.)"]:2

    USER --> MAIN
    MAIN --"Delegate"--> SUBAGENT
    SUBAGENT --"Use"--> MCP_CLIENT
    MAIN --"Direct use"--> MCP_CLIENT
    MCP_CLIENT --"JSON-RPC"--> MCP_SERVERS

    style MCP_CLIENT fill:#FFB6C1,color:#333,stroke:#333
    style SUBAGENT fill:#90EE90,color:#333,stroke:#333
    style MCP_SERVERS fill:#E8E8E8,color:#333,stroke:#333
```

### Key Relationships

The relationships between components shown in the diagram above can be summarized as follows.

- **Sub-agent = Definition of "what to do"**: Role, procedures, constraints, output format
- **MCP Client = Implementation of "how to connect"**: JSON-RPC protocol handling, authentication, communication management
- **Sub-agents are not a "replacement" for MCP Client but a "higher layer"**: Sub-agents access tools through the MCP Client

## Definition Format

### Basic Structure

Sub-agents are defined in Markdown files. Place metadata at the top of the file, followed by the system prompt (defining specialization).

```markdown
<!-- .claude/agents/rfc-specialist.md -->

name: rfc-specialist
description: RFC specification verification and validation expert
tools: rfcxml:get_rfc_structure, rfcxml:get_requirements
model: sonnet

You are an RFC specification expert.
Follow these rules:

- Use only rfcxml tools
- Answer in English
- Clearly indicate section numbers
```

### Metadata Fields

The fields available in the metadata section are as follows.

| Field       | Required | Description                                                    |
| ----------- | -------- | -------------------------------------------------------------- |
| name        | âœ…       | Unique identifier (alphanumeric and hyphens only)              |
| description | âœ…       | Role description (in a format AI can understand)               |
| tools       | -        | Restrict available MCP tools (comma-separated)                 |
| model       | -        | Model to use (sonnet, haiku, etc.; defaults if omitted)        |
| (body)      | âœ…       | System prompt (defining specialization, role, and constraints) |

### Placement and Priority

Sub-agent definition files can be placed in two scopes.

| Scope   | Path                      | Priority | Description                      |
| ------- | ------------------------- | -------- | -------------------------------- |
| Project | `.claude/agents/xxx.md`   | High     | Under git, shared by entire team |
| User    | `~/.claude/agents/xxx.md` | Low      | User-local, personal use         |

When the same sub-agent is defined at both project and user levels, the project-level definition takes priority.

## Types and Patterns

Custom sub-agents can be classified into three main types based on their roles.

### 1. Specialist

Sub-agents specialized in knowledge of a specific domain.

**Examples:**

- RFC expert: Verify and validate RFC specifications
- Translator: Translate into multiple languages and verify quality
- Security auditor: Inspect code for security issues

**Use cases:** Situations requiring specialized analysis and judgment. Tasks needing deep knowledge within a single tool set.

### 2. Workflow Runner

Sub-agents that faithfully execute pre-defined procedures. Execute multi-step processing in order.

**Examples:**

- Translation workflow: Translate â†’ Evaluate quality â†’ Suggest fixes â†’ Re-evaluate
- Deployment check: Build verification â†’ Security check â†’ Pre-deployment testing
- Document generation: Requirement extraction â†’ Structure planning â†’ Content writing â†’ Review â†’ Finalization

**Use cases:** Multi-step standardized processing. Cases where each step depends on the order.

### 3. Validator

Sub-agents specialized in quality validation of deliverables. Validate deliverables against defined standards.

**Examples:**

- Code reviewer: Verify code quality, security, and best practices
- Document validator: Verify technical accuracy, writing consistency, and format
- Test executor: Execute unit tests, integration tests, and acceptance tests

**Use cases:** Automated quality gates. Integration into CI/CD pipelines.

## Benefits

Benefits gained from implementing custom sub-agents:

- âœ… **Low cost**: Define with a single Markdown file. No complex infrastructure needed
- âœ… **Immediate changes**: File edit â†’ instant effect. No deployment or server restart needed
- âœ… **Context efficiency**: Limit tool definition loading (exclude unnecessary tools via tools specification)
- âœ… **Quality consistency**: Always processed by the same rules. No prompt drift
- âœ… **Team sharing**: Place `.claude/agents/` under git â†’ entire team uses the same specialists

## Drawbacks and Limitations

Custom sub-agents have some limitations:

- âŒ **Session-limited**: Cannot maintain state between sessions. Persistent memory and caching unavailable
- âŒ **Host-dependent**: Claude Code only. Limited compatibility with Cursor and others
- âŒ **Context sharing limitations**: Limited sharing with parent agent. Cannot share large context in some cases
- âŒ **Parallel execution constraints**: Limited control for simultaneous multi-sub-agent execution
- âŒ **Testing difficulty**: No framework for unit testing sub-agent behavior. Manual verification required after implementation

## Combining Skills + Sub-agents + MCP

The most powerful approach combines these three elements.

```mermaid
flowchart LR
    SKILL["Skill<bn>Workflow Definition"] -->|"Reference"| AGENT["Sub-agent<bn>Translation Expert"]
    AGENT -->|"Execute"| MCP["MCP<bn>deepL, xcomet"]

    style SKILL fill:#90EE90,color:#333,stroke:#333
    style MCP fill:#FFB6C1,color:#333,stroke:#333
    style AGENT fill:#87CEEB,color:#333,stroke:#333
```

### Three-Layer Role Separation

Each of these three elements has a clearly distinct responsibility.

- **Skill**: Defines "what should be done". Workflows, decision criteria, decision logic
- **Sub-agent**: Separates "who does it". Role as specialist, constraints, output format
- **MCP**: Provides "how to execute". Tools, APIs, external resource connections

### Real-world Example: Translation Workflow

1. **Skill `translation-workflow`** defines the entire workflow
   - Input check â†’ Translate â†’ Quality evaluation â†’ Correct â†’ Re-evaluate â†’ Finalize
   - Decision criteria for each step (quality score of 80 points or higher, etc.)

2. **Sub-agent `translator`** executes while referencing the Skill
   - Define role as translation expert
   - Specify how to use tools like deepL and xcomet

3. **MCP `deepl-mcp` / `xcomet-mcp`** provides tools and APIs
   - Concrete implementation of translation execution and quality evaluation

This three-layer separation minimizes the impact of changes in one layer on others, improving maintainability and extensibility.

## What to Read Next

To learn more about sub-agents and related concepts, explore the following documents.

| Purpose                          | Document                                             |
| -------------------------------- | ---------------------------------------------------- |
| Understand differences from A2A  | [what-is-a2a.md](./what-is-a2a.md)                   |
| Learn more about MCP             | [what-is-mcp.md](../mcp/what-is-mcp.md)              |
| Learn more about Skills          | [what-is-skills.md](../skills/what-is-skills.md)     |
| Claude Code overall architecture | [03-architecture.md](../concepts/03-architecture.md) |
| Implementation patterns          | [patterns.md](../workflows/patterns.md)              |

---

## Composition Patterns

Source: https://shuji-bonji.github.io/ai-agent-architecture/strategy/composition-patterns/

# Composition Patterns

> Organize combination patterns and design guidelines for MCP Ã— Skill Ã— Agent.

[æ—¥æœ¬èªž](/ja/strategy/composition-patterns)

## About This Document

While MCPs and Skills have value individually, there is **value that emerges only through combination**. This document defines 4 composition patterns and organizes the design guidelines, trigger contexts, and use cases for each.

For the MCP construction strategy, see [mcp-roadmap.md](./mcp-roadmap.md). For the Skill construction strategy, see [skill-roadmap.md](./skill-roadmap.md).

## 4 Composition Patterns

```mermaid
flowchart TB
    subgraph PATTERNS["4 Composition Patterns"]
        direction TB
        subgraph P1["Pattern 1: MCP + Skill"]
            P1_D["Evaluate data retrieved by MCP<br>using Skill judgment criteria"]
        end
        subgraph P2["Pattern 2: MCPs (Multi-MCP Coordination)"]
            P2_D["Integrate, compare, and verify<br>outputs from multiple MCPs"]
        end
        subgraph P3["Pattern 3: Skills (Multi-Skill Combination)"]
            P3_D["Simultaneously trigger<br>multiple Skills by context"]
        end
        subgraph P4["Pattern 4: MCPs + Skills (Full Integration)"]
            P4_D["Workflow where multiple MCPs<br>and Skills cooperate"]
        end
    end

    style P1 fill:#FFD700,stroke:#F9A825,color:#333
    style P2 fill:#FFB6C1,stroke:#C62828,color:#333
    style P3 fill:#90EE90,stroke:#2E7D32,color:#333
    style P4 fill:#E3F2FD,stroke:#1565C0,color:#333
```

| Pattern           | Composition                     | Core Concept                       | Difficulty |
| ----------------- | ------------------------------- | ---------------------------------- | ---------- |
| **MCP + Skill**   | 1 MCP + 1 Skill                 | Data retrieval + Judgment criteria | â˜…â˜…â˜†        |
| **MCPs**          | Multiple MCPs                   | Data integration & comparison      | â˜…â˜…â˜†        |
| **Skills**        | Multiple Skills                 | Knowledge layering                 | â˜…â˜†â˜†        |
| **MCPs + Skills** | Multiple MCPs + Multiple Skills | Complete workflow                  | â˜…â˜…â˜…        |

## Pattern 1: MCP + Skill

A composition where "raw data" retrieved by MCP from external sources is evaluated using "judgment criteria" held by Skills. The basic form of **hybrid composition**.

### Design Principle

```mermaid
flowchart LR
    MCP["MCP<br>(Data Retrieval)"]
    SKILL["Skill<br>(Judgment Criteria)"]
    RESULT["Evaluation Result"]

    MCP -->|"Structured data"| SKILL
    SKILL -->|"Apply criteria"| RESULT

    style MCP fill:#FFB6C1,color:#333
    style SKILL fill:#90EE90,color:#333
```

MCP returns "what is written," and Skill determines "whether it is good or bad." This separation is important.

### Concrete Examples

#### Electronic Signature Act Compliance Check

```mermaid
sequenceDiagram
    actor U as User
    participant A as Agent
    participant H as hourei-mcp
    participant R as rfcxml-mcp
    participant S as E-Signature Act Skill

    U->>A: Is the timestamp implementation compliant?
    A->>H: find_law_article(Electronic Signature Act, 2)
    H-->>A: Article 2 text
    A->>R: get_requirements(3161)
    R-->>A: RFC 3161 technical requirements
    A->>S: Reference legal + technical requirements
    S-->>A: Mapping criteria & judgment guidelines
    A-->>U: Compliance report
```

| Element               | Role                                                              |
| --------------------- | ----------------------------------------------------------------- |
| `hourei-mcp`          | Retrieve Electronic Signature Act article text (MCP)              |
| `rfcxml-mcp`          | Retrieve RFC 3161 technical requirements (MCP)                    |
| E-Signature Act Skill | Mapping criteria between legal and technical requirements (Skill) |

#### OAuth/JWT Implementation Review

| Element         | Role                                                          |
| --------------- | ------------------------------------------------------------- |
| `rfcxml-mcp`    | Retrieve RFC 6749 (OAuth 2.0) / RFC 7519 (JWT) specifications |
| OAuth/JWT Skill | Token management best practices, implementation patterns      |

### Design Guidelines

- **Write Skills independent of MCP output**: Avoid implementation-dependent descriptions like "look at the `article_text` field in hourei-mcp's JSON response." Instead, use abstract descriptions like "verify whether the legal text contains the following requirements"
- **Make Skill judgment criteria verifiable**: Clearly define the 3 states: "compliant," "non-compliant," and "cannot determine (additional information needed)"

### Candidate List

| Theme                               | MCP                            | Skill                      | Status                        |
| ----------------------------------- | ------------------------------ | -------------------------- | ----------------------------- |
| Electronic Signature Act            | hourei-mcp + rfcxml-mcp        | Implementation guidelines  | âš¡ MCP side already available |
| Personal Information Protection Act | hourei-mcp                     | Compliance checklist       | âš¡ MCP side already available |
| Electronic Books Preservation Act   | hourei-mcp                     | Storage requirements check | âš¡ MCP side already available |
| GDPR                                | Regulatory text MCP (planned)  | DPIA checklist             | ðŸ”² Not started                |
| OWASP                               | Vulnerability DB MCP (planned) | Security review criteria   | ðŸ”² Not started                |
| OAuth/JWT                           | rfcxml-mcp                     | Implementation patterns    | âš¡ MCP side already available |

## Pattern 2: MCPs (Multi-MCP Coordination)

A composition that integrates, compares, and verifies data retrieved from multiple MCPs. There are already proven examples in [workflows/patterns.md](../workflows/patterns.md).

### Design Principle

```mermaid
flowchart LR
    MCP_A["MCP-A<br>(Data Source A)"]
    MCP_B["MCP-B<br>(Data Source B)"]
    AGENT["Agent<br>(Integration & Judgment)"]
    RESULT["Integrated Result"]

    MCP_A -->|"Data A"| AGENT
    MCP_B -->|"Data B"| AGENT
    AGENT --> RESULT

    style MCP_A fill:#FFB6C1,color:#333
    style MCP_B fill:#FFB6C1,color:#333
```

### Proven Combinations

| Combination                       | Use Case                                                | Track Record                                             |
| --------------------------------- | ------------------------------------------------------- | -------------------------------------------------------- |
| **deepl-mcp + xcomet-mcp**        | Translation â†’ Quality evaluation â†’ Re-translation       | 180-page technical document translated in 1 day / $12    |
| **rfcxml-mcp + w3c-mcp**          | Integrated reference of RFC specs + Web API definitions | WebSocket specification verification workflow            |
| **rfcxml-mcp + hourei-mcp**       | Technical specification Ã— Legal text mapping            | Electronic Signature Act Ã— RFC 3161 correspondence table |
| **pdf-spec-mcp + pdf-reader-mcp** | PDF specification reference + Actual file verification  | PDF/UA conformance verification                          |

### Design Guidelines

- **Clarify whether order-dependent or parallelizable**: deepl â†’ xcomet is order-dependent; rfcxml + w3c is parallelizable
- **The Agent layer handles data integration logic**: MCPs only return raw data. Integration and judgment are the Agent's role

## Pattern 3: Skills (Multi-Skill Combination)

A composition that simultaneously triggers multiple Skills according to the context (development phase).

### Design Principle

```mermaid
flowchart TB
    CONTEXT["Development Context"]
    SKILL_A["Skill-A"]
    SKILL_B["Skill-B"]
    SKILL_C["Skill-C"]
    OUTPUT["Integrated Judgment"]

    CONTEXT --> SKILL_A
    CONTEXT --> SKILL_B
    CONTEXT --> SKILL_C
    SKILL_A --> OUTPUT
    SKILL_B --> OUTPUT
    SKILL_C --> OUTPUT

    style SKILL_A fill:#90EE90,color:#333
    style SKILL_B fill:#90EE90,color:#333
    style SKILL_C fill:#90EE90,color:#333
```

### Context-Based Skill Sets

```mermaid
flowchart TB
    subgraph CODE_REVIEW["Code Review Set"]
        direction TB
        CR1["ðŸ”µ SOLID<br>Detect principle violations"]
        CR2["ðŸ”´ Clean Code<br>Style & readability"]
        CR3["ðŸŸ¢ Refactoring<br>Improvement suggestions"]
        CR1 --> CR3
        CR2 --> CR3
    end

    subgraph ARCH_DESIGN["Architecture Design Set"]
        direction TB
        AD1["ðŸŸ¡ DDD<br>Domain modeling"]
        AD2["ðŸ”µ Clean Architecture<br>Layer design"]
        AD3["ðŸ”µ 12 Factor App<br>Cloud readiness"]
        AD1 --> AD2
        AD2 --> AD3
    end

    subgraph TEST_DESIGN["Test Design Set"]
        direction TB
        TD1["ðŸŸ¡ TDD<br>Process"]
        TD2["ðŸŸ¡ BDD<br>Scenario definition"]
        TD3["ðŸŸ¢ Test Patterns<br>Pattern application"]
        TD4["ðŸŸ  Coverage<br>Coverage assessment"]
        TD1 --> TD3
        TD2 --> TD3
        TD3 --> TD4
    end

    style CODE_REVIEW fill:#FFEBEE,stroke:#C62828,color:#333
    style ARCH_DESIGN fill:#E3F2FD,stroke:#1565C0,color:#333
    style TEST_DESIGN fill:#FFFDE7,stroke:#F9A825,color:#333
```

### Design Guidelines

- **Define priority order among Skills**: In the Code Review set, evaluate in order: SOLID (principles) â†’ Clean Code (style) â†’ Refactoring (improvements)
- **"Primary source of definition" rule**: For concepts with overlapping scope (e.g., SRP), designate one Skill as the primary source and the other as reference
- **Entire sets can be meta-Skill-ized**: It is possible to define "Code Review Set" itself as a single Skill that internally references the three Skills

## Pattern 4: MCPs + Skills (Full Integration)

The most complex but most powerful composition where multiple MCPs and multiple Skills cooperate.

### Design Principle

```mermaid
flowchart TB
    subgraph DATA["Data Retrieval Layer (MCPs)"]
        MCP_A["MCP-A"]
        MCP_B["MCP-B"]
    end

    subgraph KNOWLEDGE["Knowledge Layer (Skills)"]
        SKILL_A["Skill-A"]
        SKILL_B["Skill-B"]
    end

    AGENT["Agent<br>(Orchestration)"]
    RESULT["Final Output"]

    MCP_A --> AGENT
    MCP_B --> AGENT
    SKILL_A --> AGENT
    SKILL_B --> AGENT
    AGENT --> RESULT

    style DATA fill:#FFB6C1,color:#333
    style KNOWLEDGE fill:#90EE90,color:#333
    style AGENT fill:#87CEEB,color:#333
```

### Concrete Examples

#### Security Audit Workflow

```mermaid
sequenceDiagram
    actor U as User
    participant A as Agent
    participant RFC as rfcxml-mcp
    participant W3C as w3c-mcp
    participant OS as OWASP Skill
    participant OA as OAuth Skill

    U->>A: Audit the security of WebSocket authentication
    A->>RFC: get_requirements(6455)
    RFC-->>A: WebSocket specification requirements
    A->>RFC: get_requirements(6749)
    RFC-->>A: OAuth 2.0 specification requirements
    A->>W3C: get_webidl("websockets")
    W3C-->>A: WebSocket API definition
    A->>OS: Reference OWASP Top 10 relevant items
    OS-->>A: A01:Broken Access Control criteria
    A->>OA: Reference OAuth implementation patterns
    OA-->>A: Token management best practices
    A-->>U: Security audit report
```

| Layer     | Element     | Role                                              |
| --------- | ----------- | ------------------------------------------------- |
| **MCP**   | rfcxml-mcp  | Retrieve RFC 6455/6749 specification requirements |
| **MCP**   | w3c-mcp     | Retrieve WebSocket API definition                 |
| **Skill** | OWASP Skill | Vulnerability judgment criteria                   |
| **Skill** | OAuth Skill | Authentication implementation best practices      |

#### Specification Compliance Quality Gate

```mermaid
flowchart TB
    subgraph INPUT["Input"]
        CODE["Implementation Code"]
    end

    subgraph CHECK["Verification Process"]
        direction TB
        subgraph MCP_LAYER["MCPs: Specification Reference"]
            RFC["rfcxml-mcp<br>Technical specifications"]
            HOUREI["hourei-mcp<br>Legal texts"]
        end
        subgraph SKILL_LAYER["Skills: Quality Criteria"]
            SOLID_S["SOLID Skill<br>Design quality"]
            TEST_S["Test Patterns Skill<br>Test quality"]
        end
    end

    subgraph OUTPUT["Output"]
        REPORT["Quality Gate Report<br>Spec compliance + Design quality + Test sufficiency"]
    end

    CODE --> MCP_LAYER
    CODE --> SKILL_LAYER
    MCP_LAYER --> REPORT
    SKILL_LAYER --> REPORT

    style MCP_LAYER fill:#FFB6C1,color:#333
    style SKILL_LAYER fill:#90EE90,color:#333
```

### Design Guidelines

- **Agent orchestration is key**: The Agent layer determines which MCPs to call first and when to reference which Skills
- **Parallelize MCP calls**: Independent MCP calls should be executed in parallel to efficiently use the context window
- **Skill trigger timing**: Clarify whether to judge collectively after data retrieval or to judge incrementally

## Pattern Selection Guide

```mermaid
flowchart TD
    START{"What do you want<br>to achieve?"}

    START -->|"External data<br>retrieval + evaluation"| P1["Pattern 1<br>MCP + Skill"]
    START -->|"Multiple data source<br>integration & comparison"| P2["Pattern 2<br>MCPs"]
    START -->|"Multiple knowledge<br>layering"| P3["Pattern 3<br>Skills"]
    START -->|"Data + knowledge<br>full integration"| P4["Pattern 4<br>MCPs + Skills"]

    P1 -->|"Example"| P1E["Compliance check<br>Legal text + Judgment criteria"]
    P2 -->|"Example"| P2E["Translation workflow<br>Translation + Quality evaluation"]
    P3 -->|"Example"| P3E["Code review<br>SOLID + Clean Code + Refactoring"]
    P4 -->|"Example"| P4E["Security audit<br>Spec reference + OWASP + OAuth"]

    style P1 fill:#FFD700,color:#333
    style P2 fill:#FFB6C1,color:#333
    style P3 fill:#90EE90,color:#333
    style P4 fill:#E3F2FD,color:#333
```

## Accumulating Results

Practical results from each pattern are recorded in [outputs.md](../outputs.md). Include the following information.

| Item         | Content                                                  |
| ------------ | -------------------------------------------------------- |
| Pattern Used | Which of the 4 patterns                                  |
| Components   | MCPs and Skills used                                     |
| Input        | What was targeted                                        |
| Results      | Quantitative outcomes (time, cost, quality scores, etc.) |
| Learnings    | Improvements and suggestions for next time               |

## Related Documents

- [mcp-roadmap.md](./mcp-roadmap.md) â€” MCP Construction Roadmap
- [skill-roadmap.md](./skill-roadmap.md) â€” Skill Construction Roadmap
- [workflows/patterns.md](../workflows/patterns.md) â€” Existing Workflow Patterns (Pattern 2 track record)
- [concepts/03-architecture.md](../concepts/03-architecture.md) â€” MCP / Skill / Agent Layer Structure
- [mcp/catalog.md](../mcp/catalog.md) â€” Built MCP Catalog

---

## MCP Construction Roadmap

Source: https://shuji-bonji.github.io/ai-agent-architecture/strategy/mcp-roadmap/

# MCP Construction Roadmap

> Evaluate built and planned MCPs, and organize priorities and construction plans.

[æ—¥æœ¬èªž](/ja/strategy/mcp-roadmap)

## About This Document

This document formalizes [Discussion #19](https://github.com/shuji-bonji/ai-agent-architecture/discussions/19) (MCP Construction Strategy Map v2) as an official project document.

It evaluates MCP candidates across 5 axes and presents the build status and priority roadmap. For the Skill construction strategy, see [skill-roadmap.md](./skill-roadmap.md). For MCP Ã— Skill composition patterns, see [composition-patterns.md](./composition-patterns.md).

## 5-Axis MCP Evaluation

New MCP candidates are evaluated for feasibility across the following 5 axes. This evaluation corresponds to the five properties of "Reliable Reference Sources" in [02-reference-sources.md](../concepts/02-reference-sources.md).

| Axis                | Meaning                                                        |
| ------------------- | -------------------------------------------------------------- |
| Governing Body      | Whether a clear standards organization exists                  |
| Openness            | Whether the specification is freely available                  |
| Machine Readability | Whether XML Schema / DTD / JSON Schema etc. are provided       |
| Structural Clarity  | Whether the structure is queryable at the section/module level |
| Practical Use Cases | Industries and scale where it is actually used                 |

## Build Status

### Built MCPs

| MCP               | npm                           | Category            |
| ----------------- | ----------------------------- | ------------------- |
| rfcxml-mcp        | `@shuji-bonji/rfcxml-mcp`     | Standards           |
| w3c-mcp           | `@shuji-bonji/w3c-mcp`        | Standards           |
| pdf-spec-mcp      | `@shuji-bonji/pdf-spec-mcp`   | Standards           |
| pdf-reader-mcp    | `@shuji-bonji/pdf-reader-mcp` | Tool Execution      |
| epsg-mcp          | `@shuji-bonji/epsg-mcp`       | Specialized Domain  |
| rxjs-mcp-server   | `rxjs-mcp-server`             | Tool Execution      |
| xcomet-mcp-server | `xcomet-mcp-server`           | Tool Execution      |
| pwa-mcp           | ðŸ”’ Private                    | Development Support |

### Planned MCPs â€” 5-Axis Evaluation

| MCP Candidate | Governing Body        | Openness          | Machine Readability   | Structure | Practical Use               | Overall |
| ------------- | --------------------- | ----------------- | --------------------- | --------- | --------------------------- | ------- |
| **OpenAPI**   | âœ… OpenAPI Initiative | âœ… Free           | âœ… JSON/YAML          | âœ…        | âœ… API design in general    | **â—Ž**   |
| **S1000D**    | âœ… ASD/AIA/ATA        | âœ… Free           | âœ… XML Schema         | âœ…        | âœ… Defense & heavy industry | **â—Ž**   |
| **JATS XML**  | âœ… NISO               | âœ… Free           | âœ… XML DTD            | âœ…        | âœ… Academic publishing      | **â—Ž**   |
| **BIM/IFC**   | âœ… buildingSMART      | âœ… Free           | âœ… EXPRESS            | âš ï¸        | âœ… Construction DX          | **â—‹**   |
| **HL7 FHIR**  | âœ… HL7                | âœ… Free           | âœ… JSON/XML           | âœ…        | âœ… Healthcare informatics   | **â—Ž**   |
| **DICOM**     | âœ… NEMA               | âš ï¸ Partially paid | âœ… Proprietary format | âš ï¸        | âœ… Medical imaging          | **â–³**   |

### Candidate Details

#### S1000D MCP

> **Note**: Initially evaluated as "specification is paid," but this was incorrect. The S1000D specification is **freely downloadable** from s1000d.org (agreement to terms of use is required).

The conditions equivalent to rfcxml-mcp / w3c-mcp are met. The specification is massive at over 3,500 pages (51.8MB), but the chapter/data module structure is clear, and the same "search and retrieve only the necessary sections" design pattern used in rfcxml-mcp can be applied.

Notable points:

- **Supply chain quality gatekeeping**: AI can verify "Does this data module comply with S1000D Issue 6?" by referencing the specification
- **International interoperability**: Foundation for defense industries across countries to exchange technical documents using a common standard
- **Alignment with "democratization of knowledge"**: Many people are unaware that it is freely available; making it accessible via MCP has intrinsic value

#### JATS XML MCP

The design pattern from rfcxml-mcp is directly applicable. It can provide structured reference of academic papers, citation relationship analysis, and metadata extraction as MCP tools.

#### BIM/IFC MCP

> A Chinese university already provides a BIM MCP, but this project takes the approach of building bottom-up with [ifc-core-mcp](https://github.com/shuji-bonji/ifc-core-mcp) as the core.

Construction strategy:

- **ifc-core-mcp** (IFC4.3 schema definitions, entity search, inheritance relationships, PropertySet) is built first as the core
- Validation tools, conversion tools, etc. are progressively layered on top in a bottom-up approach

## Priority Roadmap

```mermaid
flowchart TB
    subgraph P1["Phase 1: Short-term"]
        direction TB
        P1_1["ðŸ”´ OpenAPI MCP"]
    end

    subgraph P2["Phase 2: Mid-term"]
        direction TB
        P2_1["ðŸ”´ S1000D MCP"]
        P2_2["ðŸ”´ JATS XML MCP"]
    end

    subgraph P3["Phase 3: Long-term"]
        direction TB
        P3_1["âš¡ BIM/IFC MCP<br>Progressive expansion from ifc-core-mcp"]
        P3_2["ðŸ”´ HL7 FHIR MCP"]
    end

    P1 -.-> P2 -.-> P3

    style P1 fill:#E8F5E9,stroke:#4CAF50,color:#333
    style P2 fill:#FFF3E0,stroke:#FF9800,color:#333
    style P3 fill:#FFEBEE,stroke:#F44336,color:#333
```

> For the Skill-side roadmap, see [skill-roadmap.md](./skill-roadmap.md). For hybrid composition (MCP + Skill) design guidelines, see [composition-patterns.md](./composition-patterns.md).

## Related Documents

- [Discussion #19: MCP Construction Strategy Map v2](https://github.com/shuji-bonji/ai-agent-architecture/discussions/19) â€” The Discussion that this document is based on
- [skill-roadmap.md](./skill-roadmap.md) â€” Skill Construction Roadmap
- [composition-patterns.md](./composition-patterns.md) â€” Composition Patterns
- [concepts/03-architecture.md](../concepts/03-architecture.md) â€” MCP / Skill / Agent Layer Structure
- [mcp/catalog.md](../mcp/catalog.md) â€” Built MCP Catalog

---

## Skill Construction Roadmap

Source: https://shuji-bonji.github.io/ai-agent-architecture/strategy/skill-roadmap/

# Skill Construction Roadmap

> Organize the classification system, evaluation criteria, dependency relationships, and construction plans for Skills.

[æ—¥æœ¬èªž](/ja/strategy/skill-roadmap)

## About This Document

This document formalizes [Discussion #20](https://github.com/shuji-bonji/ai-agent-architecture/discussions/20) (Skill Construction Strategy Map) as an official project document.

While MCPs handle "real-time access to external data," Skills handle "static knowledge and judgment criteria" (see [03-architecture.md](../concepts/03-architecture.md)). For the MCP construction strategy, see [mcp-roadmap.md](./mcp-roadmap.md). For composition patterns, see [composition-patterns.md](./composition-patterns.md).

## 5 Skill Types

All Skills are "static knowledge," but the structure differs depending on the type of knowledge.

```mermaid
flowchart TB
    subgraph TYPES["5 Skill Types"]
        direction TB
        PRINCIPLE["ðŸ”µ Principle Type<br>Abstract judgment criteria<br>Ex: SOLID, DRY, YAGNI"]
        PATTERN["ðŸŸ¢ Pattern Type<br>Reusable solution catalog<br>Ex: Design Patterns, EIP"]
        METHOD["ðŸŸ¡ Methodology Type<br>Development process & procedures<br>Ex: TDD, BDD, DDD"]
        CHECKLIST["ðŸŸ  Checklist Type<br>Verification & review criteria<br>Ex: Coverage Strategy"]
        GUIDELINE["ðŸ”´ Guideline Type<br>Style & quality standards<br>Ex: Clean Code"]
    end

    PRINCIPLE -->|"Patterns emerge<br>from principles"| PATTERN
    PRINCIPLE -->|"Principles guide<br>methodologies"| METHOD
    PATTERN -->|"Checklist items emerge<br>from patterns"| CHECKLIST
    METHOD -->|"Guidelines emerge<br>from methodologies"| GUIDELINE

    style PRINCIPLE fill:#4A90D9,color:#fff
    style PATTERN fill:#7BC67E,color:#333
    style METHOD fill:#F5C542,color:#333
    style CHECKLIST fill:#E8945A,color:#333
    style GUIDELINE fill:#D95B5B,color:#fff
```

| Type                 | Form of AI Instruction                            | Approximate Volume                        |
| -------------------- | ------------------------------------------------- | ----------------------------------------- |
| **Principle Type**   | "Determine whether this violates the principle"   | Short (1-3 pages)                         |
| **Pattern Type**     | "Select an applicable pattern for this situation" | Long (proportional to number of patterns) |
| **Methodology Type** | "Execute following this process"                  | Medium                                    |
| **Checklist Type**   | "Check all items and report the results"          | Short                                     |
| **Guideline Type**   | "Improve according to this guideline"             | Medium                                    |

## 5-Axis Skill Evaluation

Skill-specific evaluation criteria corresponding to MCP's 5 axes (Governing Body, Openness, Machine Readability, Structural Clarity, Practical Use Cases).

| Axis                        | Meaning                                                      |
| --------------------------- | ------------------------------------------------------------ |
| **Knowledge Stability**     | How frequently it is updated (Stable â—Ž to Volatile â–³)        |
| **Scope Clarity**           | Whether the boundary with other Skills is clear              |
| **Trigger Clarity**         | Whether it is possible to determine when to use it           |
| **Standalone Completeness** | Whether it can deliver value alone, or requires other Skills |
| **Verifiability**           | Whether the effect can be objectively measured               |

## Individual Skill Evaluations

### Foundation Skills

| Skill          | Type        | Stability | Scope | Trigger | Standalone | Verifiability |
| -------------- | ----------- | --------- | ----- | ------- | ---------- | ------------- |
| **SOLID**      | Principle   | â—Ž         | â—Ž     | â—Ž       | â—Ž          | â—‹             |
| **Clean Code** | Guideline   | â—Ž         | â—‹     | â—Ž       | â—Ž          | â–³             |
| **TDD**        | Methodology | â—Ž         | â—Ž     | â—Ž       | â—Ž          | â—Ž             |

### Design Skills

| Skill                  | Type        | Stability | Scope | Trigger | Standalone | Verifiability |
| ---------------------- | ----------- | --------- | ----- | ------- | ---------- | ------------- |
| **Design Patterns**    | Pattern     | â—Ž         | â—Ž     | â—‹       | â—‹          | â—‹             |
| **Clean Architecture** | Principle   | â—Ž         | â—Ž     | â—‹       | â—‹          | â—Ž             |
| **DDD**                | Methodology | â—Ž         | â–³     | â–³       | â–³          | â–³             |

### Testing Skills

| Skill                 | Type        | Stability | Scope | Trigger | Standalone | Verifiability |
| --------------------- | ----------- | --------- | ----- | ------- | ---------- | ------------- |
| **Test Patterns**     | Pattern     | â—‹         | â—‹     | â—Ž       | â—‹          | â—Ž             |
| **BDD**               | Methodology | â—Ž         | â—Ž     | â—‹       | â—Ž          | â—Ž             |
| **Coverage Strategy** | Checklist   | â—‹         | â—Ž     | â—Ž       | â—‹          | â—Ž             |

### Infrastructure & Architecture Skills

| Skill             | Type      | Stability | Scope | Trigger | Standalone | Verifiability |
| ----------------- | --------- | --------- | ----- | ------- | ---------- | ------------- |
| **12 Factor App** | Principle | â—Ž         | â—Ž     | â—‹       | â—Ž          | â—Ž             |
| **Microservices** | Pattern   | â—‹         | â–³     | â–³       | â–³          | â–³             |
| **EIP**           | Pattern   | â—Ž         | â—Ž     | â—‹       | â—‹          | â—‹             |
| **IaC Patterns**  | Pattern   | â—‹         | â—‹     | â—‹       | â—Ž          | â—‹             |

### Quality Improvement Skills

| Skill           | Type    | Stability | Scope | Trigger | Standalone | Verifiability |
| --------------- | ------- | --------- | ----- | ------- | ---------- | ------------- |
| **Refactoring** | Pattern | â—Ž         | â—Ž     | â—Ž       | â—‹          | â—‹             |

## Skill Dependency Relationships

Skills have a clear dependency hierarchy. While MCPs can be built independently, Skills require a build order that considers dependencies.

```mermaid
flowchart TB
    subgraph L1["Layer 1: Foundation (Build First)"]
        SOLID["ðŸ”µ SOLID"]
        CLEAN_CODE["ðŸ”´ Clean Code"]
        TDD["ðŸŸ¡ TDD"]
    end

    subgraph L2["Layer 2: Design"]
        DESIGN_PAT["ðŸŸ¢ Design Patterns"]
        CLEAN_ARCH["ðŸ”µ Clean Architecture"]
        BDD["ðŸŸ¡ BDD"]
        TEST_PAT["ðŸŸ¢ Test Patterns"]
    end

    subgraph L3["Layer 3: Application"]
        DDD["ðŸŸ¡ DDD"]
        REFACTOR["ðŸŸ¢ Refactoring"]
        COV["ðŸŸ  Coverage Strategy"]
        TWELVE_F["ðŸ”µ 12 Factor App"]
    end

    subgraph L4["Layer 4: Integration"]
        MICRO["ðŸŸ¢ Microservices"]
        EIP["ðŸŸ¢ EIP"]
        IAC["ðŸŸ¢ IaC Patterns"]
    end

    SOLID --> CLEAN_ARCH
    SOLID --> DESIGN_PAT
    SOLID -.-> CLEAN_CODE
    CLEAN_CODE --> REFACTOR
    DESIGN_PAT --> REFACTOR
    DESIGN_PAT --> DDD
    CLEAN_ARCH --> DDD
    CLEAN_ARCH --> TWELVE_F
    TDD --> TEST_PAT
    TDD --> BDD
    TEST_PAT --> COV
    DDD --> MICRO
    TWELVE_F --> MICRO
    MICRO --> EIP

    style L1 fill:#E3F2FD,stroke:#1565C0,color:#333
    style L2 fill:#E8F5E9,stroke:#2E7D32,color:#333
    style L3 fill:#FFF3E0,stroke:#EF6C00,color:#333
    style L4 fill:#FFEBEE,stroke:#C62828,color:#333
```

## Trigger Contexts â€” When to Use

Skills tend to have ambiguous "when to trigger" conditions. Here we organize them by context-based Skill sets.

| Context                   | Triggered Skills                      | Combination Purpose                                                  |
| ------------------------- | ------------------------------------- | -------------------------------------------------------------------- |
| **Writing Code**          | Clean Code                            | Constant reference for naming and function design standards          |
| **Code Review**           | SOLID + Clean Code + Refactoring      | Detect principle violations â†’ Identify smells â†’ Suggest improvements |
| **Architecture Design**   | DDD + Clean Architecture + 12 Factor  | Domain modeling â†’ Layer design â†’ Cloud readiness                     |
| **Test Design**           | TDD + BDD + Test Patterns + Coverage  | Process â†’ Scenarios â†’ Pattern application â†’ Coverage assessment      |
| **Refactoring**           | Refactoring + Design Patterns + SOLID | Detect smells â†’ Apply patterns â†’ Verify principle compliance         |
| **Infrastructure Design** | 12 Factor + Microservices + IaC + EIP | Cloud-native â†’ Decomposition â†’ Automation â†’ Integration              |

> For details on multi-Skill simultaneous trigger patterns, see [composition-patterns.md](./composition-patterns.md).

## Challenges of "Ambiguity" and Countermeasures

Skill design has unique challenges that MCPs do not face.

### Challenge 1: Scope Overlap

Is "SRP (Single Responsibility Principle)" part of the SOLID Skill or the Clean Code Skill?

**Countermeasure**: Place the **definition** of the principle in the SOLID Skill, and **reference it as an application example** in Clean Code. Establish a "primary source of definition" among Skills.

### Challenge 2: Granularity Decisions

Should DDD be one Skill? Or should it be split into Strategic Patterns and Tactical Patterns?

**Countermeasure**: If the trigger context is the same, keep it as one. Start with one and decide on separation through operational experience.

### Challenge 3: Quality Measurement

How do you measure "Is this a good Skill?"

**Countermeasure**: Measure using the following indirect metrics.

| Metric                  | Measurement Method                                                                    |
| ----------------------- | ------------------------------------------------------------------------------------- |
| AI Judgment Accuracy    | Whether review feedback became more accurate after Skill application                  |
| Trigger Appropriateness | Whether it avoids triggering in unnecessary situations and triggers in necessary ones |
| Context Efficiency      | The effect gained relative to token consumption from Skill references                 |

## Priority Roadmap

Build order considering dependencies and practical relevance.

```mermaid
flowchart TB
    subgraph P1["Phase 1: Foundation (Ready to Start)"]
        direction TB
        P1_1["ðŸ”µ SOLID Skill<br>Prerequisite for most Skills"]
        P1_2["ðŸ”´ Clean Code Skill<br>Triggered daily"]
        P1_3["ðŸŸ¡ TDD Skill<br>Foundation for testing"]
    end

    subgraph P2["Phase 2: Design"]
        direction TB
        P2_1["ðŸŸ¢ Test Patterns Skill<br>Directly practical (Jasmine/RxJS)"]
        P2_2["ðŸŸ¢ Design Patterns Skill"]
        P2_3["ðŸ”µ Clean Architecture Skill"]
    end

    subgraph P3["Phase 3: Application"]
        direction TB
        P3_1["ðŸŸ¢ Refactoring Skill"]
        P3_2["ðŸŸ¡ DDD Skill"]
        P3_3["ðŸŸ¡ BDD Skill"]
        P3_4["ðŸŸ  Coverage Strategy Skill"]
    end

    subgraph P4["Phase 4: Infrastructure Integration"]
        direction TB
        P4_1["ðŸ”µ 12 Factor App Skill"]
        P4_2["ðŸŸ¢ Microservices Skill"]
        P4_3["ðŸŸ¢ EIP / IaC Patterns Skill"]
    end

    P1 -.-> P2 -.-> P3 -.-> P4

    style P1 fill:#E3F2FD,stroke:#1565C0,color:#333
    style P2 fill:#E8F5E9,stroke:#2E7D32,color:#333
    style P3 fill:#FFF3E0,stroke:#EF6C00,color:#333
    style P4 fill:#FFEBEE,stroke:#C62828,color:#333
```

## Related Documents

- [Discussion #20: Skill Construction Strategy Map](https://github.com/shuji-bonji/ai-agent-architecture/discussions/20) â€” The Discussion that this document is based on
- [mcp-roadmap.md](./mcp-roadmap.md) â€” MCP Construction Roadmap
- [composition-patterns.md](./composition-patterns.md) â€” Composition Patterns
- [concepts/03-architecture.md](../concepts/03-architecture.md) â€” Skill Definitions and Layer Structure
- [skills/creating-skills.md](../skills/creating-skills.md) â€” Skill Creation Guide

---

## Development Phases Ã— MCP Integration

Source: https://shuji-bonji.github.io/ai-agent-architecture/workflows/development-phases/

# Development Phases Ã— MCP Integration

> Organizing MCPs that can be utilized in each phase of system and application development.

## About This Document

Software development progresses through phases: "Strategy/Planning â†’ Requirements Definition â†’ Design â†’ Implementation â†’ Testing â†’ Operations." In AI-driven development, leveraging appropriate MCPs at each phase can improve both quality and efficiency.

This document organizes the MCPs available for each development phase, areas that have not yet been built, and candidates for future priority development. It provides practical answers to the question "I want to use AI in this phase, but what should I use?"

## Development Phase Overview

The following diagram shows how development phases flow sequentially through the project lifecycle:

```mermaid
flowchart LR
    P1[Strategy/Planning] --> P2[Requirements Definition]
    P2 --> P3[Design]
    P3 --> P4[Implementation]
    P4 --> P5[Testing]
    P5 --> P6[Operations]

    P6 -.->|Feedback| P1
```

## Phase 1: Strategy/Planning

### Overview

Setting business goals, conducting feasibility studies, and formulating product strategy.

### MCP Utilization

This table shows which MCPs are available and planned for strategic planning tasks:

| Task              | MCP                     | Function              | Status    |
| ----------------- | ----------------------- | --------------------- | --------- |
| Market Research   | Market Research MCP     | Market size data      | ðŸ“‹ Planned |
| Competitor Analysis | Competitor Analysis MCP | Competitor comparison | ðŸ“‹ Planned |
| ROI Calculation   | Financial Modeling MCP  | TCO calculation       | ðŸ“‹ Planned |

### Current Status

MCPs for this phase have not been built. Web search and Claude's own analytical capabilities serve as alternatives.

## Phase 2: Requirements Definition

### Overview

Gathering and organizing functional and non-functional requirements.

### MCP Utilization

The following table identifies MCPs that help extract and structure requirements:

| Task                   | MCP            | Function                    | Status     |
| ---------------------- | -------------- | --------------------------- | ---------- |
| RFC Requirements Check | **rfcxml-mcp** | MUST/SHOULD/MAY extraction  | âœ… Built    |
| Web Standards Check    | **w3c-mcp**    | WebIDL, CSS, HTML specs     | âœ… Built    |
| Legal Requirements     | **hourei-mcp** | Legal text retrieval        | âœ… Available |
| API Spec Verification  | OpenAPI MCP    | Specification validation    | ðŸ“‹ Planned  |

### Example

The following sequence diagram illustrates how MCPs support the requirements gathering process:

```mermaid
sequenceDiagram
    participant PM as Product Manager
    participant Claude as Claude + MCPs
    participant RFC as rfcxml-mcp
    participant Law as hourei-mcp

    PM->>Claude: Summarize requirements for WebSocket functionality
    Claude->>RFC: get_requirements(6455)
    RFC-->>Claude: 75 MUST, 23 SHOULD
    Claude->>Law: What are the legal requirements for communications?
    Law-->>Claude: Relevant provisions of telecommunications law
    Claude-->>PM: Technical requirements + Legal considerations
```

## Phase 3: Design

### Overview

Architecture design, detailed design, and API design.

### MCP Utilization

The following MCPs support various design activities:

| Task               | MCP                 | Function             | Status     |
| ------------------ | ------------------- | -------------------- | ---------- |
| Design Patterns    | Design Pattern MCP  | Pattern suggestions  | ðŸ“‹ Planned  |
| ADR Generation     | ADR Generator MCP   | Decision record gen  | ðŸ“‹ Planned  |
| DB Design          | Schema Designer MCP | ER diagram gen       | ðŸ“‹ Planned  |
| Diagram Generation | **mermaid-mcp**     | Mermaid diagrams     | âœ… Available |
| API Design Validation | OpenAPI MCP      | Spec validation      | ðŸ“‹ Planned  |

### Current Status

Design pattern MCPs have not been built. It may be more appropriate to define a "Design Pattern Collection" as a Skill.

### Skill Alternative Example

Here is how design patterns can be effectively provided through a Skill:

```markdown
<!-- .claude/skills/design-patterns/SKILL.md -->

# Design Pattern Collection

## Architecture Patterns

- Clean Architecture
- Hexagonal Architecture
- CQRS + Event Sourcing

## GoF Patterns (Excerpt)

- Factory Method
- Observer
- Strategy
  ...
```

## Phase 4: Implementation

### Overview

Coding, API implementation, frontend/backend development.

### MCP Utilization

The following MCPs provide development support for implementation tasks:

| Task                | MCP                   | Function                | Status     |
| ------------------- | --------------------- | ----------------------- | ---------- |
| Documentation Search | Context7             | Library documentation   | âœ… Available |
| Svelte Development  | **svelte-mcp**        | Svelte/SvelteKit support | âœ… Available |
| UI Components       | **shadcn-svelte-mcp** | UI components           | âœ… Available |
| RxJS Development    | **rxjs-mcp-server**   | Stream execution/analysis | âœ… Built   |
| Coordinate Reference | **epsg-mcp**         | EPSG coordinate systems | âœ… Built    |
| Angular Development | Angular MCP           | Angular support         | ðŸ“‹ Planned  |

### Example: RxJS Implementation Flow

The following sequence diagram shows how the RxJS MCP assists in verifying and debugging stream-based code:

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant Claude as Claude
    participant RxJS as rxjs-mcp

    Dev->>Claude: Please verify how this RxJS code works
    Claude->>RxJS: execute_stream(code)
    RxJS-->>Claude: Execution result + Timeline
    Claude->>RxJS: analyze_operators(code)
    RxJS-->>Claude: Performance analysis
    Claude->>RxJS: detect_memory_leak(code)
    RxJS-->>Claude: Leak detection result
    Claude-->>Dev: Operation verification + Improvement suggestions
```

## Phase 5: Testing & Quality Assurance

### Overview

Unit testing, integration testing, and quality evaluation.

### MCP Utilization

The following MCPs support quality assessment and compliance verification:

| Task                  | MCP                   | Function                   | Status     |
| --------------------- | --------------------- | -------------------------- | ---------- |
| Translation QA        | **xcomet-mcp-server** | Quality scores, error detection | âœ… Built |
| Test Generation       | Test Generator MCP    | Test code generation       | ðŸ“‹ Planned  |
| Security              | OWASP MCP             | Vulnerability checks       | ðŸ“‹ Planned  |
| RFC Compliance Check  | **rfcxml-mcp**        | validate_statement         | âœ… Built    |

### Example: Translation Quality Testing

This workflow demonstrates quality verification for translated content:

```mermaid
flowchart TB
    SOURCE[Source Text] --> TRANSLATE[Translation]
    TRANSLATE --> EVAL[xcomet:xcomet_evaluate]
    EVAL --> CHECK{Score >= 0.85?}
    CHECK -->|Yes| PASS[âœ… Pass]
    CHECK -->|No| FAIL[âŒ Needs Revision]
    FAIL --> ERRORS[xcomet:xcomet_detect_errors]
    ERRORS --> FIX[Identify corrections]
```

## Phase 6: Operations & Maintenance

### Overview

Deployment, monitoring, incident response, and continuous improvement.

### MCP Utilization

The following MCPs support operations and maintenance activities:

| Task                | MCP                    | Function            | Status    |
| ------------------- | ---------------------- | ------------------- | --------- |
| IaC Generation      | IaC Generator MCP      | Terraform generation | ðŸ“‹ Planned |
| Pipeline            | Pipeline Generator MCP | CI/CD configuration | ðŸ“‹ Planned |
| Monitoring Config   | Monitoring Config MCP  | Monitoring setup    | ðŸ“‹ Planned |

### Current Status

Operations MCPs have not been built. If cloud provider-specific MCPs exist, use those instead.

## Cross-Cutting Activities

### Documentation

These MCPs provide support for documentation tasks across all phases:

| Task              | MCP             | Status     |
| ----------------- | --------------- | ---------- |
| Diagram Generation | **mermaid-mcp** | âœ… Available |
| Translation       | **deepl-mcp**   | âœ… Available |
| Quality Check     | **xcomet-mcp**  | âœ… Built    |

### Security

Security-focused MCPs help identify and manage vulnerabilities:

| Task          | MCP         | Status    |
| ------------- | ----------- | --------- |
| OWASP Check   | OWASP MCP   | ðŸ“‹ Planned |
| CVE Search    | CVE/NVD MCP | ðŸ“‹ Planned |

### Legal Compliance

MCPs supporting legal and regulatory compliance:

| Task           | MCP            | Status     |
| -------------- | -------------- | ---------- |
| Legal Search   | **hourei-mcp** | âœ… Available |
| GDPR Check     | GDPR MCP       | ðŸ“‹ Planned  |

## Phase Ã— MCP Matrix

This matrix provides an overview of MCP availability across all development phases:

| Phase               | Built MCPs                 | Planned MCPs                        |
| ------------------- | -------------------------- | ----------------------------------- |
| Strategy/Planning   | -                          | Market Research, Financial Modeling |
| Requirements        | rfcxml, w3c, hourei        | OpenAPI                             |
| Design              | mermaid                    | Design Pattern, ADR Generator       |
| Implementation      | rxjs, svelte, shadcn, epsg | Angular, Context7 integration       |
| Testing             | xcomet, rfcxml             | Test Generator, OWASP               |
| Operations          | -                          | IaC Generator, Pipeline Generator   |

## MCPs to Build with Priority

### Leveraging Current Strengths

The following MCPs represent the highest-priority development opportunities:

1. **OpenAPI MCP** - API design/validation (cross-cutting: Requirements â†’ Design â†’ Testing)
2. **OWASP MCP** - Security (cross-cutting: Design â†’ Testing)
3. **Angular MCP** - Implementation support for specialized domains

### Filling Gaps

1. Design phase pattern tools â†’ **Can be substituted with Skills**
2. Operations phase IaC tools â†’ Low priority (existing tools serve as alternatives)

## Recommended Approach

The following diagram shows the recommended strategy for maximizing AI-driven development support:

```mermaid
graph TB
    subgraph Utilize Built MCPs
        RFC[rfcxml-mcp]
        W3C[w3c-mcp]
        XCOMET[xcomet-mcp]
        RXJS[rxjs-mcp]
    end

    subgraph Skill Supplementation
        PATTERN[Design Pattern Skill]
        WORKFLOW[Workflow Skill]
    end

    subgraph Build Next
        OPENAPI[OpenAPI MCP]
        OWASP[OWASP MCP]
    end

    RFC --> Requirements
    W3C --> Requirements
    XCOMET --> Testing
    RXJS --> Implementation

    PATTERN --> Design
    WORKFLOW --> All Phases

    OPENAPI --> Design
    OWASP --> Testing
```

### Principles

Follow these principles when integrating MCPs into your development process:

1. **Maximize utilization of built MCPs**
2. **Supplement static knowledge with Skills**
3. **Build gaps sequentially based on priority**

---

## Integration Patterns and Workflows

Source: https://shuji-bonji.github.io/ai-agent-architecture/workflows/patterns/

# Integration Patterns and Workflows

> A compilation of practical workflow patterns that combine multiple MCPs, Skills, and sub-agents.

## About This Document

MCPs demonstrate their true value when combined rather than used individually. This document organizes eight types of integration patterns that have proven effective in practice, describing the procedures, tools used, and expected outcomes for each.

For example, to achieve the goal of "creating high-quality Japanese translations of RFCs," we can establish a workflow of deepl-mcp (translation) â†’ xcomet-mcp-server (quality evaluation) â†’ re-translation as needed, achieving equivalent or better quality at less than 1/100th of traditional translation costs. This document accumulates such practical knowledge as patterns.

## Workflow Pattern Overview

The following mindmap organizes the available workflow patterns by their primary use case domains:

```mermaid
mindmap
  root((Workflow<br/>Patterns))
    Translation
      Technical Document Translation
      Large-Scale Translation
      Glossary-Linked Translation
    Specification Reference
      RFC Specification Verification
      Web Standards Verification
      Legal Reference
    Composite
      LegalÃ—Technical Mapping
      Checklist Generation
      Compliance Verification
    Development Support
      RxJS Debugging
      Svelte Development
      Documentation Generation
```

## Pattern 1: Technical Document Translation Workflow

### Overview

A high-quality translation flow combining DeepL + xCOMET.

### MCPs Used

- `deepl-mcp` - Translation execution
- `xcomet-mcp-server` - Quality evaluation

### Flow Diagram

This diagram shows the iterative process of translation, quality evaluation, and refinement:

```mermaid
flowchart TB
    START[Source Text] --> TRANSLATE[deepl:translate-text<br/>formality: more]
    TRANSLATE --> EVAL[xcomet:xcomet_evaluate]
    EVAL --> CHECK{Score >= 0.85?}
    CHECK -->|Yes| DETECT[xcomet:xcomet_detect_errors]
    CHECK -->|No| RETRY[Re-translate/Revise]
    RETRY --> TRANSLATE
    DETECT --> REVIEW{Critical Error?}
    REVIEW -->|Yes| FIX[Manual Correction]
    REVIEW -->|No| OUTPUT[Translation Complete]
    FIX --> EVAL
```

### Skill Definition Example

The following Skill complements this pattern by defining quality thresholds and error handling procedures:

```markdown
<!-- .claude/skills/translation-workflow/SKILL.md -->

# Technical Document Translation Workflow

## Quality Criteria

- Score 0.85 or above: Pass
- Score 0.70-0.85: Requires review
- Score below 0.70: Re-translate

## Error Handling

- critical: Must fix (meaning reversal, serious mistranslation)
- major: Recommended fix (unnatural expressions, terminology inconsistency)
- minor: Optional (style issues)

## Translation Settings

- formality: "more" (use formal tone for technical documents)
- Specify glossaryId if a glossary is available
```

### Results

This workflow has proven highly effective in practice:

- Completed 180-page technical document (1.5 million characters) in one day
- Cost: approximately $12 (less than 1/100th of traditional cost)

## Pattern 2: Large-Scale Translation Workflow (Batch Processing)

### Overview

A batch workflow for efficiently processing large volumes of translation pairs.

### Flow Diagram

This diagram shows how batch processing enables efficient evaluation and targeted refinement:

```mermaid
flowchart TB
    START[Large Document] --> SPLIT[Section Split]
    SPLIT --> BATCH[Batch Translation<br/>deepl:translate-text]
    BATCH --> BATCH_EVAL[Batch Evaluation<br/>xcomet:xcomet_batch_evaluate]
    BATCH_EVAL --> ANALYZE[Result Analysis]
    ANALYZE --> LOW{Low Scores?}
    LOW -->|Yes| IDENTIFY[Identify Problem Sections]
    LOW -->|No| MERGE[Merge]
    IDENTIFY --> INDIVIDUAL[Individual Re-translation]
    INDIVIDUAL --> BATCH_EVAL
    MERGE --> OUTPUT[Completed Document]
```

### Key Points

Follow these practices when implementing batch translation workflows:

- Use `xcomet:xcomet_batch_evaluate` for bulk evaluation
- Address only problematic sections individually
- Further acceleration possible with GPU usage

## Pattern 3: RFC Specification Verification Workflow

### Overview

A flow for structuring and understanding RFC specifications and verifying implementations.

### MCPs Used

- `rfcxml-mcp` - RFC analysis
- `w3c-mcp` - Web API verification (as needed)

### Flow Diagram

This workflow guides the process from requirements through implementation to compliance verification:

```mermaid
flowchart TB
    START[Implementation Requirements] --> SEARCH[Identify Related RFCs]
    SEARCH --> STRUCTURE[rfcxml:get_rfc_structure<br/>Get Section Structure]
    STRUCTURE --> REQUIREMENTS[rfcxml:get_requirements<br/>Extract MUST/SHOULD]
    REQUIREMENTS --> CHECKLIST[rfcxml:generate_checklist<br/>Generate Checklist]
    CHECKLIST --> IMPL[Implementation]
    IMPL --> VALIDATE[rfcxml:validate_statement<br/>Verify Compliance]
    VALIDATE --> PASS{Compliant?}
    PASS -->|Yes| DONE[Complete]
    PASS -->|No| FIX[Fix]
    FIX --> IMPL
```

### Sub-Agent Definition Example

The following sub-agent specializes in RFC verification by limiting its tools to RFC-specific operations:

```markdown
<!-- .claude/agents/rfc-specialist.md -->

name: rfc-specialist
description: Specializes in RFC specification verification. Confirms whether implementations comply with RFCs.
tools: rfcxml:get_rfc_structure, rfcxml:get_requirements, rfcxml:get_definitions, rfcxml:generate_checklist, rfcxml:validate_statement
model: sonnet

You are an RFC specification expert.
Please work according to the following procedure:

1. First, use get_rfc_structure to understand the overall RFC structure
2. Extract MUST/SHOULD requirements with get_requirements
3. Verify terminology with get_definitions as needed
4. Generate an implementation checklist with generate_checklist
5. Confirm implementation compliance with validate_statement
```

### Results

This workflow has been used successfully to produce high-quality RFC work:

- Complete Japanese translation of RFC 6455 (WebSocket)
- Structured 75 MUST requirements and 23 SHOULD requirements

## Pattern 4: Legal Ã— Technical Specification Mapping Workflow

### Overview

A flow for clarifying the correspondence between legal requirements and technical specifications.

### MCPs Used

- `hourei-mcp` - Japanese law reference
- `rfcxml-mcp` - Technical specification reference

### Flow Diagram

This workflow integrates legal and technical domains to identify gaps and alignment:

```mermaid
flowchart TB
    START[Compliance Requirements] --> LEGAL[hourei:find_law_article<br/>Get Legal Requirements]
    LEGAL --> TECH[rfcxml:get_requirements<br/>Get Technical Requirements]
    TECH --> MAP[Requirements Mapping]
    MAP --> GAP{Gap Exists?}
    GAP -->|Yes| IDENTIFY[Identify Unaddressed Requirements]
    GAP -->|No| REPORT[Generate Compliance Report]
    IDENTIFY --> PLAN[Create Response Plan]
    PLAN --> IMPL[Implementation]
    IMPL --> VERIFY[Verification]
    VERIFY --> REPORT
```

### Specific Example: Electronic Signature Act Ã— RFC 3161

This specific example demonstrates how legal and technical requirements map to each other:

```mermaid
graph TB
    subgraph Legal Requirements["Electronic Signature Act Article 2"]
        L1["Creator Authentication"]
        L2["Tampering Detection"]
    end

    subgraph Technical Requirements["RFC 3161"]
        T1["TSA Signature"]
        T2["MessageImprint"]
        T3["genTime"]
    end

    L1 --> T1
    L2 --> T2
    T1 --> T3
    T2 --> T3
```

### Results

This approach has successfully enabled cross-domain analysis:

- Created correspondence table between Electronic Signature Act and RFC 3161
- Reflected in Notes-about-Digital-Signatures repository

## Pattern 5: Checklist Generation Workflow

### Overview

A flow for automatically generating implementation checklists from specifications.

### Flow Diagram

This workflow converts specification requirements into actionable checklists for different roles:

```mermaid
flowchart TB
    START[Target Specification] --> GET[rfcxml:get_requirements]
    GET --> FILTER{Role Filter}
    FILTER -->|Client| CLIENT[Client Requirements]
    FILTER -->|Server| SERVER[Server Requirements]
    FILTER -->|Both| BOTH[Common Requirements]
    CLIENT --> GEN[rfcxml:generate_checklist<br/>role: client]
    SERVER --> GEN2[rfcxml:generate_checklist<br/>role: server]
    BOTH --> GEN3[rfcxml:generate_checklist<br/>role: both]
    GEN --> MD[Markdown Checklist]
    GEN2 --> MD
    GEN3 --> MD
```

### Output Example

The following shows the type of output generated by this workflow:

```markdown
# RFC 6455 WebSocket Implementation Checklist (Client)

## MUST Requirements

- [ ] Client MUST reject any response from server other than HTTP 101
- [ ] Client MUST send Sec-WebSocket-Key header
- [ ] ...

## SHOULD Requirements

- [ ] Client SHOULD retry with exponential backoff on connection failure
- [ ] ...
```

## Pattern 6: RxJS Debugging Workflow

### Overview

A flow for verifying and debugging RxJS stream behavior.

### MCPs Used

- `rxjs-mcp-server` - Stream execution and analysis

### Flow Diagram

This workflow provides comprehensive analysis of RxJS code through multiple verification methods:

```mermaid
flowchart TB
    START[RxJS Code] --> ANALYZE[rxjs:analyze_operators<br/>Operator Analysis]
    ANALYZE --> LEAK[rxjs:detect_memory_leak<br/>Memory Leak Detection]
    LEAK --> EXECUTE[rxjs:execute_stream<br/>Execute & Get Results]
    EXECUTE --> MARBLE[rxjs:generate_marble<br/>Marble Diagram]
    MARBLE --> REVIEW[Behavior Review]
    REVIEW --> OK{As Expected?}
    OK -->|Yes| DONE[Complete]
    OK -->|No| SUGGEST[rxjs:suggest_pattern<br/>Pattern Suggestion]
    SUGGEST --> REFACTOR[Refactoring]
    REFACTOR --> EXECUTE
```

## Pattern 7: Documentation Generation Workflow

### Overview

A technical documentation generation flow combining multiple MCPs.

### MCPs Used

- `rfcxml-mcp` - Specification information
- `mermaid-mcp` - Diagram generation
- `deepl-mcp` - Multilingual support
- `xcomet-mcp` - Translation quality verification

### Flow Diagram

This workflow integrates specification content, visualization, and translation to create multilingual documentation:

```mermaid
flowchart TB
    START[Documentation Requirements] --> SPEC[rfcxml:get_rfc_structure<br/>Get Specification Info]
    SPEC --> CONTENT[Content Creation]
    CONTENT --> DIAGRAM[mermaid:validate_and_render<br/>Diagram Generation]
    DIAGRAM --> DRAFT[Japanese Draft]
    DRAFT --> TRANSLATE[deepl:translate-text<br/>Create English Version]
    TRANSLATE --> EVAL[xcomet:xcomet_evaluate<br/>Quality Check]
    EVAL --> PUBLISH[Publish]
```

## Pattern 8: Multi-Agent Collaboration

### Overview

A pattern where multiple sub-agents collaborate on tasks.

### Configuration

The following diagram shows how multiple specialized agents work together under a main orchestrator:

```mermaid
graph TB
    subgraph Orchestrator["Main Claude"]
        MAIN[Orchestrator]
    end

    subgraph Agents["Sub-Agents"]
        RFC["RFC Agent<br/>rfcxml dedicated"]
        TRANS["Translation Agent<br/>deepl+xcomet dedicated"]
        DOC["Documentation Agent<br/>mermaid dedicated"]
    end

    MAIN -->|"Spec Check"| RFC
    MAIN -->|"Translation"| TRANS
    MAIN -->|"Diagrams"| DOC

    RFC -->|"Results"| MAIN
    TRANS -->|"Results"| MAIN
    DOC -->|"Results"| MAIN
```

### Sub-Agent Definitions

The following examples show how to define sub-agents with specialized tool access:

```markdown
<!-- agents/rfc-specialist.md -->

name: rfc-specialist
tools: rfcxml:\*
model: sonnet
```

```markdown
<!-- agents/translation-specialist.md -->

name: translation-specialist
tools: deepl:translate-text, xcomet:xcomet_evaluate, xcomet:xcomet_detect_errors
model: sonnet
```

```markdown
<!-- agents/documentation-specialist.md -->

name: documentation-specialist
tools: mermaid:\*
model: sonnet
```

### Benefits

Multi-agent collaboration provides several advantages:

- **Context Isolation** - Each agent only recognizes its own MCPs
- **Enhanced Specialization** - Role-specific instructions
- **Parallel Processing** - Physical separation possible with Git worktrees

## Workflow Selection Guide

Use this table to select the most appropriate workflow pattern for your use case:

| Purpose                  | Recommended Pattern | Primary MCPs            |
| ------------------------ | ------------------- | ----------------------- |
| Technical Document Translation | Pattern 1/2        | deepl + xcomet          |
| Specification Understanding | Pattern 3          | rfcxml                  |
| Compliance Verification  | Pattern 4          | hourei + rfcxml         |
| Implementation Check     | Pattern 5          | rfcxml                  |
| RxJS Debugging           | Pattern 6          | rxjs                    |
| Documentation Creation   | Pattern 7          | Composite               |
| Large-Scale Tasks        | Pattern 8          | Composite + Sub-agents  |

---

## Glossary

Source: https://shuji-bonji.github.io/ai-agent-architecture/glossary/

# Glossary

> Definitions of MCP-related terms and concepts.

## About This Document

The MCP ecosystem involves many specialized terms and abbreviations. This document serves as a centralized reference for the definitions of terms used throughout this documentation set.

If you are new to this documentation, you can deepen your understanding by referring here when encountering unfamiliar terms. It also serves to unify terminology interpretation as a common language within teams.

## Protocols and Standards

### MCP (Model Context Protocol)

An open protocol developed by Anthropic for connecting AI models with external tools and resources.

```
Features:
- JSON-RPC based
- Provides Tools, Resources, and Prompts
- Often described as "USB for AI"
```

**Related**: MCP Server, MCP Client, MCP Host

### A2A (Agent-to-Agent Protocol)

An inter-agent communication protocol proposed by Google and donated to the Linux Foundation.

```
Features:
- Standardizes collaboration between agents
- Complementary relationship with MCP (MCP=tool connection, A2A=inter-agent)
- Over 150 companies have announced support
```

**Related**: Agent Card, Task Management

### RFC (Request for Comments)

Technical standard documents published by IETF for internet technologies.

```
Examples:
- RFC 6455: WebSocket Protocol
- RFC 3161: Timestamp Protocol
- RFC 9110: HTTP Semantics
```

**Related**: IETF, MUST/SHOULD/MAY

## MCP Architecture

### MCP Host

An application that embeds an MCP Client and provides the user interface.

```
Examples:
- Claude Code
- Claude.ai
- Cursor
- VS Code (via extensions)
```

### MCP Client

The protocol layer that handles communication with MCP Servers.

```
Responsibilities:
- Server discovery and startup
- Connection management
- JSON-RPC communication
- Error handling

Typically embedded in the Host; developers rarely interact with it directly.
```

### MCP Server

A service that provides Tools, Resources, and Prompts.

```
Responsibilities:
- Tool definition and execution
- Providing access to Resources
- Providing Prompt templates

Examples:
- rfcxml-mcp (RFC parsing)
- deepl-mcp (translation)
- xcomet-mcp-server (quality evaluation)
```

### Tool

An executable function provided by an MCP Server.

```
Examples:
- get_rfc_structure (rfcxml-mcp)
- translate-text (deepl-mcp)
- xcomet_evaluate (xcomet-mcp-server)

Components:
- name
- description
- inputSchema
```

### Resource

Data or files provided by an MCP Server.

```
Examples:
- Files in the filesystem
- Database records
- External API data

Identified using URI format.
```

## Claude Code Specific

### Custom Subagent

An AI assistant specialized for specific tasks that can be defined within Claude Code.

```
Definition locations:
- .claude/agents/xxx.md (project)
- ~/.claude/agents/xxx.md (user)

Features:
- Independent context
- Tool restrictions possible
- Clear role definition
```

**Note**: Not a "replacement" for MCP Client, but rather a "higher layer"

### Skill

Static knowledge and guidelines that can be referenced in Claude Code.

```
Definition locations:
- .claude/skills/xxx/SKILL.md (project)
- ~/.claude/skills/xxx/SKILL.md (user)

Features:
- Markdown format
- No execution capability (reference only)
- Low context consumption
```

**Use cases**: Best practices, workflow definitions, coding conventions

### CLAUDE.md

An instruction file for Claude placed at the project root.

```
Contents:
- Project overview
- List of MCPs in use
- Coding conventions
- Workflow instructions
```

## Requirement Levels

### MUST / MUST NOT

Mandatory requirements in RFCs. Non-compliance constitutes a specification violation.

```
Example: "A TCP implementation MUST support simultaneous open attempts"
```

### SHOULD / SHOULD NOT

Recommended requirements in RFCs. May be violated with valid justification.

```
Example: "Implementations SHOULD use exponential backoff"
```

### MAY

Optional requirements in RFCs. Implementation is at the discretion of the developer.

```
Example: "A client MAY provide additional metadata"
```

## Quality Evaluation

### xCOMET

A neural metric for evaluating translation quality.

```
Features:
- Score from 0-1 (higher is better quality)
- Error span detection
- Can evaluate without reference translations
```

### Error Severity

The severity level of errors detected by xCOMET.

```
Levels:
- critical: Severe (meaning reversal, mistranslation)
- major: Moderate (unnatural expressions)
- minor: Minor (style issues)
```

## AI Design Patterns

### RAG (Retrieval-Augmented Generation)

A technique that retrieves external documents via vector search and injects relevant information into the LLM's prompt.

```
How it works:
1. Split documents into chunks â†’ Vectorize â†’ Store in DB
2. Vectorize the user's question
3. Retrieve related chunks via similarity search
4. Inject chunks into prompt for LLM to generate answer

Strengths: Can find relevant information from large volumes of unstructured text
Weaknesses: Context lost through chunking, doesn't understand structure
```

**Related**: Embedding, Vector DB, Chunk

> **Difference from MCP**: See [concepts/04-ai-design-patterns.md](./concepts/04-ai-design-patterns.md)

### Embedding

Converting text into numerical vectors (arrays of hundreds to thousands of dimensions). Semantically similar texts are placed close together in vector space. The foundational technology behind RAG's vector search.

### Vector Database

A specialized database for storing and searching embedded vector data. Provides fast similarity search using cosine similarity and other metrics.

```
Examples: Pinecone, Weaviate, Chroma, pgvector
```

### Chunk

A small fragment created by splitting a document. In RAG, documents are split into chunks before vectorization. The chunk size and splitting method affect search accuracy.

### Prompt Engineering

A technique for controlling output quality solely through input prompt design, without changing model parameters. Includes techniques such as Zero-shot, Few-shot, and Chain-of-Thought.

### GraphRAG

A technique that combines standard RAG with knowledge graphs, leveraging entity relationships for search and generation. Particularly effective for relational questions like "How is A related to B?"

### Fine-tuning

A technique that further trains an LLM's parameters on domain-specific data. If RAG is "external memory," Fine-tuning is closer to "rewriting internal knowledge."

### Agentic AI

A pattern where an LLM autonomously plans, invokes tools, and solves problems through multiple steps. MCP is one of the foundational technologies that enables this pattern.

**Related**: MCP, Subagent, A2A

## Other Terms

### Authoritative Reference Sources

Authoritative information sources for maintaining consistency in AI decisions.

```
Hierarchy:
1. International standards and regulations (MUST comply)
2. Industry standards and de facto standards (SHOULD comply)
3. Organization/project conventions (local)
4. Best practices (recommended)
```

### Democratization of Knowledge

Lowering barriers to accessing specialized knowledge.

```
In the MCP context:
- Limited number of people can read specifications
  â†’ AI references them via MCP and provides in an understandable format for anyone
- Accurate information-based development becomes possible
  without relying on expensive consultants or specialists
```

### AI-Driven Development

A development methodology that utilizes AI as an "intelligent assistant" throughout the entire development process, not just for code generation.

```
â‰  Having AI write code
= Utilizing AI throughout all processes while humans focus on judgment and creativity
```

### Over-MCPization

A state where too many MCP servers are added unnecessarily, overwhelming the context window.

```
Symptoms:
- Tool definitions constantly consume context
- Increased startup overhead
- 70k problem (performance degradation from too many tools)

Countermeasures:
- Migrate to Skills where possible
- Limit MCPs per project
```

### Agent Card

Self-introduction information for agents in the A2A protocol.

```
Location: /.well-known/agent.json

Contents:
- Agent name
- Endpoint
- Provided skills
- Authentication method
```

## Abbreviation List

| Abbreviation | Full Name                                          | Description                              |
| ------------ | -------------------------------------------------- | ---------------------------------------- |
| RAG          | Retrieval-Augmented Generation                     | Search-augmented generation technique    |
| MCP          | Model Context Protocol                             | Protocol for connecting AI and tools     |
| A2A          | Agent-to-Agent Protocol                            | Inter-agent communication protocol       |
| RFC          | Request for Comments                               | IETF technical standard documents        |
| IETF         | Internet Engineering Task Force                    | Internet technology standardization body |
| W3C          | World Wide Web Consortium                          | Web standardization body                 |
| WHATWG       | Web Hypertext Application Technology Working Group | Standardization body for HTML, etc.      |
| API          | Application Programming Interface                  | Interface between applications           |
| JSON-RPC     | JSON Remote Procedure Call                         | JSON-based RPC protocol                  |
| ADR          | Architecture Decision Record                       | Architecture decision documentation      |
| TLS          | Transport Layer Security                           | Communication encryption protocol        |
| TSA          | Time Stamp Authority                               | Timestamp authority                      |

---

## Outputs and Achievements

Source: https://shuji-bonji.github.io/ai-agent-architecture/outputs/

# Outputs and Achievements

> Documenting concrete deliverables from MCP development and utilization.

## About This Document

This document catalogs the concrete deliverables produced through MCP ecosystem development. It is organized into four categories: MCP servers, technical documentation, translation outputs, and technical articles, with each entry including an overview, repository URL, and quantitative metrics.

By visualizing "what was built" and "how much value was generated," this serves as a reference for future planning and as supporting material for external communications.

## Deliverable Categories

The deliverables produced through MCP development are organized into the following four primary categories. Below is a mind map visualizing the relationships and composition of each category.

```mermaid
mindmap
  root((Deliverables))
    MCP Servers
      rfcxml-mcp
      w3c-mcp
      xcomet-mcp-server
      rxjs-mcp-server
      epsg-mcp
      pdf-spec-mcp
      pdf-reader-mcp
    Technical Documentation
      Notes-about-Digital-Signatures
      websocket-practical-guide
    Translation Outputs
      RFC 6455 Japanese Translation
      Technical Document Translation
    Articles & Publications
      Note
      Qiita
      Zenn
```

## 1. MCP Servers

### Public Repositories

| Repository                                                            | Description                        | Stars | npm                              | Version |
| --------------------------------------------------------------------- | ---------------------------------- | :---: | -------------------------------- | ------- |
| [rfcxml-mcp](https://github.com/shuji-bonji/rfcxml-mcp)               | IETF RFC Structured Reference      |   -   | [`@shuji-bonji/rfcxml-mcp`](https://www.npmjs.com/package/@shuji-bonji/rfcxml-mcp) | v0.4.5  |
| [w3c-mcp](https://github.com/shuji-bonji/w3c-mcp)                     | W3C/WHATWG Web Standards           |   -   | [`@shuji-bonji/w3c-mcp`](https://www.npmjs.com/package/@shuji-bonji/w3c-mcp) | v0.1.7  |
| [xcomet-mcp-server](https://github.com/shuji-bonji/xcomet-mcp-server) | Translation Quality Evaluation     |  â­1  | [`xcomet-mcp-server`](https://www.npmjs.com/package/xcomet-mcp-server) | v0.3.6  |
| [rxjs-mcp-server](https://github.com/shuji-bonji/rxjs-mcp-server)     | RxJS Stream Execution & Analysis   |   -   | -                                | -       |
| [epsg-mcp](https://github.com/shuji-bonji/epsg-mcp)                   | EPSG Coordinate Reference Systems  |   -   | [`@shuji-bonji/epsg-mcp`](https://www.npmjs.com/package/@shuji-bonji/epsg-mcp) | v0.9.8  |
| [pdf-spec-mcp](https://github.com/shuji-bonji/pdf-spec-mcp)           | PDF Specification (ISO 32000)      |   -   | [`@shuji-bonji/pdf-spec-mcp`](https://www.npmjs.com/package/@shuji-bonji/pdf-spec-mcp) | v0.2.2  |
| [pdf-reader-mcp](https://github.com/shuji-bonji/pdf-reader-mcp)       | PDF Internal Structure Analysis    |   -   | [`@shuji-bonji/pdf-reader-mcp`](https://www.npmjs.com/package/@shuji-bonji/pdf-reader-mcp) | v0.2.0  |

### MCP Server Features

#### [rfcxml-mcp](https://www.npmjs.com/package/@shuji-bonji/rfcxml-mcp)

```
Provided Functions:
â”œâ”€â”€ get_rfc_structure    - Retrieve section hierarchy
â”œâ”€â”€ get_requirements     - Extract MUST/SHOULD/MAY requirements
â”œâ”€â”€ get_definitions      - Retrieve term definitions
â”œâ”€â”€ get_rfc_dependencies - Retrieve reference relationships
â”œâ”€â”€ generate_checklist   - Generate implementation checklist
â””â”€â”€ validate_statement   - Verify specification compliance

Achievements:
- Requirements extraction from RFC 6455 (75 MUST, 23 SHOULD)
- Requirements extraction from RFC 3161
- Mapping correspondence with Japan's Electronic Signature Act
```

#### [xcomet-mcp-server](https://www.npmjs.com/package/xcomet-mcp-server)

```
Provided Functions:
â”œâ”€â”€ xcomet_evaluate       - Quality score + error detection
â”œâ”€â”€ xcomet_detect_errors  - Detailed error analysis
â””â”€â”€ xcomet_batch_evaluate - Batch evaluation

Features:
- Persistent model loading (fast inference)
- GPU support
- Batch processing support

Achievements:
- Quality evaluation of 180-page technical document
- Completed at approximately $12 cost (less than 1/100 of conventional cost)
```

#### [pdf-spec-mcp](https://www.npmjs.com/package/@shuji-bonji/pdf-spec-mcp)

```
Provided Functions:
â”œâ”€â”€ list_specs        - List spec documents
â”œâ”€â”€ get_structure     - Get section hierarchy
â”œâ”€â”€ get_section       - Get section content
â”œâ”€â”€ search_spec       - Full-text search
â”œâ”€â”€ get_requirements  - Extract normative requirements (shall/must/may)
â”œâ”€â”€ get_definitions   - Get term definitions
â”œâ”€â”€ get_tables        - Extract table structures
â””â”€â”€ compare_versions  - Compare PDF 1.7 vs 2.0

Features:
- Supports both ISO 32000-1 (PDF 1.7) and ISO 32000-2 (PDF 2.0)
- Section-level structured access
- Cross-version comparison
```

#### [pdf-reader-mcp](https://www.npmjs.com/package/@shuji-bonji/pdf-reader-mcp)

```
Provided Functions:
â”œâ”€â”€ Basic Operations
â”‚   â”œâ”€â”€ read_text           - Text extraction
â”‚   â”œâ”€â”€ read_images         - Image extraction
â”‚   â”œâ”€â”€ search_text         - Text search
â”‚   â”œâ”€â”€ get_metadata        - Metadata extraction
â”‚   â”œâ”€â”€ get_page_count      - Page count
â”‚   â””â”€â”€ summarize           - Overview report
â”œâ”€â”€ Structure Inspection
â”‚   â”œâ”€â”€ inspect_structure   - Object structure
â”‚   â”œâ”€â”€ inspect_tags        - Tag structure analysis
â”‚   â”œâ”€â”€ inspect_fonts       - Font information
â”‚   â”œâ”€â”€ inspect_annotations - Annotations
â”‚   â””â”€â”€ inspect_signatures  - Digital signature fields
â””â”€â”€ Validation & Analysis
    â”œâ”€â”€ validate_tagged     - PDF/UA validation
    â”œâ”€â”€ validate_metadata   - Metadata validation
    â”œâ”€â”€ compare_structure   - Compare two PDFs
    â””â”€â”€ read_url            - Fetch PDF from URL

Features:
- 15 tools across 3 tiers
- PDF/UA accessibility validation
- 185 tests (146 E2E tests)
```

## 2. Technical Documentation

### Notes-about-Digital-Signatures-and-Timestamps

Systematization of domain knowledge on digital signatures and timestamps.

| Repository | [shuji-bonji/Notes-about-Digital-Signatures-and-Timestamps](https://github.com/shuji-bonji/Notes-about-Digital-Signatures-and-Timestamps) |
| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| Status     | Public                                                                                                                                    |
| File Count | 20+ files                                                                                                                                 |

#### Main Content

| File                         | Content                            |
| ---------------------------- | ---------------------------------- |
| `DigitalSignature.md`        | Digital Signature Fundamentals     |
| `TimeStamps.md`              | Timestamp Mechanisms               |
| `PublicKeyCertificate.md`    | Public Key Certificates            |
| `CertificationAuthority.md`  | Certificate Authorities            |
| `LongTermSignature.md`       | Long-term Signatures (PAdES-LTV)   |
| `EncryptionAndDecryption.md` | Encryption and Decryption          |
| `JWT.md` / `JWS.md`          | JSON Web Token/Signature           |
| `PKCS.md`                    | Public Key Cryptography Standards  |

#### MCP Utilization

- Retrieved legal text from Japan's Electronic Signature Act using `hourei-mcp`
- Extracted requirements from RFC 3161 (Timestamps) using `rfcxml-mcp`
- Mapped legal requirements to technical specifications

### websocket-practical-guide

A practical guide to WebSocket API and RFC 6455 translation.

| Repository    | [shuji-bonji/websocket-practical-guide](https://github.com/shuji-bonji/websocket-practical-guide) |
| ------------- | ------------------------------------------------------------------------------------------------- |
| Status        | Public                                                                                            |
| License       | CC-BY-4.0                                                                                         |
| Published at  | [GitHub Pages](https://shuji-bonji.github.io/websocket-practical-guide/)                          |
| Contributors  | shuji-bonji, Claude                                                                               |

#### Main Content

| Directory                   | Content                         |
| --------------------------- | ------------------------------- |
| `docs/`                     | WebSocket Practical Guide       |
| `rfc-translations/rfc6455/` | RFC 6455 Japanese Translation   |
| `src/`                      | Demo Code                       |
| `tests/e2e/`                | E2E Tests (Playwright)          |

#### Technology Stack

```
Svelte 40.9% | MDsveX 34.4% | TypeScript 21.5% | JavaScript 2.2%
```

## 3. Translation Outputs

### RFC 6455 Japanese Translation

Complete Japanese translation of the WebSocket Protocol (RFC 6455).

| Item                 | Details                                                                                                                    |
| -------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| Original             | [RFC 6455](https://www.rfc-editor.org/rfc/rfc6455)                                                                         |
| Translation          | [rfc6455-ja.md](https://github.com/shuji-bonji/websocket-practical-guide/blob/main/rfc-translations/rfc6455/rfc6455-ja.md) |
| Character Count      | Approximately 150,000 characters                                                                                           |
| Translation Workflow | DeepL + xCOMET + Claude                                                                                                    |

#### MCP Utilization Workflow

```mermaid
sequenceDiagram
    participant RFC as RFC Original
    participant DeepL as deepl-mcp
    participant xCOMET as xcomet-mcp
    participant Claude as Claude
    participant Output as Translation Output

    RFC->>DeepL: Translation
    DeepL->>xCOMET: Quality Evaluation
    xCOMET->>Claude: Score + Errors
    Claude->>Claude: Revision & Proofreading
    Claude->>Output: rfc6455-ja.md
```

### Large-scale Technical Document Translation

| Item         | Details                              |
| ------------ | ------------------------------------ |
| Scale        | 180 pages (approx. 1.5M characters)  |
| Duration     | 1 day                                |
| Cost         | Approximately $12                    |
| Comparison   | Less than 1/100 of conventional cost |

#### Key Success Factors

1. **DeepL API** - High-quality machine translation
2. **xCOMET MCP** - Automated quality evaluation
3. **Batch Processing** - Efficient large-volume processing
4. **Quality Feedback Loop** - Re-translation of low-score sections

## 4. Articles and Publications

### Platforms

| Platform   | URL                                                      | Purpose                      |
| ---------- | -------------------------------------------------------- | ---------------------------- |
| **Note**   | [note.com/shuji396](https://note.com/shuji396)           | Concepts, analysis, opinions |
| **Qiita**  | [qiita.com/shuji-bonji](https://qiita.com/shuji-bonji)   | Technical tips               |
| **Zenn**   | [zenn.dev/shuji_bonji](https://zenn.dev/shuji_bonji)     | Technical articles           |
| **GitHub** | [github.com/shuji-bonji](https://github.com/shuji-bonji) | Source code                  |

### Publication Strategy

```
Note   = Conceptual and opinion-based content
       (MCP philosophy, knowledge democratization, AI-driven development theory)

Qiita  = Technical tips and tool introductions
       (though the SEO culture raises some concerns)

Zenn   = Detailed technical articles and tutorials
       (though it can feel one-directional)

GitHub = Implementation and source code
       (the substance of deliverables)
```

## 5. Other Achievements

### MCP Ecosystem Research and Analysis

- Analysis of LINE Yahoo's MCP use cases
- Feature analysis of everything-claude-code
- Research on A2A (Agent-to-Agent) protocol

### Knowledge Systematization

- Vision organization for AI-driven development
- MCP/A2A/Skill/Agent composition theory
- Systematization of "reliable reference sources"

## Achievement Timeline

```mermaid
timeline
    title MCP-Related Achievement Timeline

    section 2024
        Early : Started rfcxml-mcp development
             : Built xcomet-mcp-server

    section 2025 Q1
        January : Completed RFC 6455 Japanese translation
               : Published websocket-practical-guide
               : Started MCP development systematization

    section 2025 Q2-Q4
        : Published w3c-mcp on npm
        : Published epsg-mcp on npm (v0.9.8)
        : Published rxjs-mcp-server

    section 2026 Q1
        : Published pdf-spec-mcp on npm
        : Published pdf-reader-mcp on npm
        : Reached 6 npm packages
```

## Achievement Metrics

### Quantitative Metrics

| Metric                       | Current        | Target (Phase 2) | Status      |
| ---------------------------- | -------------- | ---------------- | ----------- |
| Published MCP Servers        | 7              | 7+               | âœ… Achieved |
| Total GitHub Stars           | 1              | 10+              | ðŸ”„ Ongoing |
| npm Packages                 | 6              | 4+               | âœ… Achieved |
| Translated Characters        | 1.5M+          | -                | âœ… Achieved |
| Technical Documentation      | 2 repositories | 3+               | ðŸ”„ Ongoing |

### Qualitative Metrics

- [x] Started MCP ecosystem development
- [x] Established translation workflow
- [x] Demonstrated legal requirements to technical specification mapping
- [ ] Recognition from the community
- [ ] External inquiries and contributions

## Related Links

### GitHub

- [shuji-bonji](https://github.com/shuji-bonji) - Main Profile
- [shuji-bonji/shuji-bonji](https://github.com/shuji-bonji/shuji-bonji) - Activity Log

### npm

- [@shuji-bonji](https://www.npmjs.com/~shuji-bonji) - npm Packages

### Publications

- [Note](https://note.com/shuji396)
- [Qiita](https://qiita.com/shuji-bonji)
- [Zenn](https://zenn.dev/shuji_bonji)

---

## Priority and Roadmap

Source: https://shuji-bonji.github.io/ai-agent-architecture/roadmap/

# Priority and Roadmap

> Organizing priorities and timelines for MCP development.

## About This Document

To generate maximum value with limited resources, it is crucial to determine what to develop first. This document presents a priority matrix that considers current strengths, market demand, and implementation difficulty, and organizes short-term, medium-term, and long-term roadmaps.

Additionally, we discuss project evaluation by Grok and publishing strategies (Note/Qiita/Zenn/GitHub), outlining a growth strategy for the entire ecosystem beyond just technical development.

## Current Strengths

We analyze our strengths from three perspectives, drawing on the specialized knowledge and implementation assets accumulated through MCP development.

```mermaid
graph TB
    subgraph Built Assets
        RFC[rfcxml-mcp<br/>RFC Analysis]
        XCOMET[xcomet-mcp<br/>Translation Quality]
        RXJS[rxjs-mcp<br/>RxJS Support]
        W3C[w3c-mcp<br/>Web Standards]
        EPSG[epsg-mcp<br/>Coordinate Systems]
        PDFSPEC[pdf-spec-mcp<br/>PDF Specification]
        PDFREADER[pdf-reader-mcp<br/>PDF Analysis]
    end

    subgraph Expertise
        TS[TypeScript/Angular]
        WS[WebSocket/RFC]
        SIGN[Digital Signatures]
        TRANS[Translation Workflow]
        PDF[PDF Specification & Structure]
    end

    subgraph Unique Value
        CREATE["'Creating' not just 'Using'"]
        BRIDGE["Bridge to Japanese-speaking Community"]
        OPEN["Promoting Open Standards"]
    end

    Built Assets --> Unique Value
    Expertise --> Unique Value
```

## MCP Development Priority Matrix

To determine priorities for new MCP development, we conducted a matrix analysis using two axes: implementation difficulty and value/demand. The following chart shows the positioning of each MCP candidate.

```mermaid
quadrantChart
    title MCP Development Priority
    x-axis "Implementation Difficulty Low" --> "High"
    y-axis "Value/Demand Low" --> "High"
    quadrant-1 "Priority Implementation"
    quadrant-2 "Planned Implementation"
    quadrant-3 "Wait and See"
    quadrant-4 "Future Consideration"

    "OpenAPI MCP": [0.35, 0.75]
    "OWASP MCP": [0.45, 0.70]
    "Angular MCP": [0.40, 0.65]
    "NgRx MCP": [0.45, 0.55]
    "ISO MCP": [0.70, 0.45]
    "BIM/IFC MCP": [0.80, 0.40]
    "HL7 FHIR MCP": [0.85, 0.35]
```

## Phased Roadmap

### Phase 1: Foundation Strengthening (Short-term: 1-3 months)

**Goal**: Maximize utilization of existing MCPs, establish Skills/Agents

| Task                                    | Status        | Priority |
| --------------------------------------- | ------------- | -------- |
| Documentation for existing MCP usage    | In Progress   | 5 stars  |
| Create Translation Workflow Skill       | TODO          | 4 stars  |
| Define RFC Specialist Sub-agent         | TODO          | 4 stars  |
| Develop CLAUDE.md Templates             | TODO          | 3 stars  |

### Phase 2: Expansion (Medium-term: 3-6 months)

**Goal**: Build new MCPs, expand ecosystem

| Task                        | Status    | Priority |
| --------------------------- | --------- | -------- |
| Build OpenAPI MCP           | Concept   | 4 stars  |
| Build OWASP MCP             | Concept   | 4 stars  |
| Build Angular MCP           | Concept   | 3 stars  |
| Enhance rfcxml-mcp features | TODO      | 3 stars  |

### Phase 3: Deployment (Long-term: 6+ months)

**Goal**: Community contribution, expand specialized domains

| Task                          | Status  | Priority |
| ----------------------------- | ------- | -------- |
| ISO Standards MCP             | Concept | 2 stars  |
| BIM/IFC MCP                   | Concept | 2 stars  |
| Healthcare MCP (HL7 FHIR)     | Concept | 1 star   |
| Complete Note Article Series  | TODO    | 3 stars  |

## Detailed Roadmap

### Phase 1 Details

```mermaid
gantt
    title Phase 1: Foundation Strengthening
    dateFormat YYYY-MM
    section Documentation
        MCP Architecture Systematization    :done, 2025-01, 1M
        Workflow Documentation              :2025-02, 1M
    section Skill/Agent
        Translation Workflow Skill          :2025-02, 2w
        RFC Specialist Agent                :2025-02, 2w
        Coding Standards Skill              :2025-03, 2w
    section Utilization
        Apply to Real Projects              :2025-02, 2M
```

### Phase 2 Details

```mermaid
gantt
    title Phase 2: Expansion
    dateFormat YYYY-MM
    section New MCPs
        OpenAPI MCP Design                  :2025-03, 2w
        OpenAPI MCP Implementation          :2025-03, 1M
        OWASP MCP Design                    :2025-04, 2w
        OWASP MCP Implementation            :2025-04, 1M
    section Existing MCPs
        rfcxml-mcp Enhancement              :2025-04, 1M
        w3c-mcp Enhancement                 :2025-05, 1M
    section Specialized MCPs
        Angular MCP Review                  :2025-05, 2w
        Angular MCP Implementation          :2025-06, 1M
```

## Priority Decision Criteria

### Evaluation Axes

| Axis                       | Description                                      | Weight |
| -------------------------- | ------------------------------------------------ | ------ |
| **Fit with Strengths**     | Can we leverage existing knowledge/experience?   | 30%    |
| **Immediate Impact**       | Can it deliver value quickly?                    | 25%    |
| **Demand**                 | Are there expected users?                        | 20%    |
| **Implementation Difficulty** | Feasibility                                   | 15%    |
| **Uniqueness**             | Presence of competitors                          | 10%    |

### Evaluation Examples

| MCP         | Strengths | Immediate Impact | Demand | Difficulty | Uniqueness | Total  |
| ----------- | :-------: | :--------------: | :----: | :--------: | :--------: | :----: |
| OpenAPI MCP |     A     |        A         |   A    |     B      |     C      | **85** |
| OWASP MCP   |     B     |        A         |   A    |     B      |     B      | **80** |
| Angular MCP |     A     |        B         |   B    |     B      |     A      | **75** |
| ISO MCP     |     C     |        C         |   B    |     C      |     B      | **50** |
| BIM/IFC MCP |     C     |        C         |   C    |     C      |     A      | **45** |

## Utilization Plan for Existing MCPs

### rfcxml-mcp

| Initiative              | Details                                    | Timing  |
| ----------------------- | ------------------------------------------ | ------- |
| Documentation Enhancement | Add more usage examples to README        | Phase 1 |
| Feature Enhancement     | Cross-RFC search capability                | Phase 2 |
| Integration Enhancement | Integration workflow with w3c-mcp          | Phase 2 |

### xcomet-mcp-server

| Initiative               | Details                                    | Timing  |
| ------------------------ | ------------------------------------------ | ------- |
| Increase Awareness       | Publish translation workflow case studies  | Phase 1 |
| Performance              | Document GPU usage                         | Phase 1 |
| Integration              | Integration Skill with DeepL MCP           | Phase 1 |

### rxjs-mcp-server

| Initiative            | Details                                    | Timing  |
| --------------------- | ------------------------------------------ | ------- |
| Pattern Enhancement   | More use case patterns                     | Phase 2 |
| Angular Integration   | Integration with Angular MCP               | Phase 2 |

## Strategy Based on Grok's Evaluation

### Potential of xcomet-mcp-server

> "There is sufficient potential for this to take off within the next year" (Grok evaluation)

**Actions**:

- Publish translation workflow case studies (Note)
- Demo of DeepL + Claude + xCOMET
- Outreach to Japanese-speaking and European communities

### Potential of rfcxml-mcp

> "Could surge if the protocol-understanding agent boom arrives after 2027" (Grok evaluation)

**Actions**:

- Demos with hot RFCs (QUIC, HTTP/3, TLS 1.3)
- Expand checklist generation examples
- Establish implementation support workflow

## Publishing Strategy

### Note Article Plan

| Theme                      | Content                                  | Timing  |
| -------------------------- | ---------------------------------------- | ------- |
| **RFC x AI**               | Reading/interacting with RFCs via MCP    | Phase 1 |
| **Translation Workflow**   | DeepL + xCOMET in practice               | Phase 1 |
| **Democratization of Knowledge** | The essential value of MCP         | Phase 1 |
| **Agent Design**           | Distinguishing Skills/Agents/MCPs        | Phase 2 |

### Principles for Technical Publishing

1. Structure articles as **Concept -> Implementation -> Results**
2. Show **concrete deliverables** (code, checklists)
3. Clearly articulate **value to the Japanese-speaking community**

## Risks and Countermeasures

| Risk                    | Impact                        | Countermeasure                                           |
| ----------------------- | ----------------------------- | -------------------------------------------------------- |
| MCP Specification Changes | Modifications to existing MCPs | Monitor official specs, respond early                   |
| Emergence of Competing MCPs | Difficulty differentiating | Differentiate with unique value (Japanese, expertise)  |
| Time Constraints        | Schedule delays               | Adjust with Phase priorities                             |
| Misjudging Demand       | Build without adoption        | Build small and validate                                 |

## Success Metrics

### Short-term (Phase 1)

- [x] Complete documentation systematization
- [ ] Define 3+ Skills/Agents
- [x] Achieve usage in real projects

### Medium-term (Phase 2)

- [x] Release 2+ new MCPs â†’ **4 released** (w3c-mcp, epsg-mcp, pdf-spec-mcp, pdf-reader-mcp)
- [ ] Reach 10+ total GitHub Stars
- [ ] Publish 5+ Note articles
- [x] Publish 4+ npm packages â†’ **6 packages published**

### Long-term (Phase 3)

- [x] Establish MCP ecosystem â†’ 6 npm packages published
- [ ] Gain community recognition
- [ ] Receive external inquiries/contributions

## Next Actions

### Immediate Tasks

1. **Reflect this document on GitHub**
2. **Create Translation Workflow Skill**
3. **Define RFC Specialist Sub-agent**

### Tasks for This Month

1. **Write Note article on xcomet use cases**
2. **Improve README for existing MCPs**
3. **Create CLAUDE.md template**
